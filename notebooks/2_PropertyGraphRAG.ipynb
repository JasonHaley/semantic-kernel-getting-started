{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property Graph RAG in C#\n",
    "\n",
    "Currently this notebook uses the following resources:\n",
    "* Azure Open AI\n",
    "* Neo4j\n",
    "\n",
    "If there is enough interest, I can add the changes needed to just use OpenAI - so if this is something you'd like, let me know on twitter @haleyjason or open an issue on github.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Add the references and using statements used in the rest of the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Azure.AI.OpenAI, *-*\"\n",
    "#r \"nuget: Azure, *-*\"\n",
    "#r \"nuget: Azure.Identity, *-*\"\n",
    "#r \"nuget: dotenv.net, *-*\"\n",
    "#r \"nuget: Microsoft.DotNet.Interactive.AIUtilities, *-*\"\n",
    "#r \"nuget: Microsoft.ML.Tokenizers, *-*\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Core, *-*\"\n",
    "#r \"nuget: Neo4j.Driver, *-*\"\n",
    "\n",
    "using Microsoft.DotNet.Interactive;\n",
    "using Microsoft.DotNet.Interactive.AIUtilities;\n",
    "using dotenv.net;\n",
    "using Azure.AI.OpenAI;\n",
    "using Azure;\n",
    "using Azure.Identity;\n",
    "using OpenAI.Chat;\n",
    "using System;\n",
    "using System.Text.Json;\n",
    "using System.Text.Json.Serialization;\n",
    "using System.Text.RegularExpressions;\n",
    "using System.IO;\n",
    "using Microsoft.SemanticKernel.Text;\n",
    "using Microsoft.ML.Tokenizers;\n",
    "using Neo4j.Driver;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the environment variables. **The notebook assumes you have a .env file** with the following contents:\n",
    "\n",
    "```cmd\n",
    "AZURE_OPENAI_ENDPOINT=\"<you azure open ai endpoint>\"\n",
    "AZURE_OPENAI_RESOURCE=\"<you azure open ai resource name>\"\n",
    "AZURE_OPENAI_API_KEY=\"<your azure open ai key>\"\n",
    "AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=\"<name of your embeddings deployment>\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT=\"<name of your chat deployment>\"\n",
    "\n",
    "NEO4J_URI=\"neo4j://localhost:7687\"\n",
    "NEO4J_USER=\"<neo4 user name>\"\n",
    "NEO4J_PASSWORD=\"<neo4j user password>\"\n",
    "NEO4J_DATABASE=\"<name of you neo4j database>\",\n",
    "```\n",
    "\n",
    "> Note: I did my testing using text-embedding-ada-002 for embeddings and gpt-4o for the chat service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "DotEnv.Load();\n",
    "\n",
    "var envVars = DotEnv.Read();\n",
    "\n",
    "AzureOpenAIClient client = new(new Uri(envVars[\"AZURE_OPENAI_ENDPOINT\"]), \n",
    "    new AzureKeyCredential(envVars[\"AZURE_OPENAI_API_KEY\"]));\n",
    "\n",
    "var embeddings = envVars[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"];\n",
    "var llm = envVars[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE: You may want to skip to the Neo4j Connection step to make sure your environment variables settings are complete before continuing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo4j connection\n",
    "\n",
    "I've been running this wit Neo4j Desktop. There are other ways to run it. Please check out their [Installation Page](https://neo4j.com/docs/operations-manual/current/installation/) for more information.\n",
    "\n",
    "Once you get a Neo4j database running, you'll need to make sure the information is saved in the .env file mentioned earlier before running this next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "IAuthToken token = AuthTokens.Basic(\n",
    "                envVars[\"NEO4J_USER\"],\n",
    "                envVars[\"NEO4J_PASSWORD\"]\n",
    "            );\n",
    "IDriver driver = GraphDatabase.Driver(envVars[\"NEO4J_URI\"], token);\n",
    "\n",
    "QueryConfig config = new QueryConfig();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ingestion phase is broken up in to the following steps, which should allow for some experimentation with the different steps:\n",
    "1. define the data structures used in extracting the entities and populating the Neo4j database\n",
    "2. call the LLM to extract entities\n",
    "3. process the results into a unique list of entities and their relationships\n",
    "4. generate the cypher to populate Neo4j\n",
    "5. populate the Neo4j database\n",
    "6. create and populate vector and full text indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the data structures and utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "public record DocunentMetadata(string id, string source);\n",
    "public record ChunkMetadata(string id, string name, int sequence, string documentId, string text);\n",
    "public record TripletRow(string head, string head_type, string relation, string tail, string tail_type);\n",
    "public class EntityMetadata\n",
    "{\n",
    "    public string name { get; set; }\n",
    "    public string type { get; set; }\n",
    "    public string id { get; set; }\n",
    "    public string text { get; set; }\n",
    "    public Dictionary<string, ChunkMetadata> mentionedInChunks {get; set;} = new Dictionary<string, ChunkMetadata>();\n",
    "}\n",
    "\n",
    "public class Utilities\n",
    "{    \n",
    "    public static EntityMetadata PopulateEntityMetadata(ChunkMetadata chunkMetadata, TripletRow triplet, EntityMetadata entityMetadata, bool isHead = true)\n",
    "    {\n",
    "        entityMetadata.id = Guid.NewGuid().ToString(\"N\");\n",
    "\n",
    "        if (isHead)\n",
    "        {\n",
    "            entityMetadata.name = CreateName(triplet.head);\n",
    "            entityMetadata.type = triplet.head_type;\n",
    "            entityMetadata.text = triplet.head;\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            entityMetadata.name = CreateName(triplet.tail);\n",
    "            entityMetadata.type = triplet.tail_type;\n",
    "            entityMetadata.text = triplet.tail;\n",
    "        }\n",
    "\n",
    "        entityMetadata.mentionedInChunks.Add(chunkMetadata.id, chunkMetadata);\n",
    "        \n",
    "        return entityMetadata;\n",
    "    }\n",
    "\n",
    "    public static string CreateName(string text)\n",
    "    {\n",
    "        if (string.IsNullOrEmpty(text))\n",
    "            return text;\n",
    "\n",
    "        // Split the text into words\n",
    "        string[] words = text.Split(new[] { ' ', '-', '_' }, StringSplitOptions.RemoveEmptyEntries);\n",
    "\n",
    "        StringBuilder nameText = new StringBuilder();\n",
    "        \n",
    "        foreach (string word in words)\n",
    "        {\n",
    "            // Capitalize the first letter and make the rest lowercase\n",
    "            var lword = word;\n",
    "            if (char.IsDigit(word[0]))\n",
    "            {\n",
    "                lword = \"_\" + word;\n",
    "            }\n",
    "\n",
    "            nameText.Append(lword.ToLower());\n",
    "        }\n",
    "        return Regex.Replace(nameText.ToString(), \"[^a-zA-Z0-9_]\", \"\");\n",
    "    }\n",
    "    \n",
    "    public static List<string> SplitPlainTextOnEmptyLine(string[] lines)\n",
    "    {\n",
    "        List<string> allLines = new List<string>(lines);\n",
    "        List<string> result = new List<string>();\n",
    "\n",
    "        // Make sure there is an empty string as last line to split into paragraph\n",
    "        var last = allLines.Last();\n",
    "        if (last.Length > 0)\n",
    "        {\n",
    "            allLines.Add(\"\");\n",
    "        }\n",
    "\n",
    "        StringBuilder paragraphBuilder = new StringBuilder();\n",
    "        foreach (string input in allLines)\n",
    "        {\n",
    "            if (input.Length == 0)\n",
    "            {\n",
    "                result.Add(paragraphBuilder.ToString());\n",
    "                paragraphBuilder.Clear();\n",
    "            }\n",
    "            paragraphBuilder.Append($\"{input} \");\n",
    "        }\n",
    "\n",
    "        return result;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity extraction\n",
    "\n",
    "This step is where the LLM takes the chunks of text and extracts up to 10 entities per chunk\n",
    "\n",
    "Steps include:\n",
    "* Break the data file into chunks using 500 tokens and 100 token overlap as limits\n",
    "* Provide some default entities and relation types for the prompt to use in directing the LLM in extracting the entities (extration works best if you customize this to match your data file contents)\n",
    "* Loop through all the chunks calling the LLM for each chunk **(Warning: this can get expensive - so change the ```paragraphs.Count``` limit to 1 or 2 until you are happy with your results)**\n",
    "* Parse each JSON result form the LLM calls and keep the ```chunks``` variable for later post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"(Personal Update) Learning AI\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"(Personal Update) Learning AI\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Thursday, January 18, 2024\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"(Personal Update) Learning AI\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"(Personal Update) Learning AI\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"(Personal Update) Learning AI\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"(Personal Update) Learning AI\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Personal Update\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"PLANS_TO\", \"tail\": \"make more blog posts\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"WORKS_ON\", \"tail\": \"Learning AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"WORKS_ON\", \"tail\": \"four stages of competence\", \"tail_type\": \"PROCESS\"},\n",
      "    {\"head\": \"four stages of competence\", \"head_type\": \"PROCESS\", \"relation\": \"HAS_STAGE\", \"tail\": \"Unconscious incompetence\", \"tail_type\": \"STAGE\"},\n",
      "    {\"head\": \"four stages of competence\", \"head_type\": \"PROCESS\", \"relation\": \"HAS_STAGE\", \"tail\": \"Conscious incompetence\", \"tail_type\": \"STAGE\"},\n",
      "    {\"head\": \"four stages of competence\", \"head_type\": \"PROCESS\", \"relation\": \"HAS_STAGE\", \"tail\": \"Conscious competence\", \"tail_type\": \"STAGE\"},\n",
      "    {\"head\": \"four stages of competence\", \"head_type\": \"PROCESS\", \"relation\": \"HAS_STAGE\", \"tail\": \"Unconscious competence\", \"tail_type\": \"STAGE\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"MOVED_FROM\", \"tail\": \"stage 2 to stage 3\", \"tail_type\": \"PROCESS\"},\n",
      "    {\"head\": \"Q1 of 2024\", \"head_type\": \"TIME_PERIOD\", \"relation\": \"INCLUDES\", \"tail\": \"moving from stage 2 to stage 3\", \"tail_type\": \"PROCESS\"},\n",
      "    {\"head\": \"2023\", \"head_type\": \"TIME_PERIOD\", \"relation\": \"INCLUDES\", \"tail\": \"moved from stage 1 to stage 2\", \"tail_type\": \"PROCESS\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"USED_BY\", \"tail\": \"industry leaders\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"industry leaders\", \"head_type\": \"PERSON\", \"relation\": \"USE\", \"tail\": \"latest AI tool\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"latest AI tool\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"EXAMPLE\", \"tail\": \"ChatGPT\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"IGNORED\", \"tail\": \"beginning of last year\", \"tail_type\": \"TIME_PERIOD\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"RAG Demo Chronicles\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"RAG Demo Chronicles\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Wednesday, February 7, 2024\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"RAG Demo Chronicles\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"RAG Demo Chronicles\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"RAG Demo Chronicles\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"RAG Demo Chronicles\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG Demo Series\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"MENTIONED\", \"tail\": \"last blog entry\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"LEARNING\", \"tail\": \"AI related topics\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"newest research topic\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"IS\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"CONVINCED_BY\", \"tail\": \"learning about RAG\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"clients\", \"head_type\": \"PERSON\", \"relation\": \"CAN_TAKE_ADVANTAGE_OF\", \"tail\": \"GenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"clients\", \"head_type\": \"PERSON\", \"relation\": \"TIMELINE\", \"tail\": \"short term\", \"tail_type\": \"TIME_PERIOD\"},\n",
      "    {\"head\": \"presentation\", \"head_type\": \"EVENT\", \"relation\": \"TOPIC\", \"tail\": \"How to Chat with Your Documents\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"blog\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"How to Chat with Your Documents\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"How to Chat with Your Documents\", \"head_type\": \"BLOG_POST\", \"relation\": \"ABOUT\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server and OpenAI\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server and OpenAI\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Wednesday, February 7, 2024\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server and OpenAI\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server and OpenAI\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server and OpenAI\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server and OpenAI\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server and OpenAI\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG Demo Series\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server and OpenAI\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"SQL Server\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server and OpenAI\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"ORGANIZATION\"},\n",
      "    {\"head\": \"full stack C# developer\", \"head_type\": \"PERSON\", \"relation\": \"INTERESTED_IN\", \"tail\": \"GenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"relational database developer\", \"head_type\": \"PERSON\", \"relation\": \"USES\", \"tail\": \"SQL Server\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"INTEREST_IN\", \"tail\": \"vector databases\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"relational database developer\", \"head_type\": \"PERSON\", \"relation\": \"INTERESTS\", \"tail\": \"functionality\", \"tail_type\": \"ACTION\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Sunday, February 11, 2024\", \"tail_type\": \"DATE\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Function Calling\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG Demo Series\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"SQL Server\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"ORGANIZATION\"},\n",
      "    {\"head\": \"Michael Washington\", \"head_type\": \"PERSON\", \"relation\": \"CREATED\", \"tail\": \"Demo\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Demo\", \"head_type\": \"EVENT\", \"relation\": \"TITLE\", \"tail\": \"Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Full Stack Developer\", \"head_type\": \"PERSON\", \"relation\": \"ATTEMPTS_TO_LEARN\", \"tail\": \"GenAI Technologies\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"GenAI Technologies\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USED_IN\", \"tail\": \"Business Applications\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"RAG (Retrieval Augmented Generation)\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"HAS_STEP\", \"tail\": \"Step 1\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"RAG (Retrieval Augmented Generation)\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"HAS_STEP\", \"tail\": \"Step 2\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"RAG (Retrieval Augmented Generation)\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"HAS_STEP\", \"tail\": \"Step 3\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"RAG (Retrieval Augmented Generation)\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"HAS_STEP\", \"tail\": \"Step 4\", \"tail_type\": \"ACTION\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo C#\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo C#\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Wednesday, February 14, 2024\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo C#\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo C#\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo C#\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo C#\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo C#\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG Demo Series\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo C#\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo C#\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"ORGANIZATION\"},\n",
      "    {\"head\": \"RAG demos\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"USES\", \"tail\": \"Azure Search\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"RAG demos\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"USES\", \"tail\": \"Azure OpenAI\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"RAG demos\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"PART_OF\", \"tail\": \"GitHub\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"azure-search-openai-demo-csharp\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"WRITTEN_IN\", \"tail\": \"C#\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"azure-search-openai-demo\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"WRITTEN_IN\", \"tail\": \"Python\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"azure-search-openai-javascript\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"WRITTEN_IN\", \"tail\": \"JavaScript/TypeScript\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"azure-search-openai-demo-java\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"WRITTEN_IN\", \"tail\": \"Java\", \"tail_type\": \"TECHNOLOGY\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Javascript/Typescript\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Javascript/Typescript\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Monday, February 19, 2024\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Javascript/Typescript\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Javascript/Typescript\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Javascript/Typescript\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Javascript/Typescript\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Javascript/Typescript\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG Demo Series\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Javascript/Typescript\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Javascript/Typescript\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"LangChain\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"REVIEWED\", \"tail\": \"Azure Search OpenAI demos\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Azure Search OpenAI demos\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"PART_OF\", \"tail\": \"Azure Search OpenAI Javascript/Typescript\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"C# version\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"REVIEWED_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"C# version\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"PART_OF\", \"tail\": \"Azure Search OpenAI demos\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Javascript version\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"PART_OF\", \"tail\": \"Azure Search OpenAI demos\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Javascript version\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"DIFFERENT_FROM\", \"tail\": \"C# version\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Javascript version\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"USES\", \"tail\": \"web components\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"web application\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"WRITTEN_IN\", \"tail\": \"React\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"web application\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"USES\", \"tail\": \"web components\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"web components\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"COMPATIBLE_WITH\", \"tail\": \"React\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"web components\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"COMPATIBLE_WITH\", \"tail\": \"Angular\", \"tail_type\": \"TECHNOLOGY\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo (Python)\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo (Python)\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Friday, February 23, 2024\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo (Python)\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo (Python)\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo (Python)\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo (Python)\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo (Python)\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG Demo Series\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Demo Review: Azure Search OpenAI Demo (Python)\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Azure Search OpenAI demos\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"PART_OF\", \"tail\": \"RAG Demo Series\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"REVIEWED\", \"tail\": \"C# version of Azure Search OpenAI demos\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"REVIEWED\", \"tail\": \"Javascript/Typescript version of Azure Search OpenAI demos\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Azure Search OpenAI Demo (Python)\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"IS_ACTIVE\", \"tail\": \"most active\", \"tail_type\": \"ATTRIBUTE\"},\n",
      "    {\"head\": \"Azure Search OpenAI Demo (Python)\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"IS_POPULAR\", \"tail\": \"most popular\", \"tail_type\": \"ATTRIBUTE\"},\n",
      "    {\"head\": \"Azure Search OpenAI Demo (Python)\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"HAS_DOCUMENTATION\", \"tail\": \"most documentation\", \"tail_type\": \"ATTRIBUTE\"},\n",
      "    {\"head\": \"Hack Together: The AI Chat App Hack\", \"head_type\": \"EVENT\", \"relation\": \"USED\", \"tail\": \"Azure Search OpenAI Demo (Python)\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Hack Together: The AI Chat App Hack\", \"head_type\": \"EVENT\", \"relation\": \"OCCURRED_ON\", \"tail\": \"February 2024\", \"tail_type\": \"DATE\"},\n",
      "    {\"head\": \"Azure Search OpenAI Demo (Python)\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"MARKED_AS\", \"tail\": \"solid reference implementation for RAG\", \"tail_type\": \"DESCRIPTION\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Demo Review: Azure Vector Search AI Assistant\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Demo Review: Azure Vector Search AI Assistant\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Monday, February 26, 2024\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Demo Review: Azure Vector Search AI Assistant\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Vector Search AI Assistant\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Demo Review: Azure Vector Search AI Assistant\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Vector Search AI Assistant\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Vector Search AI Assistant\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG Demo Series\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Demo Review: Azure Vector Search AI Assistant\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Azure Vector Search AI Assistant\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    \n",
      "    {\"head\": \"The RAG Demo Chronicles\", \"head_type\": \"BLOG_POST\", \"relation\": \"PART_OF\", \"tail\": \"RAG Demo Series\", \"tail_type\": \"BLOG_POST\"},\n",
      "    \n",
      "    {\"head\": \"RAG Demo Series\", \"head_type\": \"BLOG_POST\", \"relation\": \"INCLUDES\", \"tail\": \"fourth C# demo\", \"tail_type\": \"BLOG_POST\"},\n",
      "    \n",
      "    {\"head\": \"fourth C# demo\", \"head_type\": \"BLOG_POST\", \"relation\": \"FEATURES\", \"tail\": \"saves history to database\", \"tail_type\": \"ACTION\"},\n",
      "    \n",
      "    {\"head\": \"RAG demo\", \"head_type\": \"BLOG_POST\", \"relation\": \"SOURCE\", \"tail\": \"data from database\", \"tail_type\": \"DATA\"},\n",
      "    \n",
      "    {\"head\": \"RAG demo\", \"head_type\": \"BLOG_POST\", \"relation\": \"USES\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "  {\"head\": \"Boston Code Camp 36\", \"head_type\": \"EVENT\", \"relation\": \"HAS_SESSION\", \"tail\": \"Boston Code Camp 36 Sessions\", \"tail_type\": \"PRESENTATION\"},\n",
      "  {\"head\": \"Boston Code Camp 36 Sessions\", \"head_type\": \"PRESENTATION\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "  {\"head\": \"Boston Code Camp 36 Sessions\", \"head_type\": \"PRESENTATION\", \"relation\": \"POSTED_ON\", \"tail\": \"Sunday, March 24, 2024\", \"tail_type\": \"DATE\"},\n",
      "  {\"head\": \"Boston Code Camp 36 Sessions\", \"head_type\": \"PRESENTATION\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Boston Code Camp 36 Sessions\", \"head_type\": \"PRESENTATION\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Boston Code Camp 36 Sessions\", \"head_type\": \"PRESENTATION\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "  {\"head\": \"Boston Code Camp 36 Sessions\", \"head_type\": \"PRESENTATION\", \"relation\": \"TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Boston Code Camp 36 Sessions\", \"head_type\": \"PRESENTATION\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Boston Code Camp 36 Sessions\", \"head_type\": \"PRESENTATION\", \"relation\": \"TOPIC\", \"tail\": \"Presentation\", \"tail_type\": \"ACTION\"},\n",
      "  {\"head\": \"Boston Code Camp 36\", \"head_type\": \"EVENT\", \"relation\": \"BELONGS_TO\", \"tail\": \"Boston tech community\", \"tail_type\": \"COMMUNITY\"},\n",
      "  {\"head\": \"Boston tech community\", \"head_type\": \"COMMUNITY\", \"relation\": \"HOSTS\", \"tail\": \"Boston Code Camp 36\", \"tail_type\": \"EVENT\"},\n",
      "  {\"head\": \"Boston Code Camp 36\", \"head_type\": \"EVENT\", \"relation\": \"DURATION\", \"tail\": \"20+ years\", \"tail_type\": \"TIME_PERIOD\"},\n",
      "  {\"head\": \"Boston Code Camp 36\", \"head_type\": \"EVENT\", \"relation\": \"PARTICIPANT\", \"tail\": \"developers\", \"tail_type\": \"PERSON\"},\n",
      "  {\"head\": \"Boston Code Camp 36\", \"head_type\": \"EVENT\", \"relation\": \"PARTICIPANT\", \"tail\": \"students\", \"tail_type\": \"PERSON\"},\n",
      "  {\"head\": \"Boston Code Camp 36\", \"head_type\": \"EVENT\", \"relation\": \"PARTICIPANT\", \"tail\": \"architects\", \"tail_type\": \"PERSON\"},\n",
      "  {\"head\": \"Talk: Getting Started with Retrieval Augmented Generation (RAG)\", \"head_type\": \"PRESENTATION\", \"relation\": \"PRESENTED_AT\", \"tail\": \"Boston Code Camp 36\", \"tail_type\": \"EVENT\"},\n",
      "  {\"head\": \"Talk: Getting Started with Retrieval Augmented Generation (RAG)\", \"head_type\": \"PRESENTATION\", \"relation\": \"TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Talk: Getting Started with Retrieval Augmented Generation (RAG)\", \"head_type\": \"PRESENTATION\", \"relation\": \"AUDIENCE\", \"tail\": \"full room\", \"tail_type\": \"PLACE\"},\n",
      "  {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"PRESENTED\", \"tail\": \"Talk: Getting Started with Retrieval Augmented Generation (RAG)\", \"tail_type\": \"PRESENTATION\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "  {\"head\": \"Semantic Kernel Hello World\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "  {\"head\": \"Semantic Kernel Hello World\", \"head_type\": \"BLOG_POST\", \"relation\": \"PUBLISHED_ON\", \"tail\": \"Saturday, March 30, 2024\", \"tail_type\": \"EVENT\"},\n",
      "  {\"head\": \"Semantic Kernel Hello World\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Semantic Kernel Hello World\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"ACTION\"},\n",
      "  {\"head\": \"Semantic Kernel Hello World\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Semantic Kernel Hello World\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"ORGANIZATION\"},\n",
      "  {\"head\": \"Semantic Kernel Hello World\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Virtual Boston Azure meetup\", \"head_type\": \"EVENT\", \"relation\": \"PART_OF\", \"tail\": \"Thursday night\", \"tail_type\": \"EVENT\"},\n",
      "  {\"head\": \"Bill Wilder\", \"head_type\": \"PERSON\", \"relation\": \"CREATED\", \"tail\": \"AI mini-workshop\", \"tail_type\": \"EVENT\"},\n",
      "  {\"head\": \"Virtual Boston Azure meetup\", \"head_type\": \"EVENT\", \"relation\": \"INCLUDES\", \"tail\": \"AI mini-workshop\", \"tail_type\": \"EVENT\"},\n",
      "  {\"head\": \"Virtual Boston Azure meetup\", \"head_type\": \"EVENT\", \"relation\": \"LOCATED_IN\", \"tail\": \"Boston\", \"tail_type\": \"PLACE\"},\n",
      "  {\"head\": \"AI mini-workshop\", \"head_type\": \"EVENT\", \"relation\": \"FOCUSED_ON\", \"tail\": \"hands on with code\", \"tail_type\": \"ACTION\"},\n",
      "  {\"head\": \"AI mini-workshop\", \"head_type\": \"EVENT\", \"relation\": \"USES\", \"tail\": \"Azure OpenAI API\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"ATTENDED\", \"tail\": \"Virtual Boston Azure meetup\", \"tail_type\": \"EVENT\"},\n",
      "  {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"APPLIED_IDEA_OF\", \"tail\": \"AI mini-workshop\", \"tail_type\": \"EVENT\"},\n",
      "  {\"head\": \"OpenAI Chat Hello World C#\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "  {\"head\": \"OpenAI Chat Hello World C#\", \"head_type\": \"BLOG_POST\", \"relation\": \"USES\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Bill\", \"head_type\": \"PERSON\", \"relation\": \"PROVIDED_CODE\", \"tail\": \"OpenAI chat\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "  {\"head\": \"OpenAI chat\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"IMPLEMENTATION_LANGUAGE\", \"tail\": \"C#\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"OpenAI chat\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"USES\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Thursday, April 11, 2024\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"WROTE\", \"tail\": \"Hello World application with Semantic Kernel\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"MS Learning path: APL-2005\", \"head_type\": \"COURSE\", \"relation\": \"USES\", \"tail\": \"Azure OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"MS Learning path: APL-2005\", \"head_type\": \"COURSE\", \"relation\": \"USES\", \"tail\": \"Semantic Kernel SDK\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"MS Learning path: APL-2005\", \"head_type\": \"COURSE\", \"relation\": \"RECOMMENDED_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"RECOMMENDS\", \"tail\": \"MS Learning path: APL-2005\", \"tail_type\": \"COURSE\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"PART_OF\", \"tail\": \"last entry\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Hello World application\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"CREATED_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"prompt\", \"head_type\": \"CODE_SNIPPET\", \"relation\": \"EXTRACTED_FROM\", \"tail\": \"last entry\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"prompt\", \"head_type\": \"CODE_SNIPPET\", \"relation\": \"EXTRACTED_TO\", \"tail\": \"plugin\", \"tail_type\": \"SOFTWARE_COMPONENT\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"My Session at Boston Global Azure Bootcamp\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"My Session at Boston Global Azure Bootcamp\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Tuesday, April 23, 2024\", \"tail_type\": \"DATE\"},\n",
      "    {\"head\": \"My Session at Boston Global Azure Bootcamp\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"My Session at Boston Global Azure Bootcamp\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"TOPIC\"},\n",
      "    {\"head\": \"My Session at Boston Global Azure Bootcamp\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"My Session at Boston Global Azure Bootcamp\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"My Session at Boston Global Azure Bootcamp\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"My Session at Boston Global Azure Bootcamp\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Presentation\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Boston Azure’s Edition of the annual Global Azure Bootcamp\", \"head_type\": \"EVENT\", \"relation\": \"PART_OF\", \"tail\": \"annual Global Azure Bootcamp\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Boston Azure’s Edition of the annual Global Azure Bootcamp\", \"head_type\": \"EVENT\", \"relation\": \"FOCUS\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Boston Azure’s Edition of the annual Global Azure Bootcamp\", \"head_type\": \"EVENT\", \"relation\": \"ACTIVITY\", \"tail\": \"hands-on-labs\", \"tail_type\": \"ACTIVITY\"},\n",
      "    {\"head\": \"Boston Azure’s Edition of the annual Global Azure Bootcamp\", \"head_type\": \"EVENT\", \"relation\": \"LOCATION\", \"tail\": \"Boston\", \"tail_type\": \"PLACE\"},\n",
      "    {\"head\": \"meetup\", \"head_type\": \"EVENT\", \"relation\": \"PART_OF\", \"tail\": \"Boston Azure’s Edition of the annual Global Azure Bootcamp\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"people\", \"head_type\": \"PERSON\", \"relation\": \"SIGN_UP_FOR\", \"tail\": \"group\", \"tail_type\": \"ORGANIZATION\"},\n",
      "    {\"head\": \"members\", \"head_type\": \"PERSON\", \"relation\": \"PART_OF\", \"tail\": \"group\", \"tail_type\": \"ORGANIZATION\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"PARTICIPATED_IN\", \"tail\": \"meetup\", \"tail_type\": \"EVENT\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Friday, April 26, 2024\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"PREVIOUS_PART_OF\", \"tail\": \"Semantic Kernel Hello World Plugins Part 2\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"prompt template\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"USED_IN\", \"tail\": \"Part 1\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"native function\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"IMPLEMENTED_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"native function\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"DISCUSSED_IN\", \"tail\": \"Semantic Kernel Hello World Plugins Part 2\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"current date\", \"head_type\": \"DATA\", \"relation\": \"USED_AS_INPUT_IN\", \"tail\": \"native function\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"LLM\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"CALLED_BY\", \"tail\": \"native function\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"HelloWorld.Plugin2.Console project\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"CONTAINS_CODE_FOR\", \"tail\": \"Semantic Kernel Hello World Plugins Part 2\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"HelloWorld.Plugin2.Console project\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"PART_OF_REPO\", \"tail\": \"semantic-kernel-getting-started\", \"tail_type\": \"REPOSITORY\"},\n",
      "    {\"head\": \"semantic-kernel-getting-started\", \"head_type\": \"REPOSITORY\", \"relation\": \"CONTAINS\", \"tail\": \"HelloWorld.Plugin2.Console project\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Microsoft Learn module\", \"head_type\": \"LEARNING_MODULE\", \"relation\": \"COVERS_TOPIC\", \"tail\": \"Give your AI agent skills\", \"tail_type\": \"LEARNING_TOPIC\"},\n",
      "    {\"head\": \"Give your AI agent skills\", \"head_type\": \"LEARNING_TOPIC\", \"relation\": \"EXPLAINS\", \"tail\": \"native function\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Microsoft\", \"head_type\": \"ORGANIZATION\", \"relation\": \"PROVIDES\", \"tail\": \"Microsoft Learn module\", \"tail_type\": \"LEARNING_MODULE\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 3\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 3\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Tuesday, April 30, 2024\", \"tail_type\": \"DATE\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 3\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Artificial Intelligence\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 3\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"TOPIC\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 3\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 3\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 3\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"WRITTEN_BLOG_POST\", \"tail\": \"Part 2\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"SHOWS\", \"tail\": \"Creation of native function plugin\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 3\", \"head_type\": \"BLOG_POST\", \"relation\": \"USING_TECHNOLOGY\", \"tail\": \"OpenAI Function calling\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"CREATED\", \"tail\": \"HelloWorld.Plugin3.Console project\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"HelloWorld.Plugin3.Console project\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"ACCESSIBLE_ON\", \"tail\": \"GitHub\", \"tail_type\": \"WEBSITE\"},\n",
      "    {\"head\": \"HelloWorld.Plugin3.Console project\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"CONTAINS_CODE_FOR\", \"tail\": \"Semantic Kernel Hello World Plugins Part 3\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Native function plugin\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"STEPS_FORWARD\", \"tail\": \"OpenAI Function calling\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"OpenAI\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"PROVIDES\", \"tail\": \"Current date\", \"tail_type\": \"INFORMATION\"},\n",
      "    {\"head\": \"OpenAI\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USES\", \"tail\": \"Function calling\", \"tail_type\": \"TECHNOLOGY\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Memphis Azure User Group\", \"head_type\": \"EVENT\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Memphis Azure User Group\", \"head_type\": \"EVENT\", \"relation\": \"POSTED_ON\", \"tail\": \"Tuesday, May 7, 2024\", \"tail_type\": \"DATE\"},\n",
      "    {\"head\": \"Memphis Azure User Group\", \"head_type\": \"EVENT\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Memphis Azure User Group\", \"head_type\": \"EVENT\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"TOPIC\"},\n",
      "    {\"head\": \"Memphis Azure User Group\", \"head_type\": \"EVENT\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Memphis Azure User Group\", \"head_type\": \"EVENT\", \"relation\": \"TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Memphis Azure User Group\", \"head_type\": \"EVENT\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"PRESENTED_AT\", \"tail\": \"Memphis Azure User Group\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"GAVE_TALK\", \"tail\": \"Getting Started with Retrieval Augmented Generation\", \"tail_type\": \"PRESENTATION\"},\n",
      "    {\"head\": \"Getting Started with Retrieval Augmented Generation\", \"head_type\": \"PRESENTATION\", \"relation\": \"GIVEN_AT\", \"tail\": \"Memphis Azure User Group\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"UPDATED_SLIDES\", \"tail\": \"Memphis themed via Bing/create\", \"tail_type\": \"\"},\n",
      "    {\"head\": \"Getting Started with Retrieval Augmented Generation\", \"head_type\": \"PRESENTATION\", \"relation\": \"FORMAT\", \"tail\": \"hybrid\", \"tail_type\": \"FORMAT\"},\n",
      "    {\"head\": \"Memphis Azure User Group\", \"head_type\": \"EVENT\", \"relation\": \"HELD_ON\", \"tail\": \"last Thursday night\", \"tail_type\": \"DATE\"},\n",
      "    {\"head\": \"Memphis Azure User Group\", \"head_type\": \"EVENT\", \"relation\": \"HELD_IN\", \"tail\": \"Memphis\", \"tail_type\": \"PLACE\"},\n",
      "    {\"head\": \"Retrieval Augmented Generation\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"TOPIC_OF_PRESENTATION\", \"tail\": \"Getting Started with Retrieval Augmented Generation\", \"tail_type\": \"PRESENTATION\"},\n",
      "    {\"head\": \"Memphis themed via Bing/create\", \"head_type\": \"\", \"relation\": \"UPDATED_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Presentation pdf\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"AVAILABLE_AT\", \"tail\": \"here\", \"tail_type\": \"URL\"},\n",
      "    {\"head\": \"Memphis Azure User Group\", \"head_type\": \"EVENT\", \"relation\": \"ATTENDED_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Sunday, May 19, 2024\", \"tail_type\": \"DATE\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Plugins Part 3\", \"head_type\": \"BLOG_POST\", \"relation\": \"MENTIONS\", \"tail\": \"OpenAI Function Calling\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"OpenAI Function Calling\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USES\", \"tail\": \"four API calls\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"USES\", \"tail\": \"Handlebars Planner\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"SHOWS\", \"tail\": \"request and response JSON\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"plan\", \"head_type\": \"ACTION\", \"relation\": \"CREATED_BY\", \"tail\": \"LLM\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"COVERS\", \"tail\": \"token usage comparison\", \"tail_type\": \"ACTION\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Monday, May 27, 2024\", \"tail_type\": \"EVENT_DATE\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"PART_OF\", \"tail\": \"Semantic Kernel Hello World Planners Part 2\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"WRITTEN\", \"tail\": \"Semantic Kernel Hello World Planners Part 1\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"WRITTEN\", \"tail\": \"Semantic Kernel Hello World Planners Part 3\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Handlebars planner\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USED_IN\", \"tail\": \"Semantic Kernel Hello World Planners Part 1\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Function Calling Stepwise Planner\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USED_IN\", \"tail\": \"Semantic Kernel Hello World Planners Part 2\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"token difference\", \"head_type\": \"CONCEPT\", \"relation\": \"DISCUSSED_IN\", \"tail\": \"Semantic Kernel Hello World Planners Part 1\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"sample Hello World functionality\", \"head_type\": \"CONCEPT\", \"relation\": \"IMPLEMENTED_IN\", \"tail\": \"Semantic Kernel Hello World Planners Part 1\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"saved plan\", \"head_type\": \"CONCEPT\", \"relation\": \"COMPARED_TO\", \"tail\": \"generating a plan\", \"tail_type\": \"CONCEPT\"},\n",
      "    {\"head\": \"sample Hello World functionality\", \"head_type\": \"CONCEPT\", \"relation\": \"IMPLEMENTED_IN\", \"tail\": \"Semantic Kernel Hello World Planners Part 2\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"COMPARED_TO\", \"tail\": \"Semantic Kernel Hello World Plugins Part 3\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Semantic Kernel\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USED_FOR\", \"tail\": \"creating sample Hello World functionality\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"AI\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"DISCUSSED_IN\", \"tail\": \"Semantic Kernel Hello World Planners Part 2\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Azure\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"DISCUSSED_IN\", \"tail\": \"Semantic Kernel Hello World Planners Part 2\", \"tail_type\": \"BLOG_POST\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "  {\"head\": \"Semantic Kernel Hello World WebSearchEnginePlugin\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "  {\"head\": \"Semantic Kernel Hello World WebSearchEnginePlugin\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Monday, June 10, 2024\", \"tail_type\": \"DATE\"},\n",
      "  {\"head\": \"Semantic Kernel Hello World WebSearchEnginePlugin\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Artificial Intelligence\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Semantic Kernel Hello World WebSearchEnginePlugin\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"ACTION\"},\n",
      "  {\"head\": \"Semantic Kernel Hello World WebSearchEnginePlugin\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Semantic Kernel Hello World WebSearchEnginePlugin\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Semantic Kernel Hello World WebSearchEnginePlugin\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"ACTIVITY\", \"tail\": \"getting in depth with Semantic Kernel\", \"tail_type\": \"ACTION\"},\n",
      "  {\"head\": \"Will Velida\", \"head_type\": \"PERSON\", \"relation\": \"AUTHORED_VIDEO\", \"tail\": \"Using Bing Search API in the Semantic Kernel SDK\", \"tail_type\": \"VIDEO\"},\n",
      "  {\"head\": \"Will Velida\", \"head_type\": \"PERSON\", \"relation\": \"EXPLAINED_USAGE\", \"tail\": \"Bing Search API\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "  {\"head\": \"Will Velida\", \"head_type\": \"PERSON\", \"relation\": \"EXPLAINED_USAGE\", \"tail\": \"Semantic Kernel SDK\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "  {\"head\": \"Bing Search API\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"USED_IN\", \"tail\": \"Semantic Kernel SDK\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "  {\"head\": \"semantic kernel\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"CONTAINS\", \"tail\": \"plugins\", \"tail_type\": \"FEATURE\"},\n",
      "  {\"head\": \"WebSearchEnginePlugin\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"PART_OF\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "  {\"head\": \"WebSearchEnginePlugin\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"USES\", \"tail\": \"Bing Search API\", \"tail_type\": \"SOFTWARE_SYSTEM\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Demo Review: Chat Copilot\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Demo Review: Chat Copilot\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Tuesday, June 18, 2024\", \"tail_type\": \"EVENT_DATE\"},\n",
      "    {\"head\": \"Demo Review: Chat Copilot\", \"head_type\": \"BLOG_POST\", \"relation\": \"HAS_TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Chat Copilot\", \"head_type\": \"BLOG_POST\", \"relation\": \"HAS_TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Chat Copilot\", \"head_type\": \"BLOG_POST\", \"relation\": \"HAS_TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Chat Copilot\", \"head_type\": \"BLOG_POST\", \"relation\": \"HAS_TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Chat Copilot\", \"head_type\": \"BLOG_POST\", \"relation\": \"HAS_TOPIC\", \"tail\": \"RAG Demo Series\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Chat Copilot\", \"head_type\": \"BLOG_POST\", \"relation\": \"HAS_TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Review: Chat Copilot\", \"head_type\": \"BLOG_POST\", \"relation\": \"HAS_TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"RAG Demo Chronicles\", \"head_type\": \"BLOG_POST\", \"relation\": \"PART_OF\", \"tail\": \"Blog Series\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"RAG Demo Chronicles\", \"head_type\": \"BLOG_POST\", \"relation\": \"HAS_TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"RAG Demo Chronicles\", \"head_type\": \"BLOG_POST\", \"relation\": \"IN_COMPETITION_WITH\", \"tail\": \"other demos\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Retrieval Augmented Generation\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"FEATURE_OF\", \"tail\": \"this demo\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"Retrieval Augmented Generation\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"DIFFERENT_FROM\", \"tail\": \"other demos\", \"tail_type\": \"SOFTWARE_SYSTEM\"},\n",
      "    {\"head\": \"MS Graph plugin\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"CONFIGURED_IN\", \"tail\": \"optional authentication\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"EXPERIENCED\", \"tail\": \"WOW\", \"tail_type\": \"REACTION\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Boston Azure June 2024\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Boston Azure June 2024\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Tuesday, June 25, 2024\", \"tail_type\": \"DATE\"},\n",
      "    {\"head\": \"Boston Azure June 2024\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Boston Azure June 2024\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"TOPIC\"},\n",
      "    {\"head\": \"Boston Azure June 2024\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Azure\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Boston Azure June 2024\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"RAG\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Boston Azure June 2024\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Boston Azure June 2024\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Season of AI presentation\", \"head_type\": \"PRESENTATION\", \"relation\": \"PART_OF\", \"tail\": \"Boston Azure June 2024\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Bill Wilder\", \"head_type\": \"PERSON\", \"relation\": \"PRESENTED_BY\", \"tail\": \"fundamentals of Generative AI\", \"tail_type\": \"TOPIC\"},\n",
      "    {\"head\": \"Bill Wilder\", \"head_type\": \"PERSON\", \"relation\": \"PRESENTED_BY\", \"tail\": \"quick introduction to Azure AI Studio\", \"tail_type\": \"TOPIC\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"PRESENTED_BY\", \"tail\": \".NET code walkthrough implementing Retrieval Augmented Generation (RAG)\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Retrieval Augmented Generation (RAG) implementation\", \"head_type\": \"ACTION\", \"relation\": \"USES\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Demo Code\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"LOCATED_IN\", \"tail\": \"GitHub repo BostonAzure-June2024\", \"tail_type\": \"PLACE\"},\n",
      "    {\"head\": \"Demo Code\", \"head_type\": \"SOFTWARE_SYSTEM\", \"relation\": \"SUBDIRECTORY_OF\", \"tail\": \"BostonAzure-June2024\", \"tail_type\": \"PLACE\"},\n",
      "    {\"head\": \"Presentation\", \"head_type\": \"EVENT\", \"relation\": \"ATTENDED_BY\", \"tail\": \"regular faces\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Presentation\", \"head_type\": \"EVENT\", \"relation\": \"ATTENDED_BY\", \"tail\": \"several new people\", \"tail_type\": \"PERSON\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Study Notes: Text-to-SQL\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL\", \"head_type\": \"BLOG_POST\", \"relation\": \"PUBLISHED_ON\", \"tail\": \"Friday, July 5, 2024\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL\", \"head_type\": \"BLOG_POST\", \"relation\": \"INCLUDES_TOPICS\", \"tail\": \"AI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL\", \"head_type\": \"BLOG_POST\", \"relation\": \"INCLUDES_TOPICS\", \"tail\": \"Learning\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL\", \"head_type\": \"BLOG_POST\", \"relation\": \"INCLUDES_TOPICS\", \"tail\": \"OpenAI\", \"tail_type\": \"ORGANIZATION\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL\", \"head_type\": \"BLOG_POST\", \"relation\": \"INCLUDES_TOPICS\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL\", \"head_type\": \"BLOG_POST\", \"relation\": \"INCLUDES_TOPICS\", \"tail\": \"Text-to-SQL\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL\", \"head_type\": \"BLOG_POST\", \"relation\": \"PART_OF\", \"tail\": \"Study Notes Series\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"RESEARCHED\", \"tail\": \"Text-to-SQL\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Text-to-SQL\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"ALSO_KNOWN_AS\", \"tail\": \"Natural Language to SQL\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL\", \"head_type\": \"BLOG_POST\", \"relation\": \"INCLUDES_CONTENT\", \"tail\": \"resources on Text-to-SQL\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Blog entry\", \"head_type\": \"BLOG_POST\", \"relation\": \"INCLUDES_CONTENT\", \"tail\": \"code example\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Text-to-SQL\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"OBJECTIVE\", \"tail\": \"LLM to generate SQL statements\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"LLM\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"GENERATES\", \"tail\": \"SQL statements\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"FOCUSES_ON\", \"tail\": \"extending usage scenarios in RAG application\", \"tail_type\": \"ACTION\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Study Notes: Text-to-SQL Code Sample\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL Code Sample\", \"head_type\": \"BLOG_POST\", \"relation\": \"POSTED_ON\", \"tail\": \"Saturday, July 6, 2024\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL Code Sample\", \"head_type\": \"BLOG_POST\", \"relation\": \"PART_OF\", \"tail\": \"Study Notes Series\", \"tail_type\": \"SERIES\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL Code Sample\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Artificial Intelligence\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL Code Sample\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Learning\", \"tail_type\": \"ACTION\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL Code Sample\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"OpenAI\", \"tail_type\": \"ORGANIZATION\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL Code Sample\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Semantic Kernel\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL Code Sample\", \"head_type\": \"BLOG_POST\", \"relation\": \"TOPIC\", \"tail\": \"Text-to-SQL\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"POSTED\", \"tail\": \"notes from this week’s study topic\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Text-to-SQL\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"INCLUDES\", \"tail\": \"resources\", \"tail_type\": \"RESOURCE\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL Code Sample\", \"head_type\": \"BLOG_POST\", \"relation\": \"INCLUDES\", \"tail\": \"code sample\", \"tail_type\": \"CODE\"},\n",
      "    {\"head\": \"code sample\", \"head_type\": \"CODE\", \"relation\": \"AVAILABLE_IN\", \"tail\": \"GitHub repo semantic-kernel-getting-started\", \"tail_type\": \"PLACE\"},\n",
      "    {\"head\": \"GitHub repo semantic-kernel-getting-started\", \"head_type\": \"PLACE\", \"relation\": \"INCLUDES\", \"tail\": \"samples/demos/Text-to-Sql\", \"tail_type\": \"DIRECTORY\"},\n",
      "    {\"head\": \"Study Notes: Text-to-SQL Code Sample\", \"head_type\": \"BLOG_POST\", \"relation\": \"CONTAINS\", \"tail\": \"NL2SQL code sample\", \"tail_type\": \"CODE\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"MODIFIED\", \"tail\": \"NL2SQL code sample\", \"tail_type\": \"CODE\"}\n",
      "]\n",
      "```\n",
      "Number of chunks: 22\n"
     ]
    }
   ],
   "source": [
    "ChatClient chatClient = client.GetChatClient(llm);\n",
    "string fileName = \"data/summaries.txt\";\n",
    "string fileText = File.ReadAllText(fileName);\n",
    "\n",
    "DocunentMetadata documentMetatdata = new (Guid.NewGuid().ToString(\"N\"), fileName);\n",
    "\n",
    "//var tokenizer = TiktokenTokenizer.CreateForModel(\"gpt-4o\");\n",
    "//#pragma warning disable SKEXP0050\n",
    "//var lines = TextChunker.SplitPlainTextLines(fileText, 500, text => tokenizer.CountTokens(text));\n",
    "//var paragraphs = TextChunker.SplitPlainTextParagraphs(lines, 500, 100, null, text => tokenizer.CountTokens(text));\n",
    "\n",
    "var simpleLines = File.ReadAllLines(documentMetatdata.source);\n",
    "var paragraphs = Utilities.SplitPlainTextOnEmptyLine(simpleLines);\n",
    "\n",
    "string entityTypes = \"BLOG_POST,PRESENTATION,EVENT,ORGANIZATION,PERSON,PLACE,TECHNOLOGY,SOFTWARE_SYSTEM,REVIEW,ACTION\";\n",
    "string relationTypes = \"WRITTEN_BY,PRESENTED_BY,PART_OF,LOCATED_IN,LIVES_IN,TRAVELED_TO\";\n",
    "\n",
    "Dictionary<ChunkMetadata, List<TripletRow>> chunks = new Dictionary<ChunkMetadata, List<TripletRow>>();\n",
    "int maxTripletsPerChunk = 20;\n",
    "string preamble = \"The given text document contains blog entry summaries with a Title, Author, Posted On date, Topics and Summary. Make sure to add the WRITTEN_BY relationship for the author.\";\n",
    "for (int i = 0; i < paragraphs.Count; i++)\n",
    "{\n",
    "    string text = paragraphs[i];\n",
    "\n",
    "    ChunkMetadata chunkMetadata = new (Guid.NewGuid().ToString(\"N\"), $\"DocumentChunk{i}\", i, documentMetatdata.id, text);\n",
    "\n",
    "\tstring prompt =  $@\"Please extract up to {maxTripletsPerChunk} knowledge triplets from the provied text.\n",
    "    {{$preamble}}\n",
    "    Each triplet should be in the form of (head, relation, tail) with their respective types.\n",
    "    ######################\n",
    "    ONTOLOGY:\n",
    "    Entity Types: {entityTypes}\n",
    "    Relation Types: {relationTypes}\n",
    "    \n",
    "    Use these entity types and relation types as a starting point, introduce new types if necessary based on the context.\n",
    "    \n",
    "    GUIDELINES:\n",
    "    - Output in JSON format: [{{\"\"head\"\": \"\"\"\", \"\"head_type\"\": \"\"\"\", \"\"relation\"\": \"\"\"\", \"\"tail\"\": \"\"\"\", \"\"tail_type\"\": \"\"\"\"}}]\n",
    "    - Use the full form for entities (ie., 'Artificial Intelligence' instead of 'AI')\n",
    "    - Keep entities and relation names concise (3-5 words max)\n",
    "    - Break down complex phrases into multiple triplets\n",
    "    - Ensure the knowledge graph is coherent and easily understandable\n",
    "    ######################\n",
    "    EXAMPLE:\n",
    "    Text: Jason Haley, chief engineer of Jason Haley Consulting, wrote a new blog post titled 'Study Notes: GraphRAG - Property Graphs' about creating a property graph RAG system using Semantic Kernel. \n",
    "    Output:\n",
    "    [{{\"\"head\"\": \"\"Jason Haley\"\", \"\"head_type\"\": \"\"PERSON\"\", \"\"relation\"\": \"\"WORKS_FOR\"\", \"\"tail\"\": \"\"Jason Haley Consulting\"\", \"\"tail_type\"\": \"\"COMPANY\"\"}},\n",
    "    {{\"\"head\"\": \"\"Study Notes: GraphRAG - Property Grids\"\", \"\"head_type\"\": \"\"BLOG_POST\"\", \"\"relation\"\": \"\"WRITTEN_BY\"\", \"\"tail\"\": \"\"Jason Haley\"\", \"\"tail_type\"\": \"\"PERSON\"\"}},\n",
    "    {{\"\"head\"\": \"\"Study Notes: GraphRAG - Property Grids\"\", \"\"head_type\"\": \"\"BLOG_POST\"\", \"\"relation\"\": \"\"TOPIC\"\", \"\"tail\"\": \"\"Semantic Kernel\"\", \"\"tail_type\"\": \"\"TECHNOLOGY\"\"}},\n",
    "    {{\"\"head\"\": \"\"property grid RAG system\"\", \"\"head_type\"\": \"\"SOFTWARE_SYSTEM\"\", \"\"relation\"\": \"\"USES\"\", \"\"tail\"\": \"\"Semantic Kernel\"\", \"\"tail_type\"\": \"\"TECHNOLOGY\"\"}}]\n",
    "    ######################\n",
    "    Text: {text}\n",
    "    ######################\n",
    "    Output:\";\n",
    "\n",
    "\tChatCompletion completion = chatClient.CompleteChat(\n",
    "    \t[\n",
    "        \tnew UserChatMessage(prompt),\n",
    "    \t]);\n",
    "\n",
    "\tConsole.WriteLine($\"{completion.Role}: {completion.Content[0].Text}\");\n",
    "    List<TripletRow> rows =  JsonSerializer.Deserialize<List<TripletRow>>(completion.Content[0].Text.Replace(\"```json\", \"\").Replace(\"```\",\"\").Replace(\"'\", \"\").Trim());\n",
    "    \n",
    "    chunks.Add(chunkMetadata, rows);\n",
    "}\n",
    "\n",
    "Console.WriteLine($\"Number of chunks: {chunks.Count}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop throug the LLM results and create a dictionary of the entitites. In order to create a relation from each entity to the document chunk it was extracted from we also keep a mentionedInChunk dictionary (this could be a 1 to many relationship)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique entity count: 234\r\n"
     ]
    }
   ],
   "source": [
    "Dictionary<string,EntityMetadata> entities = new Dictionary<string,EntityMetadata>();\n",
    "\n",
    "foreach (ChunkMetadata key in chunks.Keys)\n",
    "{\n",
    "    List<TripletRow> triplets = chunks[key];\n",
    "    foreach (var triplet in triplets)\n",
    "    {\n",
    "        EntityMetadata entity;\n",
    "        string pcHead = Utilities.CreateName(triplet.head);\n",
    "        if (entities.ContainsKey(pcHead)) \n",
    "        {\n",
    "            entity = entities[pcHead];\n",
    "            if (!entity.mentionedInChunks.ContainsKey(key.id))\n",
    "            {\n",
    "                entity.mentionedInChunks.Add(key.id, key);\n",
    "            }\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            entity = new EntityMetadata();   \n",
    "            entities.Add(pcHead, Utilities.PopulateEntityMetadata(key, triplet, entity, true));\n",
    "        }      \n",
    "\n",
    "        string pcTail = Utilities.CreateName(triplet.tail);\n",
    "        if (entities.ContainsKey(pcTail)) \n",
    "        {\n",
    "            entity = entities[pcTail];\n",
    "            if (!entity.mentionedInChunks.ContainsKey(key.id))\n",
    "            {\n",
    "                entity.mentionedInChunks.Add(key.id, key);\n",
    "            }\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            entity = new EntityMetadata();   \n",
    "            entities.Add(pcTail, Utilities.PopulateEntityMetadata(key, triplet, entity, false));\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "Console.WriteLine($\"Unique entity count: {entities.Count}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see the entities and list of which document chunks they were extracted from, you can run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personalupdatelearningai Mentioned In 1 chunks\n",
      "jason Mentioned In 22 chunks\n",
      "thursdayjanuary_18_2024 Mentioned In 1 chunks\n",
      "ai Mentioned In 19 chunks\n",
      "learning Mentioned In 22 chunks\n",
      "azure Mentioned In 19 chunks\n",
      "personalupdate Mentioned In 1 chunks\n",
      "makemoreblogposts Mentioned In 1 chunks\n",
      "learningai Mentioned In 1 chunks\n",
      "fourstagesofcompetence Mentioned In 1 chunks\n",
      "unconsciousincompetence Mentioned In 1 chunks\n",
      "consciousincompetence Mentioned In 1 chunks\n",
      "consciouscompetence Mentioned In 1 chunks\n",
      "unconsciouscompetence Mentioned In 1 chunks\n",
      "stage_2tostage_3 Mentioned In 1 chunks\n",
      "q1of_2024 Mentioned In 1 chunks\n",
      "movingfromstage_2tostage_3 Mentioned In 1 chunks\n",
      "_2023 Mentioned In 1 chunks\n",
      "movedfromstage_1tostage_2 Mentioned In 1 chunks\n",
      "industryleaders Mentioned In 1 chunks\n",
      "latestaitool Mentioned In 1 chunks\n",
      "chatgpt Mentioned In 1 chunks\n",
      "beginningoflastyear Mentioned In 1 chunks\n",
      "ragdemochronicles Mentioned In 2 chunks\n",
      "wednesdayfebruary_7_2024 Mentioned In 2 chunks\n",
      "rag Mentioned In 12 chunks\n",
      "ragdemoseries Mentioned In 8 chunks\n",
      "lastblogentry Mentioned In 1 chunks\n",
      "airelatedtopics Mentioned In 1 chunks\n",
      "newestresearchtopic Mentioned In 1 chunks\n",
      "learningaboutrag Mentioned In 1 chunks\n",
      "clients Mentioned In 1 chunks\n",
      "genai Mentioned In 2 chunks\n",
      "shortterm Mentioned In 1 chunks\n",
      "presentation Mentioned In 4 chunks\n",
      "howtochatwithyourdocuments Mentioned In 1 chunks\n",
      "blog Mentioned In 1 chunks\n",
      "demoreviewsimpleragusingsqlserverandopenai Mentioned In 1 chunks\n",
      "sqlserver Mentioned In 2 chunks\n",
      "openai Mentioned In 20 chunks\n",
      "fullstackcdeveloper Mentioned In 1 chunks\n",
      "relationaldatabasedeveloper Mentioned In 1 chunks\n",
      "vectordatabases Mentioned In 1 chunks\n",
      "functionality Mentioned In 1 chunks\n",
      "demoreviewsimpleragusingsqlserveropenaiandfunctioncalling Mentioned In 1 chunks\n",
      "sundayfebruary_11_2024 Mentioned In 1 chunks\n",
      "functioncalling Mentioned In 2 chunks\n",
      "michaelwashington Mentioned In 1 chunks\n",
      "demo Mentioned In 1 chunks\n",
      "fullstackdeveloper Mentioned In 1 chunks\n",
      "genaitechnologies Mentioned In 1 chunks\n",
      "businessapplications Mentioned In 1 chunks\n",
      "ragretrievalaugmentedgeneration Mentioned In 1 chunks\n",
      "step_1 Mentioned In 1 chunks\n",
      "step_2 Mentioned In 1 chunks\n",
      "step_3 Mentioned In 1 chunks\n",
      "step_4 Mentioned In 1 chunks\n",
      "demoreviewazuresearchopenaidemoc Mentioned In 1 chunks\n",
      "wednesdayfebruary_14_2024 Mentioned In 1 chunks\n",
      "semantickernel Mentioned In 13 chunks\n",
      "ragdemos Mentioned In 1 chunks\n",
      "azuresearch Mentioned In 1 chunks\n",
      "azureopenai Mentioned In 2 chunks\n",
      "github Mentioned In 2 chunks\n",
      "azuresearchopenaidemocsharp Mentioned In 1 chunks\n",
      "c Mentioned In 2 chunks\n",
      "azuresearchopenaidemo Mentioned In 1 chunks\n",
      "python Mentioned In 1 chunks\n",
      "azuresearchopenaijavascript Mentioned In 1 chunks\n",
      "javascripttypescript Mentioned In 1 chunks\n",
      "azuresearchopenaidemojava Mentioned In 1 chunks\n",
      "java Mentioned In 1 chunks\n",
      "demoreviewazuresearchopenaijavascripttypescript Mentioned In 1 chunks\n",
      "mondayfebruary_19_2024 Mentioned In 1 chunks\n",
      "langchain Mentioned In 1 chunks\n",
      "azuresearchopenaidemos Mentioned In 2 chunks\n",
      "azuresearchopenaijavascripttypescript Mentioned In 1 chunks\n",
      "cversion Mentioned In 1 chunks\n",
      "javascriptversion Mentioned In 1 chunks\n",
      "webcomponents Mentioned In 1 chunks\n",
      "webapplication Mentioned In 1 chunks\n",
      "react Mentioned In 1 chunks\n",
      "angular Mentioned In 1 chunks\n",
      "demoreviewazuresearchopenaidemopython Mentioned In 1 chunks\n",
      "fridayfebruary_23_2024 Mentioned In 1 chunks\n",
      "cversionofazuresearchopenaidemos Mentioned In 1 chunks\n",
      "javascripttypescriptversionofazuresearchopenaidemos Mentioned In 1 chunks\n",
      "azuresearchopenaidemopython Mentioned In 1 chunks\n",
      "mostactive Mentioned In 1 chunks\n",
      "mostpopular Mentioned In 1 chunks\n",
      "mostdocumentation Mentioned In 1 chunks\n",
      "hacktogethertheaichatapphack Mentioned In 1 chunks\n",
      "february_2024 Mentioned In 1 chunks\n",
      "solidreferenceimplementationforrag Mentioned In 1 chunks\n",
      "demoreviewazurevectorsearchaiassistant Mentioned In 1 chunks\n",
      "mondayfebruary_26_2024 Mentioned In 1 chunks\n",
      "theragdemochronicles Mentioned In 1 chunks\n",
      "fourthcdemo Mentioned In 1 chunks\n",
      "saveshistorytodatabase Mentioned In 1 chunks\n",
      "ragdemo Mentioned In 1 chunks\n",
      "datafromdatabase Mentioned In 1 chunks\n",
      "bostoncodecamp_36 Mentioned In 1 chunks\n",
      "bostoncodecamp_36sessions Mentioned In 1 chunks\n",
      "sundaymarch_24_2024 Mentioned In 1 chunks\n",
      "bostontechcommunity Mentioned In 1 chunks\n",
      "_20years Mentioned In 1 chunks\n",
      "developers Mentioned In 1 chunks\n",
      "students Mentioned In 1 chunks\n",
      "architects Mentioned In 1 chunks\n",
      "talkgettingstartedwithretrievalaugmentedgenerationrag Mentioned In 1 chunks\n",
      "fullroom Mentioned In 1 chunks\n",
      "semantickernelhelloworld Mentioned In 1 chunks\n",
      "saturdaymarch_30_2024 Mentioned In 1 chunks\n",
      "virtualbostonazuremeetup Mentioned In 1 chunks\n",
      "thursdaynight Mentioned In 1 chunks\n",
      "billwilder Mentioned In 2 chunks\n",
      "aiminiworkshop Mentioned In 1 chunks\n",
      "boston Mentioned In 2 chunks\n",
      "handsonwithcode Mentioned In 1 chunks\n",
      "azureopenaiapi Mentioned In 1 chunks\n",
      "openaichathelloworldc Mentioned In 1 chunks\n",
      "bill Mentioned In 1 chunks\n",
      "openaichat Mentioned In 1 chunks\n",
      "semantickernelhelloworldpluginspart_1 Mentioned In 1 chunks\n",
      "thursdayapril_11_2024 Mentioned In 1 chunks\n",
      "helloworldapplicationwithsemantickernel Mentioned In 1 chunks\n",
      "mslearningpathapl_2005 Mentioned In 1 chunks\n",
      "semantickernelsdk Mentioned In 2 chunks\n",
      "lastentry Mentioned In 1 chunks\n",
      "helloworldapplication Mentioned In 1 chunks\n",
      "prompt Mentioned In 1 chunks\n",
      "plugin Mentioned In 1 chunks\n",
      "mysessionatbostonglobalazurebootcamp Mentioned In 1 chunks\n",
      "tuesdayapril_23_2024 Mentioned In 1 chunks\n",
      "bostonazureseditionoftheannualglobalazurebootcamp Mentioned In 1 chunks\n",
      "annualglobalazurebootcamp Mentioned In 1 chunks\n",
      "handsonlabs Mentioned In 1 chunks\n",
      "meetup Mentioned In 1 chunks\n",
      "people Mentioned In 1 chunks\n",
      "group Mentioned In 1 chunks\n",
      "members Mentioned In 1 chunks\n",
      "semantickernelhelloworldpluginspart_2 Mentioned In 1 chunks\n",
      "fridayapril_26_2024 Mentioned In 1 chunks\n",
      "part_1 Mentioned In 1 chunks\n",
      "prompttemplate Mentioned In 1 chunks\n",
      "nativefunction Mentioned In 1 chunks\n",
      "currentdate Mentioned In 2 chunks\n",
      "llm Mentioned In 3 chunks\n",
      "helloworldplugin2consoleproject Mentioned In 1 chunks\n",
      "semantickernelgettingstarted Mentioned In 1 chunks\n",
      "microsoftlearnmodule Mentioned In 1 chunks\n",
      "giveyouraiagentskills Mentioned In 1 chunks\n",
      "microsoft Mentioned In 1 chunks\n",
      "semantickernelhelloworldpluginspart_3 Mentioned In 3 chunks\n",
      "tuesdayapril_30_2024 Mentioned In 1 chunks\n",
      "artificialintelligence Mentioned In 3 chunks\n",
      "part_2 Mentioned In 1 chunks\n",
      "creationofnativefunctionplugin Mentioned In 1 chunks\n",
      "openaifunctioncalling Mentioned In 2 chunks\n",
      "helloworldplugin3consoleproject Mentioned In 1 chunks\n",
      "nativefunctionplugin Mentioned In 1 chunks\n",
      "memphisazureusergroup Mentioned In 1 chunks\n",
      "tuesdaymay_7_2024 Mentioned In 1 chunks\n",
      "gettingstartedwithretrievalaugmentedgeneration Mentioned In 1 chunks\n",
      "memphisthemedviabingcreate Mentioned In 1 chunks\n",
      "hybrid Mentioned In 1 chunks\n",
      "lastthursdaynight Mentioned In 1 chunks\n",
      "memphis Mentioned In 1 chunks\n",
      "retrievalaugmentedgeneration Mentioned In 2 chunks\n",
      "presentationpdf Mentioned In 1 chunks\n",
      "here Mentioned In 1 chunks\n",
      "semantickernelhelloworldplannerspart_1 Mentioned In 2 chunks\n",
      "sundaymay_19_2024 Mentioned In 1 chunks\n",
      "fourapicalls Mentioned In 1 chunks\n",
      "handlebarsplanner Mentioned In 2 chunks\n",
      "requestandresponsejson Mentioned In 1 chunks\n",
      "plan Mentioned In 1 chunks\n",
      "tokenusagecomparison Mentioned In 1 chunks\n",
      "semantickernelhelloworldplannerspart_2 Mentioned In 1 chunks\n",
      "mondaymay_27_2024 Mentioned In 1 chunks\n",
      "semantickernelhelloworldplannerspart_3 Mentioned In 1 chunks\n",
      "functioncallingstepwiseplanner Mentioned In 1 chunks\n",
      "tokendifference Mentioned In 1 chunks\n",
      "samplehelloworldfunctionality Mentioned In 1 chunks\n",
      "savedplan Mentioned In 1 chunks\n",
      "generatingaplan Mentioned In 1 chunks\n",
      "creatingsamplehelloworldfunctionality Mentioned In 1 chunks\n",
      "semantickernelhelloworldwebsearchengineplugin Mentioned In 1 chunks\n",
      "mondayjune_10_2024 Mentioned In 1 chunks\n",
      "gettingindepthwithsemantickernel Mentioned In 1 chunks\n",
      "willvelida Mentioned In 1 chunks\n",
      "usingbingsearchapiinthesemantickernelsdk Mentioned In 1 chunks\n",
      "bingsearchapi Mentioned In 1 chunks\n",
      "plugins Mentioned In 1 chunks\n",
      "websearchengineplugin Mentioned In 1 chunks\n",
      "demoreviewchatcopilot Mentioned In 1 chunks\n",
      "tuesdayjune_18_2024 Mentioned In 1 chunks\n",
      "blogseries Mentioned In 1 chunks\n",
      "otherdemos Mentioned In 1 chunks\n",
      "thisdemo Mentioned In 1 chunks\n",
      "msgraphplugin Mentioned In 1 chunks\n",
      "optionalauthentication Mentioned In 1 chunks\n",
      "wow Mentioned In 1 chunks\n",
      "bostonazurejune_2024 Mentioned In 1 chunks\n",
      "tuesdayjune_25_2024 Mentioned In 1 chunks\n",
      "seasonofaipresentation Mentioned In 1 chunks\n",
      "fundamentalsofgenerativeai Mentioned In 1 chunks\n",
      "quickintroductiontoazureaistudio Mentioned In 1 chunks\n",
      "netcodewalkthroughimplementingretrievalaugmentedgenerationrag Mentioned In 1 chunks\n",
      "retrievalaugmentedgenerationragimplementation Mentioned In 1 chunks\n",
      "democode Mentioned In 1 chunks\n",
      "githubrepobostonazurejune2024 Mentioned In 1 chunks\n",
      "bostonazurejune2024 Mentioned In 1 chunks\n",
      "regularfaces Mentioned In 1 chunks\n",
      "severalnewpeople Mentioned In 1 chunks\n",
      "studynotestexttosql Mentioned In 1 chunks\n",
      "fridayjuly_5_2024 Mentioned In 1 chunks\n",
      "texttosql Mentioned In 2 chunks\n",
      "studynotesseries Mentioned In 2 chunks\n",
      "naturallanguagetosql Mentioned In 1 chunks\n",
      "resourcesontexttosql Mentioned In 1 chunks\n",
      "blogentry Mentioned In 1 chunks\n",
      "codeexample Mentioned In 1 chunks\n",
      "llmtogeneratesqlstatements Mentioned In 1 chunks\n",
      "sqlstatements Mentioned In 1 chunks\n",
      "extendingusagescenariosinragapplication Mentioned In 1 chunks\n",
      "studynotestexttosqlcodesample Mentioned In 1 chunks\n",
      "saturdayjuly_6_2024 Mentioned In 1 chunks\n",
      "notesfromthisweeksstudytopic Mentioned In 1 chunks\n",
      "resources Mentioned In 1 chunks\n",
      "codesample Mentioned In 1 chunks\n",
      "githubreposemantickernelgettingstarted Mentioned In 1 chunks\n",
      "samplesdemostexttosql Mentioned In 1 chunks\n",
      "nl2sqlcodesample Mentioned In 1 chunks\n"
     ]
    }
   ],
   "source": [
    "foreach(var key in entities.Keys)\n",
    "{\n",
    "    var e = entities[key];\n",
    "    Console.WriteLine($\"{key} Mentioned In {e.mentionedInChunks.Count} chunks\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is all about generatint the cypher to populate the entities extracted by the LLM into Neo4j.\n",
    "\n",
    "> NOTE: If you are using a different graph database, this is the first step you'll probably need to start changing things\n",
    "\n",
    "The results of this step look something like this:\n",
    "```cypher\n",
    "MERGE (Document1:DOCUMENT { id: '54e9916c99ef4459ae8eabb227a5c341', name:'Document1', type:'DOCUMENT', source: 'data/summaries.txt'})\n",
    "MERGE (DocumentChunk0:DOCUMENT_CHUNK { id: '8dcf15992ced4c8ba77e9dd6f9372241', name: 'DocumentChunk0', type: 'DOCUMENT_CHUNK', documentId: '54e9916c99ef4459ae8eabb227a5c341', sequence: '0', text: \"Title:\t\t(Personal Update) Learning AI\n",
    "Author:\t\tJason \n",
    "Posted On:\tThursday, January 18, 2024\n",
    "Topics:\t\tAI, Learning, Azure, Personal Update\n",
    "Summary:\tThis is the first of many blog posts I plan to make this year, stay tuned (please subscribe) for more soon. Learning AI Currently I am working my way through the four stages of competence with the topic of AI. This quarter (Q1 of 2024), I’m currently working on moving from stage 2 to stage 3 in the four stages of competence. For reference, those stages are: Unconscious incompetence Conscious incompetence Conscious competence Unconscious competence Last year I moved from stage 1 to stage 2: In the beginning of last year (2023) I had my head buried in the sand while all the other leaders in my industry were actively learning how to use the latest and greatest AI tool (ChatGPT).\n",
    "\n",
    "Title:\t\tRAG Demo Chronicles Author:\t\tJason\n",
    "Posted On:\tWednesday, February 7, 2024\n",
    "Topics:\t\tAI, Learning, RAG, RAG Demo Series\n",
    "\"})\n",
    "MERGE (learningai:ENTITY { name: 'learningai', type: 'BLOG_POST', id: '1226ef1f38a04c05b13f1f794089cd3e', text: 'Learning AI'})\n",
    "MERGE (learningai)-[:MENTIONED_IN]->(DocumentChunk0)\n",
    "MERGE (jason:ENTITY { name: 'jason', type: 'PERSON', id: '16b00aa6e21e4f30a3ed9577bbf65aba', text: 'Jason'})\n",
    "MERGE (jason)-[:MENTIONED_IN]->(DocumentChunk0)\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "List<string> entityCypherText = new List<string>(); // Document, DocumentChunk and Entity\n",
    "\n",
    "entityCypherText.Add($\"MERGE (Document1:DOCUMENT {{ id: '{documentMetatdata.id}', name:'Document1', type:'DOCUMENT', source: '{documentMetatdata.source}'}})\"); \n",
    "\n",
    "foreach (var chunk in chunks.Keys)\n",
    "{\n",
    "    entityCypherText.Add($\"MERGE (DocumentChunk{chunk.sequence}:DOCUMENT_CHUNK {{ id: '{chunk.id}', name: '{chunk.name}', type: 'DOCUMENT_CHUNK', documentId: '{chunk.documentId}', sequence: '{chunk.sequence}', text: \\\"{chunk.text.Replace(\"\\\"\", \"'\")}\\\"}})\");\n",
    "    entityCypherText.Add($\"MERGE (Document1)-[:CONTAINS]->(DocumentChunk{chunk.sequence})\");\n",
    "}\n",
    "\n",
    "HashSet<string> types = new HashSet<string>();\n",
    "foreach(var entity in entities.Keys)\n",
    "{\n",
    "    var labels = entities[entity];\n",
    "    var pcEntity = entity;\n",
    "    entityCypherText.Add($\"MERGE ({pcEntity}:ENTITY {{ name: '{pcEntity}', type: '{labels.type}', id: '{labels.id}', text: '{labels.text}'}})\");\n",
    "\n",
    "    if (!types.Contains(labels.type))\n",
    "    {\n",
    "        types.Add(labels.type);\n",
    "    }\n",
    "\n",
    "    foreach(var key in labels.mentionedInChunks.Keys)\n",
    "    {\n",
    "        var documentChunk = labels.mentionedInChunks[key];\n",
    "        entityCypherText.Add($\"MERGE ({pcEntity})-[:MENTIONED_IN]->(DocumentChunk{documentChunk.sequence})\");\n",
    "    }\n",
    "}\n",
    "\n",
    "HashSet<string> relationships = new HashSet<string>();\n",
    "foreach (ChunkMetadata key in chunks.Keys)\n",
    "{\n",
    "    List<TripletRow> triplets = chunks[key];\n",
    "    foreach (var triplet in triplets)\n",
    "    {\n",
    "        var pcHead = Utilities.CreateName(triplet.head);\n",
    "        var pcTail = Utilities.CreateName(triplet.tail);\n",
    "        entityCypherText.Add($\"MERGE ({pcHead})-[:{triplet.relation.Replace(\" \", \"_\").Replace(\"-\",\"_\")}]->({pcTail})\");\n",
    "\n",
    "        string headRelationship = $\"MERGE (DocumentChunk{key.sequence})-[:MENTIONS]->({pcHead})\";\n",
    "        if (!relationships.Contains(headRelationship))\n",
    "        {\n",
    "            relationships.Add(headRelationship);\n",
    "            entityCypherText.Add(headRelationship);\n",
    "        }\n",
    "        \n",
    "        string tailRelationship = $\"MERGE (DocumentChunk{key.sequence})-[:MENTIONS]->({pcTail})\";\n",
    "        if (!relationships.Contains(tailRelationship))\n",
    "        {\n",
    "            relationships.Add(tailRelationship);\n",
    "            entityCypherText.Add(tailRelationship);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see all the cypher youc an run this next block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "foreach(var t in entityCypherText)\n",
    "{\n",
    "    Console.WriteLine(t);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see the unique list of entity types you can run this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "foreach(var t in types)\n",
    "{\n",
    "    Console.WriteLine(t);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the graph db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If for some reason you need to debug the cypher text being passed to Neo4j, run this next block to see what the contents are. I had to debug some characters and duplicates getting through the logic when testing. I fixed the bugs I found, but there may be more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1426\r\n"
     ]
    }
   ],
   "source": [
    "Console.WriteLine(entityCypherText.ToArray().Length);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate Neo4j with the generated cypher text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "using (var session = driver.AsyncSession())\n",
    "{\n",
    "    StringBuilder all = new StringBuilder();\n",
    "    all.AppendJoin(Environment.NewLine, entityCypherText.ToArray());\n",
    "    await driver.ExecutableQuery(all.ToString()).WithConfig(config).ExecuteAsync();\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have enabled two plugins to Neo4j: GenAI, which you'll need for some of the following used features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vector index on the DOCUMENT_CHUNK embedding field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string createVectorIndex = @\"CREATE VECTOR INDEX CHUNK_EMBEDDING IF NOT EXISTS\n",
    "                            FOR (c:DOCUMENT_CHUNK) ON c.embedding\n",
    "                            OPTIONS {indexConfig: {\n",
    "                           `vector.dimensions`: 1536,\n",
    "                            `vector.similarity_function`: 'cosine'\n",
    "                            }}\";\n",
    "\n",
    "await driver.ExecutableQuery(createVectorIndex).WithConfig(config).ExecuteAsync();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate the Vector index using the DOCUMENT_CHUNK text field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string populateEmbeddings = $@\"\n",
    "                            MATCH (n:DOCUMENT_CHUNK) WHERE n.text IS NOT NULL\n",
    "                            WITH n, genai.vector.encode(\n",
    "                                n.text,\n",
    "                                'AzureOpenAI',\n",
    "                                {{\n",
    "                                    token: $token,\n",
    "                                    resource: $resource,\n",
    "                                    deployment: $deployment\n",
    "                                }}) AS vector\n",
    "                            CALL db.create.setNodeVectorProperty(n, 'embedding', vector)\n",
    "                            \";\n",
    "await driver.ExecutableQuery(populateEmbeddings)\n",
    "    .WithParameters(new() { \n",
    "        {\"token\", envVars[\"AZURE_OPENAI_API_KEY\"]}, \n",
    "        {\"resource\", envVars[\"AZURE_OPENAI_RESOURCE\"]}, \n",
    "        {\"deployment\", envVars[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"]}})\n",
    "    .WithConfig(config)\n",
    "    .ExecuteAsync();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string createEntityVectorIndex = @\"CREATE VECTOR INDEX TEXT_EMBEDDING IF NOT EXISTS\n",
    "                                    FOR (e:ENTITY) ON e.embedding\n",
    "                                    OPTIONS {indexConfig: {\n",
    "                                        `vector.dimensions`: 1536,\n",
    "                                        `vector.similarity_function`: 'cosine'\n",
    "                                    }}\";\n",
    "\n",
    "await driver.ExecutableQuery(createEntityVectorIndex).WithConfig(config).ExecuteAsync();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string populateEntittyEmbeddings = $@\"\n",
    "                            MATCH (n:ENTITY) WHERE n.text IS NOT NULL\n",
    "                            WITH n, genai.vector.encode(\n",
    "                                n.text,\n",
    "                                'AzureOpenAI',\n",
    "                                {{\n",
    "                                    token: $token,\n",
    "                                    resource: $resource,\n",
    "                                    deployment: $deployment\n",
    "                                }}) AS vector\n",
    "                            CALL db.create.setNodeVectorProperty(n, 'embedding', vector)\n",
    "                            \";\n",
    "await driver.ExecutableQuery(populateEntittyEmbeddings)\n",
    "    .WithParameters(new() { \n",
    "        {\"token\", envVars[\"AZURE_OPENAI_API_KEY\"]}, \n",
    "        {\"resource\", envVars[\"AZURE_OPENAI_RESOURCE\"]}, \n",
    "        {\"deployment\", envVars[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"]}})\n",
    "    .WithConfig(config)\n",
    "    .ExecuteAsync();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a full text index on the entity's text field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "string createFulltextIndex = @\"CREATE FULLTEXT INDEX ENTITY_TEXT IF NOT EXISTS \n",
    "                                FOR (n:ENTITY) ON EACH [n.text]\";\n",
    "await driver.ExecutableQuery(createFulltextIndex).WithConfig(config).ExecuteAsync();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you open the Neo4j Browser for you database and run this command, you should see the entities and relationships:\n",
    "\n",
    "```cypher\n",
    "MATCH (n) RETURN (n)\n",
    "```\n",
    "\n",
    "![Summaries.txt Entities and Relations](.\\images\\summaries-entities-relations.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "Now that we have a graph database populated, we get to decide what sort of retrieval steps we want to include to provide usefal graph data to the RAG workflow.\n",
    "\n",
    "This notebook uses these steps:\n",
    "1. Capture the user's input\n",
    "2. Make a call to the LLM to get 10 keywords or synonyms from the user's request\n",
    "3. Loop through those keyworkds and perform a full text search on the entity's text field and get related entities for the matches found.\n",
    "4. Deduplicate the entities found in step 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "//string questionText = \"what are the blog post titles that are about Semantic Kernel?\";\n",
    "string questionText = \"How many blog post did Jason write about Semantic Kernel and what are their titles?\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonym extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Semantic Kernel\r\n"
     ]
    }
   ],
   "source": [
    "ChatClient chatClient = client.GetChatClient(\"chat\");\n",
    "\n",
    "int maxSynonyms = 10;\n",
    "string prompt = $@\"\n",
    "Given a user question, pick or use 1 to 3 words to create a keyword to capture what the user is asking for'.\n",
    "\n",
    "QUERY: {questionText}\n",
    "######################\n",
    "KEYWORDS:\n",
    "\";\n",
    "ChatCompletion completion = chatClient.CompleteChat(\n",
    "    [\n",
    "        new UserChatMessage(prompt),\n",
    "    ]);\n",
    "\n",
    "Console.WriteLine($\"{completion.Role}: {completion.Content[0].Text}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just one approach to getting additional information from the graph. In this case we do a full text search on the entity text to locate what should be relevant entities in the graph - **then we get their related entities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "public record FulltextResult(string text, double score);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Kernel\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World) 2.9473254680633545\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Plugins Part 3) 2.9473254680633545\n",
      "(Semantic Kernel)-[:HAS_TOPIC]->(Demo Review: Chat Copilot) 2.9473254680633545\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Plugins Part 2) 2.9473254680633545\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Plugins Part 1) 2.9473254680633545\n",
      "(Semantic Kernel)-[:USED_FOR]->(creating sample Hello World functionality) 2.9473254680633545\n",
      "(Semantic Kernel)-[:TOPIC]->(Demo Review: Azure Vector Search AI Assistant) 2.9473254680633545\n",
      "(Semantic Kernel)-[:TOPIC]->(Boston Azure June 2024) 2.9473254680633545\n",
      "(Semantic Kernel)-[:CONTAINS]->(plugins) 2.9473254680633545\n",
      "(Semantic Kernel)-[:TOPIC]->(Demo Review: Azure Search OpenAI Demo C#) 2.9473254680633545\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World WebSearchEnginePlugin) 2.9473254680633545\n",
      "(Semantic Kernel)-[:TOPIC]->(Study Notes: Text-to-SQL Code Sample) 2.9473254680633545\n",
      "(Semantic Kernel)-[:USES]->(RAG demo) 2.9473254680633545\n",
      "(Semantic Kernel)-[:INCLUDES_TOPICS]->(Study Notes: Text-to-SQL) 2.9473254680633545\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Planners Part 1) 2.9473254680633545\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Planners Part 2) 2.9473254680633545\n",
      "(Semantic Kernel)-[:USES]->(Retrieval Augmented Generation (RAG) implementation) 2.9473254680633545\n",
      "(Semantic Kernel)-[:HAS_TOPIC]->(RAG Demo Chronicles) 2.9473254680633545\n",
      "(Semantic Kernel)-[:PART_OF]->(WebSearchEnginePlugin) 2.9473254680633545\n",
      "(Semantic Kernel SDK)-[:EXPLAINED_USAGE]->(Will Velida) 2.568082332611084\n",
      "(Semantic Kernel SDK)-[:USED_IN]->(Bing Search API) 2.568082332611084\n",
      "(Semantic Kernel SDK)-[:USES]->(MS Learning path: APL-2005) 2.568082332611084\n",
      "(Semantic Kernel Hello World)-[:TOPIC]->(Semantic Kernel) 2.2753102779388428\n",
      "(Semantic Kernel Hello World)-[:TOPIC]->(AI) 2.2753102779388428\n",
      "(Semantic Kernel Hello World)-[:WRITTEN_BY]->(Jason) 2.2753102779388428\n",
      "(Semantic Kernel Hello World)-[:TOPIC]->(Azure) 2.2753102779388428\n",
      "(Semantic Kernel Hello World)-[:TOPIC]->(OpenAI) 2.2753102779388428\n",
      "(Semantic Kernel Hello World)-[:PUBLISHED_ON]->(Saturday, March 30, 2024) 2.2753102779388428\n",
      "(Semantic Kernel Hello World)-[:TOPIC]->(Learning) 2.2753102779388428\n",
      "(semantic-kernel-getting-started)-[:CONTAINS]->(HelloWorld.Plugin2.Console project) 2.2753102779388428\n",
      "(semantic-kernel-getting-started)-[:PART_OF_REPO]->(HelloWorld.Plugin2.Console project) 2.2753102779388428\n",
      "(Semantic Kernel Hello World WebSearchEnginePlugin)-[:WRITTEN_BY]->(Jason) 2.0424611568450928\n",
      "(Semantic Kernel Hello World WebSearchEnginePlugin)-[:TOPIC]->(Artificial Intelligence) 2.0424611568450928\n",
      "(Semantic Kernel Hello World WebSearchEnginePlugin)-[:TOPIC]->(Azure) 2.0424611568450928\n",
      "(Semantic Kernel Hello World WebSearchEnginePlugin)-[:POSTED_ON]->(Monday, June 10, 2024) 2.0424611568450928\n",
      "(Semantic Kernel Hello World WebSearchEnginePlugin)-[:TOPIC]->(OpenAI) 2.0424611568450928\n",
      "(Semantic Kernel Hello World WebSearchEnginePlugin)-[:TOPIC]->(Semantic Kernel) 2.0424611568450928\n",
      "(Semantic Kernel Hello World WebSearchEnginePlugin)-[:TOPIC]->(Learning) 2.0424611568450928\n",
      "(Hello World application with Semantic Kernel)-[:WROTE]->(Jason) 1.8528456687927246\n",
      "(getting in depth with Semantic Kernel)-[:ACTIVITY]->(Jason) 1.8528456687927246\n",
      "(GitHub repo semantic-kernel-getting-started)-[:INCLUDES]->(samples/demos/Text-to-Sql) 1.8528456687927246\n",
      "(GitHub repo semantic-kernel-getting-started)-[:AVAILABLE_IN]->(code sample) 1.8528456687927246\n",
      "(Semantic Kernel Hello World Plugins Part 1)-[:WRITTEN_BY]->(Jason) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 1)-[:TOPIC]->(Semantic Kernel) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 1)-[:TOPIC]->(AI) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 1)-[:POSTED_ON]->(Thursday, April 11, 2024) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 1)-[:TOPIC]->(Azure) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 1)-[:PART_OF]->(last entry) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 1)-[:TOPIC]->(Learning) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 1)-[:TOPIC]->(OpenAI) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 3)-[:WRITTEN]->(Jason) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 2)-[:DISCUSSED_IN]->(native function) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 2)-[:TOPIC]->(Azure) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 2)-[:TOPIC]->(Semantic Kernel) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 2)-[:TOPIC]->(AI) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 2)-[:TOPIC]->(Learning) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 2)-[:PREVIOUS_PART_OF]->(Part 1) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 2)-[:CONTAINS_CODE_FOR]->(HelloWorld.Plugin2.Console project) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 2)-[:POSTED_ON]->(Friday, April 26, 2024) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 2)-[:WRITTEN_BY]->(Jason) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 2)-[:TOPIC]->(OpenAI) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 3)-[:USING_TECHNOLOGY]->(OpenAI Function calling) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 3)-[:COMPARED_TO]->(Semantic Kernel Hello World Planners Part 2) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 3)-[:TOPIC]->(Semantic Kernel) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 3)-[:TOPIC]->(OpenAI) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 3)-[:WRITTEN_BY]->(Jason) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 3)-[:TOPIC]->(Azure) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 3)-[:MENTIONS]->(OpenAI Function calling) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 3)-[:CONTAINS_CODE_FOR]->(HelloWorld.Plugin3.Console project) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 3)-[:TOPIC]->(Learning) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 3)-[:POSTED_ON]->(Tuesday, April 30, 2024) 1.695446252822876\n",
      "(Semantic Kernel Hello World Plugins Part 3)-[:TOPIC]->(Artificial Intelligence) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:USES]->(Handlebars Planner) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:USED_IN]->(Handlebars Planner) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:TOPIC]->(OpenAI) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:COVERS]->(token usage comparison) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:TOPIC]->(Learning) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:PART_OF]->(Semantic Kernel Hello World Planners Part 2) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:DISCUSSED_IN]->(token difference) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:WRITTEN_BY]->(Jason) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:WRITTEN]->(Jason) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:IMPLEMENTED_IN]->(sample Hello World functionality) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:POSTED_ON]->(Sunday, May 19, 2024) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:TOPIC]->(Azure) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:TOPIC]->(Semantic Kernel) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 1)-[:TOPIC]->(AI) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:COMPARED_TO]->(Semantic Kernel Hello World Plugins Part 3) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:IMPLEMENTED_IN]->(sample Hello World functionality) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:WRITTEN_BY]->(Jason) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:USED_IN]->(Function Calling Stepwise Planner) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:TOPIC]->(OpenAI) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:DISCUSSED_IN]->(Azure) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:DISCUSSED_IN]->(AI) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:PART_OF]->(Semantic Kernel Hello World Planners Part 1) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:TOPIC]->(Azure) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:TOPIC]->(Learning) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:TOPIC]->(AI) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:TOPIC]->(Semantic Kernel) 1.695446252822876\n",
      "(Semantic Kernel Hello World Planners Part 2)-[:POSTED_ON]->(Monday, May 27, 2024) 1.695446252822876\n",
      "(Using Bing Search API in the Semantic Kernel SDK)-[:AUTHORED_VIDEO]->(Will Velida) 1.4492225646972656\n",
      "\n",
      "100 Unique nodes with matches:\n",
      "FulltextResult { text = (Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Plugins Part 3), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:HAS_TOPIC]->(Demo Review: Chat Copilot), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Plugins Part 2), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Plugins Part 1), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:USED_FOR]->(creating sample Hello World functionality), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:TOPIC]->(Demo Review: Azure Vector Search AI Assistant), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:TOPIC]->(Boston Azure June 2024), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:CONTAINS]->(plugins), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:TOPIC]->(Demo Review: Azure Search OpenAI Demo C#), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World WebSearchEnginePlugin), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:TOPIC]->(Study Notes: Text-to-SQL Code Sample), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:USES]->(RAG demo), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:INCLUDES_TOPICS]->(Study Notes: Text-to-SQL), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Planners Part 1), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Planners Part 2), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:USES]->(Retrieval Augmented Generation (RAG) implementation), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:HAS_TOPIC]->(RAG Demo Chronicles), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel)-[:PART_OF]->(WebSearchEnginePlugin), score = 2.9473254680633545 }\n",
      "FulltextResult { text = (Semantic Kernel SDK)-[:EXPLAINED_USAGE]->(Will Velida), score = 2.568082332611084 }\n",
      "FulltextResult { text = (Semantic Kernel SDK)-[:USED_IN]->(Bing Search API), score = 2.568082332611084 }\n",
      "FulltextResult { text = (Semantic Kernel SDK)-[:USES]->(MS Learning path: APL-2005), score = 2.568082332611084 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World)-[:TOPIC]->(Semantic Kernel), score = 2.2753102779388428 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World)-[:TOPIC]->(AI), score = 2.2753102779388428 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World)-[:WRITTEN_BY]->(Jason), score = 2.2753102779388428 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World)-[:TOPIC]->(Azure), score = 2.2753102779388428 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World)-[:TOPIC]->(OpenAI), score = 2.2753102779388428 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World)-[:PUBLISHED_ON]->(Saturday, March 30, 2024), score = 2.2753102779388428 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World)-[:TOPIC]->(Learning), score = 2.2753102779388428 }\n",
      "FulltextResult { text = (semantic-kernel-getting-started)-[:CONTAINS]->(HelloWorld.Plugin2.Console project), score = 2.2753102779388428 }\n",
      "FulltextResult { text = (semantic-kernel-getting-started)-[:PART_OF_REPO]->(HelloWorld.Plugin2.Console project), score = 2.2753102779388428 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World WebSearchEnginePlugin)-[:WRITTEN_BY]->(Jason), score = 2.0424611568450928 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World WebSearchEnginePlugin)-[:TOPIC]->(Artificial Intelligence), score = 2.0424611568450928 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World WebSearchEnginePlugin)-[:TOPIC]->(Azure), score = 2.0424611568450928 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World WebSearchEnginePlugin)-[:POSTED_ON]->(Monday, June 10, 2024), score = 2.0424611568450928 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World WebSearchEnginePlugin)-[:TOPIC]->(OpenAI), score = 2.0424611568450928 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World WebSearchEnginePlugin)-[:TOPIC]->(Semantic Kernel), score = 2.0424611568450928 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World WebSearchEnginePlugin)-[:TOPIC]->(Learning), score = 2.0424611568450928 }\n",
      "FulltextResult { text = (Hello World application with Semantic Kernel)-[:WROTE]->(Jason), score = 1.8528456687927246 }\n",
      "FulltextResult { text = (getting in depth with Semantic Kernel)-[:ACTIVITY]->(Jason), score = 1.8528456687927246 }\n",
      "FulltextResult { text = (GitHub repo semantic-kernel-getting-started)-[:INCLUDES]->(samples/demos/Text-to-Sql), score = 1.8528456687927246 }\n",
      "FulltextResult { text = (GitHub repo semantic-kernel-getting-started)-[:AVAILABLE_IN]->(code sample), score = 1.8528456687927246 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 1)-[:WRITTEN_BY]->(Jason), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 1)-[:TOPIC]->(Semantic Kernel), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 1)-[:TOPIC]->(AI), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 1)-[:POSTED_ON]->(Thursday, April 11, 2024), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 1)-[:TOPIC]->(Azure), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 1)-[:PART_OF]->(last entry), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 1)-[:TOPIC]->(Learning), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 1)-[:TOPIC]->(OpenAI), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 3)-[:WRITTEN]->(Jason), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 2)-[:DISCUSSED_IN]->(native function), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 2)-[:TOPIC]->(Azure), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 2)-[:TOPIC]->(Semantic Kernel), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 2)-[:TOPIC]->(AI), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 2)-[:TOPIC]->(Learning), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 2)-[:PREVIOUS_PART_OF]->(Part 1), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 2)-[:CONTAINS_CODE_FOR]->(HelloWorld.Plugin2.Console project), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 2)-[:POSTED_ON]->(Friday, April 26, 2024), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 2)-[:WRITTEN_BY]->(Jason), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 2)-[:TOPIC]->(OpenAI), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 3)-[:USING_TECHNOLOGY]->(OpenAI Function calling), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 3)-[:COMPARED_TO]->(Semantic Kernel Hello World Planners Part 2), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 3)-[:TOPIC]->(Semantic Kernel), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 3)-[:TOPIC]->(OpenAI), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 3)-[:WRITTEN_BY]->(Jason), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 3)-[:TOPIC]->(Azure), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 3)-[:MENTIONS]->(OpenAI Function calling), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 3)-[:CONTAINS_CODE_FOR]->(HelloWorld.Plugin3.Console project), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 3)-[:TOPIC]->(Learning), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 3)-[:POSTED_ON]->(Tuesday, April 30, 2024), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Plugins Part 3)-[:TOPIC]->(Artificial Intelligence), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:USES]->(Handlebars Planner), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:USED_IN]->(Handlebars Planner), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:TOPIC]->(OpenAI), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:COVERS]->(token usage comparison), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:TOPIC]->(Learning), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:PART_OF]->(Semantic Kernel Hello World Planners Part 2), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:DISCUSSED_IN]->(token difference), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:WRITTEN_BY]->(Jason), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:WRITTEN]->(Jason), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:IMPLEMENTED_IN]->(sample Hello World functionality), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:POSTED_ON]->(Sunday, May 19, 2024), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:TOPIC]->(Azure), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:TOPIC]->(Semantic Kernel), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 1)-[:TOPIC]->(AI), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:COMPARED_TO]->(Semantic Kernel Hello World Plugins Part 3), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:IMPLEMENTED_IN]->(sample Hello World functionality), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:WRITTEN_BY]->(Jason), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:USED_IN]->(Function Calling Stepwise Planner), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:TOPIC]->(OpenAI), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:DISCUSSED_IN]->(Azure), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:DISCUSSED_IN]->(AI), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:PART_OF]->(Semantic Kernel Hello World Planners Part 1), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:TOPIC]->(Azure), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:TOPIC]->(Learning), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:TOPIC]->(AI), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:TOPIC]->(Semantic Kernel), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Semantic Kernel Hello World Planners Part 2)-[:POSTED_ON]->(Monday, May 27, 2024), score = 1.695446252822876 }\n",
      "FulltextResult { text = (Using Bing Search API in the Semantic Kernel SDK)-[:AUTHORED_VIDEO]->(Will Velida), score = 1.4492225646972656 }\n"
     ]
    }
   ],
   "source": [
    "var synonyms = completion.Content[0].Text.Split(\"~\");\n",
    "\n",
    "var uniqueNodes = new HashSet<FulltextResult>();\n",
    "foreach(var synonym in synonyms)\n",
    "{\n",
    "    Console.WriteLine(synonym);\n",
    "    string cypher = $@\"\n",
    "                        CALL db.index.fulltext.queryNodes(\"\"ENTITY_TEXT\"\", \"\"{synonym}\"\")\n",
    "                        YIELD node AS e1, score\n",
    "                        MATCH (e1)-[r]-(e2:ENTITY)\n",
    "                        RETURN '(' + COALESCE(e1.text,'') + ')-[:' + COALESCE(type(r),'') + ']->(' + COALESCE(e2.text,'') + ')' as triplet, score\n",
    "                    \";\n",
    "\n",
    "    var textSearchResult = await driver.ExecutableQuery(cypher)\n",
    "                    .WithConfig(config)\n",
    "                    .ExecuteAsync();\n",
    "    if (textSearchResult.Result.Count() > 0)\n",
    "    {\n",
    "        foreach(var r in textSearchResult.Result)\n",
    "        {\n",
    "            var tripletText = $\"{r[\"triplet\"]}\";\n",
    "            var fullTextResult = new FulltextResult(tripletText, Convert.ToDouble(r[\"score\"]));\n",
    "            if (!uniqueNodes.Contains(fullTextResult))\n",
    "        {\n",
    "            uniqueNodes.Add(fullTextResult);\n",
    "            Console.WriteLine($\"{fullTextResult.text} {fullTextResult.score}\");\n",
    "        }  \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"\");\n",
    "Console.WriteLine($\"{uniqueNodes.Count} Unique nodes with matches:\");\n",
    "foreach(var key in uniqueNodes)\n",
    "{\n",
    "    Console.WriteLine($\"{key}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(getting in depth with Semantic Kernel)-[:ACTIVITY]->(Jason) 0.9498878717422485\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World) 0.9315083026885986\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Plugins Part 3) 0.9315083026885986\n",
      "(Semantic Kernel)-[:HAS_TOPIC]->(Demo Review: Chat Copilot) 0.9315083026885986\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Plugins Part 2) 0.9315083026885986\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Plugins Part 1) 0.9315083026885986\n",
      "(Semantic Kernel)-[:USED_FOR]->(creating sample Hello World functionality) 0.9315083026885986\n",
      "(Semantic Kernel)-[:TOPIC]->(Demo Review: Azure Vector Search AI Assistant) 0.9315083026885986\n",
      "(Semantic Kernel)-[:TOPIC]->(Boston Azure June 2024) 0.9315083026885986\n",
      "(Semantic Kernel)-[:CONTAINS]->(plugins) 0.9315083026885986\n",
      "(Semantic Kernel)-[:TOPIC]->(Demo Review: Azure Search OpenAI Demo C#) 0.9315083026885986\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World WebSearchEnginePlugin) 0.9315083026885986\n",
      "(Semantic Kernel)-[:TOPIC]->(Study Notes: Text-to-SQL Code Sample) 0.9315083026885986\n",
      "(Semantic Kernel)-[:USES]->(RAG demo) 0.9315083026885986\n",
      "(Semantic Kernel)-[:INCLUDES_TOPICS]->(Study Notes: Text-to-SQL) 0.9315083026885986\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Planners Part 1) 0.9315083026885986\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Planners Part 2) 0.9315083026885986\n",
      "(Semantic Kernel)-[:USES]->(Retrieval Augmented Generation (RAG) implementation) 0.9315083026885986\n",
      "(Semantic Kernel)-[:HAS_TOPIC]->(RAG Demo Chronicles) 0.9315083026885986\n",
      "(Semantic Kernel)-[:PART_OF]->(WebSearchEnginePlugin) 0.9315083026885986\n",
      "(Semantic Kernel Hello World)-[:TOPIC]->(Semantic Kernel) 0.9278889894485474\n",
      "(Semantic Kernel Hello World)-[:TOPIC]->(AI) 0.9278889894485474\n",
      "(Semantic Kernel Hello World)-[:WRITTEN_BY]->(Jason) 0.9278889894485474\n",
      "(Semantic Kernel Hello World)-[:TOPIC]->(Azure) 0.9278889894485474\n",
      "(Semantic Kernel Hello World)-[:TOPIC]->(OpenAI) 0.9278889894485474\n",
      "(Semantic Kernel Hello World)-[:PUBLISHED_ON]->(Saturday, March 30, 2024) 0.9278889894485474\n",
      "(Semantic Kernel Hello World)-[:TOPIC]->(Learning) 0.9278889894485474\n",
      "(semantic-kernel-getting-started)-[:CONTAINS]->(HelloWorld.Plugin2.Console project) 0.9273103475570679\n",
      "(semantic-kernel-getting-started)-[:PART_OF_REPO]->(HelloWorld.Plugin2.Console project) 0.9273103475570679\n",
      "(Hello World application with Semantic Kernel)-[:WROTE]->(Jason) 0.9267582893371582\n"
     ]
    }
   ],
   "source": [
    "string question = $@\"\n",
    "                    WITH genai.vector.encode(\n",
    "                            $question,\n",
    "                            'AzureOpenAI',\n",
    "                            {{\n",
    "                                token: $token,\n",
    "                                resource: $resource,\n",
    "                                deployment: $deployment\n",
    "                            }}) AS question_embedding\n",
    "                        CALL db.index.vector.queryNodes(\n",
    "                            'TEXT_EMBEDDING',\n",
    "                            $top_k, \n",
    "                            question_embedding\n",
    "                            ) \n",
    "                        YIELD node AS e1, score\n",
    "                        MATCH (e1)-[r]-(e2:ENTITY)-[r2:MENTIONED_IN]->(dc)\n",
    "                        RETURN '(' + COALESCE(e1.text,'') + ')-[:' + COALESCE(type(r),'') + ']->(' + COALESCE(e2.text,'') + ')' as triplet, dc.text as t, score\n",
    "                    \";\n",
    "\n",
    "var chunkResult = await driver.ExecutableQuery(question)\n",
    "                .WithParameters(new() { \n",
    "                    {\"question\", questionText},\n",
    "                    {\"token\", envVars[\"AZURE_OPENAI_API_KEY\"]}, \n",
    "                    {\"resource\", envVars[\"AZURE_OPENAI_RESOURCE\"]}, \n",
    "                    {\"deployment\", envVars[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"]},\n",
    "                    {\"top_k\", 5}})\n",
    "                .WithConfig(config)\n",
    "                .ExecuteAsync();\n",
    "\n",
    "var uniqueNodes = new HashSet<FulltextResult>();\n",
    "if (chunkResult.Result.Count() > 0)\n",
    "{\n",
    "    foreach(var r in chunkResult.Result)\n",
    "    {\n",
    "        var tripletText = $\"{r[\"triplet\"]}\";\n",
    "        var fullTextResult = new FulltextResult(tripletText, Convert.ToDouble(r[\"score\"]));\n",
    "        if (!uniqueNodes.Contains(fullTextResult))\n",
    "        {\n",
    "            uniqueNodes.Add(fullTextResult);\n",
    "            Console.WriteLine($\"{fullTextResult.text} {fullTextResult.score}\");\n",
    "        }   \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we perform the typical RAG functionality - a vector similarity search on the document chunk text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string question = $@\"\n",
    "                    WITH genai.vector.encode(\n",
    "                        $question,\n",
    "                        'AzureOpenAI',\n",
    "                        {{\n",
    "                            token: $token,\n",
    "                            resource: $resource,\n",
    "                            deployment: $deployment\n",
    "                        }}) AS question_embedding\n",
    "                    CALL db.index.vector.queryNodes(\n",
    "                        'CHUNK_EMBEDDING',\n",
    "                        $top_k, \n",
    "                        question_embedding\n",
    "                        ) YIELD node AS chunk, score \n",
    "                    RETURN chunk.id, chunk.text, score\n",
    "                    \";\n",
    "\n",
    "var chunkResult = await driver.ExecutableQuery(question)\n",
    "                .WithParameters(new() { \n",
    "                    {\"question\", questionText},\n",
    "                    {\"token\", envVars[\"AZURE_OPENAI_API_KEY\"]}, \n",
    "                    {\"resource\", envVars[\"AZURE_OPENAI_RESOURCE\"]}, \n",
    "                    {\"deployment\", envVars[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"]},\n",
    "                    {\"top_k\", 5}})\n",
    "                .WithConfig(config)\n",
    "                .ExecuteAsync();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to add the chunk results to the LLM request, I serialize the vector search results as a JSON string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Keys\": [\n",
      "    \"chunk.id\",\n",
      "    \"chunk.text\",\n",
      "    \"score\"\n",
      "  ],\n",
      "  \"Result\": [\n",
      "    {\n",
      "      \"chunk.id\": \"39020047081242689012476764f381f2\",\n",
      "      \"chunk.text\": \" Title:\\t\\tSemantic Kernel Hello World WebSearchEnginePlugin Author:\\t\\tJason  Posted On:\\tMonday, June 10, 2024 Topics:\\t\\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\\tA couple of weeks ago I thought I\\u2019d written my last of these blogs, mainly due to me getting more in depth with Semantic Kernel. However, after I watched Will Velida\\u2019s video Using Bing Search API in the Semantic Kernel SDK \\u2026 I couldn\\u2019t help but wonder what the API calls were behind the scenes. Will does a great job at explaining how to use the plugin and the Bing resource needed to make calls to the search API, so I won\\u2019t get into that part of it - I want to focus on the usefulness and API calls made by the plugin. \",\n",
      "      \"score\": 0.9169420003890991\n",
      "    },\n",
      "    {\n",
      "      \"chunk.id\": \"ed26beef072549e1aa9b979fd55b3c30\",\n",
      "      \"chunk.text\": \" Title:\\t\\tSemantic Kernel Hello World Planners Part 2 Author:\\t\\tJason  Posted On:\\tMonday, May 27, 2024 Topics:\\t\\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\\tLast week in the Semantic Kernel Hello World Planners Part 1 entry, I used the Handlebars planner to implement the sample Hello World functionality and then looked at the token difference between using a saved plan vs. generating a plan. In this entry I use the Function Calling Stepwise Planner to create the sample Hello World functionality and compare it to the implementation in the Semantic Kernel Hello World Plugins Part 3 entry. \",\n",
      "      \"score\": 0.9153493642807007\n",
      "    },\n",
      "    {\n",
      "      \"chunk.id\": \"29642fbb36cb4476992b440eeba23c04\",\n",
      "      \"chunk.text\": \" Title:\\t\\tSemantic Kernel Hello World Plugins Part 1 Author:\\t\\tJason  Posted On:\\tThursday, April 11, 2024 Topics:\\t\\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\\tA couple of weeks ago, in my last entry I created a simple Hello World application with Semantic Kernel. Since then, I\\u2019ve worked my way through the MS Learning path: APL-2005 Develop AI agents using Azure OpenAI and the Semantic Kernel SDK - which I highly recommend if you are also learning SK. In this entry I\\u2019m going to start with the code from the last entry and extract the prompt to a plugin. \",\n",
      "      \"score\": 0.9148409366607666\n",
      "    },\n",
      "    {\n",
      "      \"chunk.id\": \"a72fea85880d47429cf8049d239e99a6\",\n",
      "      \"chunk.text\": \" Title:\\t\\tSemantic Kernel Hello World Plugins Part 3 Author:\\t\\tJason  Posted On:\\tTuesday, April 30, 2024 Topics:\\t\\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\\tLast week I blogged Part 2 showing the creation of a native function plugin, in this post I want to take that native function a step further and use the OpenAI Function calling. This will allow us to not provide the current date when making the call to get a historic daily fact and have OpenAI call a function to get the current date. I\\u2019ve added the HelloWorld.Plugin3.Console project to the GitHub repo for the code in this blog entry. \",\n",
      "      \"score\": 0.9144268035888672\n",
      "    },\n",
      "    {\n",
      "      \"chunk.id\": \"54ad1ca99cb84b2d91ea5ddeaea905f0\",\n",
      "      \"chunk.text\": \" Title:\\t\\tSemantic Kernel Hello World Author:\\t\\tJason  Posted On:\\tSaturday, March 30, 2024 Topics:\\t\\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\\tThis past Thursday night after the Virtual Boston Azure meetup, Bill Wilder (@codingoutloud) created an AI mini-workshop (hands on) for the attendees that were interested in getting hands on with code using the Azure OpenAI API. This post is me using the same idea but with Semantic Kernel. OpenAI Chat Hello World C# Bill provided the following code for us to get a simple OpenAI chat working: using Azure; using Azure. \",\n",
      "      \"score\": 0.9135735034942627\n",
      "    }\n",
      "  ],\n",
      "  \"Summary\": {\n",
      "    \"Query\": {\n",
      "      \"Text\": \"\\n                    WITH genai.vector.encode(\\n                        $question,\\n                        \\u0027AzureOpenAI\\u0027,\\n                        {\\n                            token: $token,\\n                            resource: $resource,\\n                            deployment: $deployment\\n                        }) AS question_embedding\\n                    CALL db.index.vector.queryNodes(\\n                        \\u0027CHUNK_EMBEDDING\\u0027,\\n                        $top_k, \\n                        question_embedding\\n                        ) YIELD node AS chunk, score \\n                    RETURN chunk.id, chunk.text, score\\n                    \",\n",
      "      \"Parameters\": {\n",
      "        \"question\": \"What blog posts are about Semantic Kernel?\",\n",
      "        \"token\": \"c36e2182dbbc401d9a6867bad09712ac\",\n",
      "        \"resource\": \"aoai-jhaley\",\n",
      "        \"deployment\": \"embedding\",\n",
      "        \"top_k\": 5\n",
      "      }\n",
      "    },\n",
      "    \"Counters\": {\n",
      "      \"ContainsUpdates\": false,\n",
      "      \"NodesCreated\": 0,\n",
      "      \"NodesDeleted\": 0,\n",
      "      \"RelationshipsCreated\": 0,\n",
      "      \"RelationshipsDeleted\": 0,\n",
      "      \"PropertiesSet\": 0,\n",
      "      \"LabelsAdded\": 0,\n",
      "      \"LabelsRemoved\": 0,\n",
      "      \"IndexesAdded\": 0,\n",
      "      \"IndexesRemoved\": 0,\n",
      "      \"ConstraintsAdded\": 0,\n",
      "      \"ConstraintsRemoved\": 0,\n",
      "      \"SystemUpdates\": 0,\n",
      "      \"ContainsSystemUpdates\": false\n",
      "    },\n",
      "    \"QueryType\": 1,\n",
      "    \"HasPlan\": false,\n",
      "    \"HasProfile\": false,\n",
      "    \"Plan\": null,\n",
      "    \"Profile\": null,\n",
      "    \"Notifications\": null,\n",
      "    \"GqlStatusObjects\": [\n",
      "      {\n",
      "        \"GqlStatus\": \"00000\",\n",
      "        \"StatusDescription\": \"note: successful completion\",\n",
      "        \"Position\": null,\n",
      "        \"Classification\": 0,\n",
      "        \"RawClassification\": null,\n",
      "        \"Severity\": 0,\n",
      "        \"RawSeverity\": null,\n",
      "        \"DiagnosticRecord\": {\n",
      "          \"OPERATION\": \"\",\n",
      "          \"OPERATION_CODE\": \"0\",\n",
      "          \"CURRENT_SCHEMA\": \"/\"\n",
      "        },\n",
      "        \"RawDiagnosticRecord\": \"[{OPERATION, }, {OPERATION_CODE, 0}, {CURRENT_SCHEMA, /}]\"\n",
      "      }\n",
      "    ],\n",
      "    \"ResultAvailableAfter\": \"00:00:00.0020000\",\n",
      "    \"ResultConsumedAfter\": \"00:00:00.1360000\",\n",
      "    \"Server\": {\n",
      "      \"Address\": \"localhost:7687\",\n",
      "      \"ProtocolVersion\": \"5.4\",\n",
      "      \"Agent\": \"Neo4j/5.21.2\"\n",
      "    },\n",
      "    \"Database\": {\n",
      "      \"Name\": \"neo4j\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "Document: { text:  Title:\t\tSemantic Kernel Hello World WebSearchEnginePlugin Author:\t\tJason  Posted On:\tMonday, June 10, 2024 Topics:\t\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\tA couple of weeks ago I thought I’d written my last of these blogs, mainly due to me getting more in depth with Semantic Kernel. However, after I watched Will Velida’s video Using Bing Search API in the Semantic Kernel SDK … I couldn’t help but wonder what the API calls were behind the scenes. Will does a great job at explaining how to use the plugin and the Bing resource needed to make calls to the search API, so I won’t get into that part of it - I want to focus on the usefulness and API calls made by the plugin.  }\n",
      "Document: { text:  Title:\t\tSemantic Kernel Hello World Planners Part 2 Author:\t\tJason  Posted On:\tMonday, May 27, 2024 Topics:\t\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\tLast week in the Semantic Kernel Hello World Planners Part 1 entry, I used the Handlebars planner to implement the sample Hello World functionality and then looked at the token difference between using a saved plan vs. generating a plan. In this entry I use the Function Calling Stepwise Planner to create the sample Hello World functionality and compare it to the implementation in the Semantic Kernel Hello World Plugins Part 3 entry.  }\n",
      "Document: { text:  Title:\t\tSemantic Kernel Hello World Plugins Part 1 Author:\t\tJason  Posted On:\tThursday, April 11, 2024 Topics:\t\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\tA couple of weeks ago, in my last entry I created a simple Hello World application with Semantic Kernel. Since then, I’ve worked my way through the MS Learning path: APL-2005 Develop AI agents using Azure OpenAI and the Semantic Kernel SDK - which I highly recommend if you are also learning SK. In this entry I’m going to start with the code from the last entry and extract the prompt to a plugin.  }\n",
      "Document: { text:  Title:\t\tSemantic Kernel Hello World Plugins Part 3 Author:\t\tJason  Posted On:\tTuesday, April 30, 2024 Topics:\t\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\tLast week I blogged Part 2 showing the creation of a native function plugin, in this post I want to take that native function a step further and use the OpenAI Function calling. This will allow us to not provide the current date when making the call to get a historic daily fact and have OpenAI call a function to get the current date. I’ve added the HelloWorld.Plugin3.Console project to the GitHub repo for the code in this blog entry.  }\n",
      "Document: { text:  Title:\t\tSemantic Kernel Hello World Author:\t\tJason  Posted On:\tSaturday, March 30, 2024 Topics:\t\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\tThis past Thursday night after the Virtual Boston Azure meetup, Bill Wilder (@codingoutloud) created an AI mini-workshop (hands on) for the attendees that were interested in getting hands on with code using the Azure OpenAI API. This post is me using the same idea but with Semantic Kernel. OpenAI Chat Hello World C# Bill provided the following code for us to get a simple OpenAI chat working: using Azure; using Azure.  }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Console.WriteLine(JsonSerializer.Serialize(chunkResult, new JsonSerializerOptions {\n",
    "             WriteIndented = true\n",
    "         }));\n",
    "\n",
    "StringBuilder chunkTexts = new StringBuilder();\n",
    "foreach(var r in chunkResult.Result)\n",
    "{\n",
    "    chunkTexts.AppendLine($\"Document: {{ text: {r[\"chunk.text\"].ToString()} }}\");\n",
    "}\n",
    "\n",
    "Console.WriteLine(chunkTexts.ToString());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the typical RAG request (no entity or relation information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The following blog posts are about Semantic Kernel:\n",
      "\n",
      "1. **Semantic Kernel Hello World WebSearchEnginePlugin** - Posted On: Monday, June 10, 2024\n",
      "2. **Semantic Kernel Hello World Planners Part 2** - Posted On: Monday, May 27, 2024\n",
      "3. **Semantic Kernel Hello World Plugins Part 1** - Posted On: Thursday, April 11, 2024\n",
      "4. **Semantic Kernel Hello World Plugins Part 3** - Posted On: Tuesday, April 30, 2024\n",
      "5. **Semantic Kernel Hello World** - Posted On: Saturday, March 30, 2024\r\n"
     ]
    }
   ],
   "source": [
    "ChatClient chatClient = client.GetChatClient(\"chat\");\n",
    "\n",
    "string context = $@\"Unstructured data:\n",
    "{chunkTexts.ToString()}\n",
    "\";\n",
    "\n",
    "string prompt = $@\"Answer the question based only on the following context:\n",
    "\t\t\t    {context}\n",
    "                ######################\n",
    "                Question: {questionText}\n",
    "                ######################\n",
    "                Answer:\";\n",
    "\n",
    "string sysprompt = @\"Be brief in your answers.\n",
    "                    Answer ONLY with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below. If asking a clarifying question to the user would help, ask the question.\n",
    "                    For tabular information return it as an html table. Do not return markdown format. If the question is not in English, answer in the language used in the question.\";\n",
    "\n",
    "ChatCompletion completion = chatClient.CompleteChat(\n",
    "    [\n",
    "        new SystemChatMessage(sysprompt),\n",
    "        new UserChatMessage(prompt),\n",
    "    ]);\n",
    "\n",
    "Console.WriteLine($\"{completion.Role}: {completion.Content[0].Text}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the graph RAG request (with entity or relation information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To plan the response, begin by examining the Neo4j entity relations and their structured data to determine if the answer is present within. Follow these steps:\n",
      "\n",
      "Analyze the provided Neo4j entity relations and their structured data:\n",
      "\n",
      "Look at the nodes, relationships, and properties in the graph.\n",
      "Identify the entities and their connections relevant to the question.\n",
      "Identify relevant information:\n",
      "\n",
      "Extract data points and relationships that are pertinent to the question.\n",
      "Consider how these relationships influence the answer.\n",
      "Synthesize the identified information:\n",
      "\n",
      "Combine the extracted information logically.\n",
      "Formulate a coherent and comprehensive response.\n",
      "Here are some examples to guide the process:\n",
      "\n",
      "######################\n",
      "Example:\n",
      "(Semantic Kernel)-[:TOPIC]->(Blog Post Title 1)\n",
      "(Semantic Kernel)-[:HAS_TOPIC]->(Blog Post Title 2)\n",
      "(Semantic Kernel)-[:INCLUDES_TOPIC]->(Blog Post Title 3)\n",
      "\n",
      "Question:\n",
      "What blog posts are about Semantic Kernel?\n",
      "\n",
      "Answer:\n",
      "Blog Post is about Semantic Kernel\n",
      "######################\n",
      "Answer the question based solely on the following context:\n",
      "\n",
      "######################\n",
      "Structured data:\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World)\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Plugins Part 3)\n",
      "(Semantic Kernel)-[:HAS_TOPIC]->(Demo Review: Chat Copilot)\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Plugins Part 2)\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Plugins Part 1)\n",
      "(Semantic Kernel)-[:USED_FOR]->(creating sample Hello World functionality)\n",
      "(Semantic Kernel)-[:TOPIC]->(Demo Review: Azure Vector Search AI Assistant)\n",
      "(Semantic Kernel)-[:TOPIC]->(Boston Azure June 2024)\n",
      "(Semantic Kernel)-[:CONTAINS]->(plugins)\n",
      "(Semantic Kernel)-[:TOPIC]->(Demo Review: Azure Search OpenAI Demo C#)\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World WebSearchEnginePlugin)\n",
      "(Semantic Kernel)-[:TOPIC]->(Study Notes: Text-to-SQL Code Sample)\n",
      "(Semantic Kernel)-[:USES]->(RAG demo)\n",
      "(Semantic Kernel)-[:INCLUDES_TOPICS]->(Study Notes: Text-to-SQL)\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Planners Part 1)\n",
      "(Semantic Kernel)-[:TOPIC]->(Semantic Kernel Hello World Planners Part 2)\n",
      "(Semantic Kernel)-[:USES]->(Retrieval Augmented Generation (RAG) implementation)\n",
      "(Semantic Kernel)-[:HAS_TOPIC]->(RAG Demo Chronicles)\n",
      "(Semantic Kernel)-[:PART_OF]->(WebSearchEnginePlugin)\n",
      "######################\n",
      "Unstructured data:\n",
      "Document: { text:  Title:\t\tSemantic Kernel Hello World WebSearchEnginePlugin Author:\t\tJason  Posted On:\tMonday, June 10, 2024 Topics:\t\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\tA couple of weeks ago I thought I’d written my last of these blogs, mainly due to me getting more in depth with Semantic Kernel. However, after I watched Will Velida’s video Using Bing Search API in the Semantic Kernel SDK … I couldn’t help but wonder what the API calls were behind the scenes. Will does a great job at explaining how to use the plugin and the Bing resource needed to make calls to the search API, so I won’t get into that part of it - I want to focus on the usefulness and API calls made by the plugin.  }\n",
      "Document: { text:  Title:\t\tSemantic Kernel Hello World Planners Part 2 Author:\t\tJason  Posted On:\tMonday, May 27, 2024 Topics:\t\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\tLast week in the Semantic Kernel Hello World Planners Part 1 entry, I used the Handlebars planner to implement the sample Hello World functionality and then looked at the token difference between using a saved plan vs. generating a plan. In this entry I use the Function Calling Stepwise Planner to create the sample Hello World functionality and compare it to the implementation in the Semantic Kernel Hello World Plugins Part 3 entry.  }\n",
      "Document: { text:  Title:\t\tSemantic Kernel Hello World Plugins Part 1 Author:\t\tJason  Posted On:\tThursday, April 11, 2024 Topics:\t\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\tA couple of weeks ago, in my last entry I created a simple Hello World application with Semantic Kernel. Since then, I’ve worked my way through the MS Learning path: APL-2005 Develop AI agents using Azure OpenAI and the Semantic Kernel SDK - which I highly recommend if you are also learning SK. In this entry I’m going to start with the code from the last entry and extract the prompt to a plugin.  }\n",
      "Document: { text:  Title:\t\tSemantic Kernel Hello World Plugins Part 3 Author:\t\tJason  Posted On:\tTuesday, April 30, 2024 Topics:\t\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\tLast week I blogged Part 2 showing the creation of a native function plugin, in this post I want to take that native function a step further and use the OpenAI Function calling. This will allow us to not provide the current date when making the call to get a historic daily fact and have OpenAI call a function to get the current date. I’ve added the HelloWorld.Plugin3.Console project to the GitHub repo for the code in this blog entry.  }\n",
      "Document: { text:  Title:\t\tSemantic Kernel Hello World Author:\t\tJason  Posted On:\tSaturday, March 30, 2024 Topics:\t\tAI, Learning, Azure, OpenAI, Semantic Kernel Summary:\tThis past Thursday night after the Virtual Boston Azure meetup, Bill Wilder (@codingoutloud) created an AI mini-workshop (hands on) for the attendees that were interested in getting hands on with code using the Azure OpenAI API. This post is me using the same idea but with Semantic Kernel. OpenAI Chat Hello World C# Bill provided the following code for us to get a simple OpenAI chat working: using Azure; using Azure.  }\n",
      "\n",
      "\n",
      "\n",
      "######################\n",
      "Question: What blog posts are about Semantic Kernel?\n",
      "######################\n",
      "Answer:\n",
      "Assistant: The blog posts that are about Semantic Kernel are:\n",
      "\n",
      "1. Semantic Kernel Hello World\n",
      "2. Semantic Kernel Hello World Plugins Part 3\n",
      "3. Demo Review: Chat Copilot\n",
      "4. Semantic Kernel Hello World Plugins Part 2\n",
      "5. Semantic Kernel Hello World Plugins Part 1\n",
      "6. Demo Review: Azure Vector Search AI Assistant\n",
      "7. Boston Azure June 2024\n",
      "8. Demo Review: Azure Search OpenAI Demo C#\n",
      "9. Semantic Kernel Hello World WebSearchEnginePlugin\n",
      "10. Study Notes: Text-to-SQL Code Sample\n",
      "11. Semantic Kernel Hello World Planners Part 1\n",
      "12. Semantic Kernel Hello World Planners Part 2\n"
     ]
    }
   ],
   "source": [
    "ChatClient chatClient = client.GetChatClient(\"chat\");\n",
    "\n",
    "string context = $@\"\n",
    "######################\n",
    "Structured data:\n",
    "{string.Join(Environment.NewLine, uniqueNodes.Select(c => c.text).Take(50).ToArray())}\n",
    "######################\n",
    "Unstructured data:\n",
    "{chunkTexts.ToString()}\n",
    "\";\n",
    "\n",
    "string prompt = $@\"\n",
    "To plan the response, begin by examining the Neo4j entity relations and their structured data to determine if the answer is present within. Follow these steps:\n",
    "\n",
    "Analyze the provided Neo4j entity relations and their structured data:\n",
    "\n",
    "Look at the nodes, relationships, and properties in the graph.\n",
    "Identify the entities and their connections relevant to the question.\n",
    "Identify relevant information:\n",
    "\n",
    "Extract data points and relationships that are pertinent to the question.\n",
    "Consider how these relationships influence the answer.\n",
    "Synthesize the identified information:\n",
    "\n",
    "Combine the extracted information logically.\n",
    "Formulate a coherent and comprehensive response.\n",
    "Here are some examples to guide the process:\n",
    "\n",
    "######################\n",
    "Example:\n",
    "(Semantic Kernel)-[:TOPIC]->(Blog Post Title 1)\n",
    "(Semantic Kernel)-[:HAS_TOPIC]->(Blog Post Title 2)\n",
    "(Semantic Kernel)-[:INCLUDES_TOPIC]->(Blog Post Title 3)\n",
    "\n",
    "Question:\n",
    "What blog posts are about Semantic Kernel?\n",
    "\n",
    "Answer:\n",
    "Blog Post is about Semantic Kernel\n",
    "######################\n",
    "Answer the question based solely on the following context:\n",
    "{context}\n",
    "\n",
    "######################\n",
    "Question: {questionText}\n",
    "######################\n",
    "Answer:\";\n",
    "\n",
    "string sysprompt = @\"Answer ONLY with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below. If asking a clarifying question to the user would help, ask the question.\n",
    "                    For tabular information return it as an html table. Do not return markdown format. If the question is not in English, answer in the language used in the question.\";\n",
    "\n",
    "ChatCompletion completion = chatClient.CompleteChat(\n",
    "    [\n",
    "        new SystemChatMessage(sysprompt),\n",
    "        new UserChatMessage(prompt),\n",
    "    ]);\n",
    "\n",
    "Console.WriteLine($\"{completion.Role}: {completion.Content[0].Text}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what the prompt was to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Console.WriteLine(sysprompt);\n",
    "Console.WriteLine(\"######################\");\n",
    "Console.WriteLine(prompt);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
