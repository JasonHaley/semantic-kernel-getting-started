{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure, 1.0.6</span></li><li><span>Azure.AI.OpenAI, 2.0.0-beta.2</span></li><li><span>Azure.Identity, 1.13.0-beta.1</span></li><li><span>dotenv.net, 3.2.0</span></li><li><span>Microsoft.DotNet.Interactive.AIUtilities, 1.0.0-beta.24229.4</span></li><li><span>Microsoft.ML.Tokenizers, 0.22.0-preview.24378.1</span></li><li><span>Microsoft.SemanticKernel.Core, 1.16.1</span></li><li><span>Neo4j.Driver, 5.22.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading extensions from `C:\\Users\\haley\\.nuget\\packages\\skiasharp\\2.88.6\\interactive-extensions\\dotnet\\SkiaSharp.DotNet.Interactive.dll`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading extension script from `C:\\Users\\haley\\.nuget\\packages\\microsoft.dotnet.interactive.aiutilities\\1.0.0-beta.24229.4\\interactive-extensions\\dotnet\\extension.dib`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Azure.AI.OpenAI, *-*\"\n",
    "#r \"nuget: Azure, *-*\"\n",
    "#r \"nuget: Azure.Identity, *-*\"\n",
    "#r \"nuget: dotenv.net, *-*\"\n",
    "#r \"nuget: Microsoft.DotNet.Interactive.AIUtilities, *-*\"\n",
    "#r \"nuget: Microsoft.ML.Tokenizers, *-*\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Core, *-*\"\n",
    "#r \"nuget: Neo4j.Driver, *-*\"\n",
    "\n",
    "using Microsoft.DotNet.Interactive;\n",
    "using Microsoft.DotNet.Interactive.AIUtilities;\n",
    "using dotenv.net;\n",
    "using Azure.AI.OpenAI;\n",
    "using Azure;\n",
    "using Azure.Identity;\n",
    "using OpenAI.Chat;\n",
    "using System;\n",
    "using System.Text.Json;\n",
    "using System.Text.Json.Serialization;\n",
    "using System.IO;\n",
    "using Microsoft.SemanticKernel.Text;\n",
    "using Microsoft.ML.Tokenizers;\n",
    "using Neo4j.Driver;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "DotEnv.Load();\n",
    "\n",
    "var envVars = DotEnv.Read();\n",
    "\n",
    "AzureOpenAIClient client = new(new Uri(envVars[\"AZURE_OPENAI_ENDPOINT\"]), \n",
    "    new AzureKeyCredential(envVars[\"AZURE_OPENAI_API_KEY\"]));\n",
    "\n",
    "var embeddings = envVars[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"];\n",
    "var llm = envVars[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "public record DocunentMetadata(string id, string source);\n",
    "public record ChunkMetadata(string id, string name, int sequence, string documentId, string text);\n",
    "public record TripletRow(string head, string head_type, string relation, string tail, string tail_type);\n",
    "public class EntityMetadata\n",
    "{\n",
    "    public string name { get; set; }\n",
    "    public string type { get; set; }\n",
    "    public string id { get; set; }\n",
    "    public string text { get; set; }\n",
    "    public Dictionary<string, ChunkMetadata> mentionedInChunks {get; set;} = new Dictionary<string, ChunkMetadata>();\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Blog Post 1\", \"head_type\": \"CREATIVE_WORK\", \"relation\": \"TITLE\", \"tail\": \"Personal Update: Learning AI\", \"tail_type\": \"CREATIVE_WORK\"},\n",
      "    {\"head\": \"Learning AI\", \"head_type\": \"BOOK\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Four Stages of Competence\", \"head_type\": \"CONCEPT\", \"relation\": \"USED_FOR\", \"tail\": \"Learning AI\", \"tail_type\": \"BOOK\"},\n",
      "    {\"head\": \"Four Stages of Competence\", \"head_type\": \"CONCEPT\", \"relation\": \"STAGE 1\", \"tail\": \"Unconscious Incompetence\", \"tail_type\": \"CONCEPT\"},\n",
      "    {\"head\": \"Four Stages of Competence\", \"head_type\": \"CONCEPT\", \"relation\": \"STAGE 2\", \"tail\": \"Conscious Incompetence\", \"tail_type\": \"CONCEPT\"},\n",
      "    {\"head\": \"Four Stages of Competence\", \"head_type\": \"CONCEPT\", \"relation\": \"STAGE 3\", \"tail\": \"Conscious Competence\", \"tail_type\": \"CONCEPT\"},\n",
      "    {\"head\": \"Four Stages of Competence\", \"head_type\": \"CONCEPT\", \"relation\": \"STAGE 4\", \"tail\": \"Unconscious Competence\", \"tail_type\": \"CONCEPT\"},\n",
      "    {\"head\": \"Blog Post 2\", \"head_type\": \"CREATIVE_WORK\", \"relation\": \"TITLE\", \"tail\": \"Demo Review: Simple RAG using SQL Server and OpenAI\", \"tail_type\": \"CREATIVE_WORK\"},\n",
      "    {\"head\": \"Blazor\", \"head_type\": \"PRODUCT\", \"relation\": \"USED_FOR\", \"tail\": \"RAG Application\", \"tail_type\": \"PRODUCT\"},\n",
      "    {\"head\": \"Michael Washington\", \"head_type\": \"PERSON\", \"relation\": \"CREATED\", \"tail\": \"Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling\", \"tail_type\": \"CREATIVE_WORK\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\n",
      "        \"head\": \"Demo Review\",\n",
      "        \"head_type\": \"REVIEW\",\n",
      "        \"relation\": \"COVERS\",\n",
      "        \"tail\": \"Simple RAG using Blazor, SQL Server, Azure OpenAI, Function Calling\",\n",
      "        \"tail_type\": \"CREATIVE_WORK\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Michael Washington\",\n",
      "        \"head_type\": \"PERSON\",\n",
      "        \"relation\": \"AUTHORED\",\n",
      "        \"tail\": \"Simple RAG using Blazor, SQL Server, Azure OpenAI, Function Calling\",\n",
      "        \"tail_type\": \"CREATIVE_WORK\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Azure Search OpenAI Demo C#\",\n",
      "        \"head_type\": \"CREATIVE_WORK\",\n",
      "        \"relation\": \"WRITTEN_IN\",\n",
      "        \"tail\": \"C#\",\n",
      "        \"tail_type\": \"PROGRAMMING_LANGUAGE\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Azure Search OpenAI Demo\",\n",
      "        \"head_type\": \"CREATIVE_WORK\",\n",
      "        \"relation\": \"WRITTEN_IN\",\n",
      "        \"tail\": \"Python\",\n",
      "        \"tail_type\": \"PROGRAMMING_LANGUAGE\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Azure Search OpenAI Demo\",\n",
      "        \"head_type\": \"CREATIVE_WORK\",\n",
      "        \"relation\": \"WRITTEN_IN\",\n",
      "        \"tail\": \"Java\",\n",
      "        \"tail_type\": \"PROGRAMMING_LANGUAGE\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Azure Search OpenAI Demo\",\n",
      "        \"head_type\": \"CREATIVE_WORK\",\n",
      "        \"relation\": \"WRITTEN_IN\",\n",
      "        \"tail\": \"Javascript/Typescript\",\n",
      "        \"tail_type\": \"PROGRAMMING_LANGUAGE\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Demo Review\",\n",
      "        \"head_type\": \"REVIEW\",\n",
      "        \"relation\": \"COVERS\",\n",
      "        \"tail\": \"Azure Search OpenAI Demo C#\",\n",
      "        \"tail_type\": \"CREATIVE_WORK\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Demo Review\",\n",
      "        \"head_type\": \"REVIEW\",\n",
      "        \"relation\": \"COVERS\",\n",
      "        \"tail\": \"Azure Search OpenAI Demo Javascript/Typescript\",\n",
      "        \"tail_type\": \"CREATIVE_WORK\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Demo Review\",\n",
      "        \"head_type\": \"REVIEW\",\n",
      "        \"relation\": \"COVERS\",\n",
      "        \"tail\": \"Azure Search OpenAI Demo Python\",\n",
      "        \"tail_type\": \"CREATIVE_WORK\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Web application\",\n",
      "        \"head_type\": \"PRODUCT\",\n",
      "        \"relation\": \"WRITTEN_IN\",\n",
      "        \"tail\": \"React\",\n",
      "        \"tail_type\": \"TECHNOLOGY\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\n",
      "        \"head\": \"Demo Review: Azure Search OpenAI Demo (Python)\",\n",
      "        \"head_type\": \"BLOG_POST\",\n",
      "        \"relation\": \"ABOUT\",\n",
      "        \"tail\": \"Azure Search OpenAI demos\",\n",
      "        \"tail_type\": \"PROJECT\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Hack Together: The AI Chat App Hack\",\n",
      "        \"head_type\": \"EVENT\",\n",
      "        \"relation\": \"USED\",\n",
      "        \"tail\": \"Azure Search OpenAI Demo (Python)\",\n",
      "        \"tail_type\": \"BLOG_POST\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Demo Review: Azure Vector Search AI Assistant\",\n",
      "        \"head_type\": \"BLOG_POST\",\n",
      "        \"relation\": \"USES\",\n",
      "        \"tail\": \"Semantic Kernel\",\n",
      "        \"tail_type\": \"TECHNOLOGY\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Azure Vector Search AI Assistant\",\n",
      "        \"head_type\": \"PROJECT\",\n",
      "        \"relation\": \"USES_DATA_FROM\",\n",
      "        \"tail\": \"database\",\n",
      "        \"tail_type\": \"TECHNOLOGY\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"The RAG Demo Chronicles\",\n",
      "        \"head_type\": \"BLOG_SERIES\",\n",
      "        \"relation\": \"INCLUDES\",\n",
      "        \"tail\": \"Demo Review: Azure Vector Search AI Assistant\",\n",
      "        \"tail_type\": \"BLOG_POST\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Boston Code Camp 36\",\n",
      "        \"head_type\": \"EVENT\",\n",
      "        \"relation\": \"HELDS_AT\",\n",
      "        \"tail\": \"Boston\",\n",
      "        \"tail_type\": \"PLACE\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Boston Code Camp 36\",\n",
      "        \"head_type\": \"EVENT\",\n",
      "        \"relation\": \"ONGOING_FOR\",\n",
      "        \"tail\": \"20+ years\",\n",
      "        \"tail_type\": \"DURATION\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Talk: Getting Started with Retrieval Augmented Generation (RAG)\",\n",
      "        \"head_type\": \"PRESENTATION\",\n",
      "        \"relation\": \"PART_OF\",\n",
      "        \"tail\": \"Boston Code Camp 36\",\n",
      "        \"tail_type\": \"EVENT\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Boston tech community\",\n",
      "        \"head_type\": \"ORGANIZATION\",\n",
      "        \"relation\": \"ATTENDS\",\n",
      "        \"tail\": \"Boston Code Camp 36\",\n",
      "        \"tail_type\": \"EVENT\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Jason\",\n",
      "        \"head_type\": \"PERSON\",\n",
      "        \"relation\": \"POSTED\",\n",
      "        \"tail\": \"Demo Review: Azure Search OpenAI Demo (Python)\",\n",
      "        \"tail_type\": \"BLOG_POST\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Virtual Boston Azure meetup\", \"head_type\": \"EVENT\", \"relation\": \"CREATED\", \"tail\": \"AI mini-workshop\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Bill Wilder\", \"head_type\": \"PERSON\", \"relation\": \"HOSTED\", \"tail\": \"AI mini-workshop\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"AI mini-workshop\", \"head_type\": \"EVENT\", \"relation\": \"USED_FOR\", \"tail\": \"Azure OpenAI API\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Semantic Kernel\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USED_FOR\", \"tail\": \"Hello World application\", \"tail_type\": \"SOFTWARE\"},\n",
      "    {\"head\": \"MS Learning path\", \"head_type\": \"PRODUCT\", \"relation\": \"PART_OF\", \"tail\": \"APL-2005 Develop AI agents\", \"tail_type\": \"COURSE\"},\n",
      "    {\"head\": \"APL-2005 Develop AI agents\", \"head_type\": \"COURSE\", \"relation\": \"USES\", \"tail\": \"Azure OpenAI\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"APL-2005 Develop AI agents\", \"head_type\": \"COURSE\", \"relation\": \"USES\", \"tail\": \"Semantic Kernel SDK\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Boston Global Azure Bootcamp\", \"head_type\": \"EVENT\", \"relation\": \"PART_OF\", \"tail\": \"Global Azure Bootcamp\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Boston Azure\", \"head_type\": \"ORGANIZATION\", \"relation\": \"HOSTED\", \"tail\": \"Boston Global Azure Bootcamp\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Boston Global Azure Bootcamp\", \"head_type\": \"EVENT\", \"relation\": \"FOCUSED_ON\", \"tail\": \"AI and hands-on-labs\", \"tail_type\": \"TOPIC\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\n",
      "        \"head\": \"Jason\",\n",
      "        \"head_type\": \"PERSON\",\n",
      "        \"relation\": \"POSTED\",\n",
      "        \"tail\": \"Semantic Kernel Hello World Plugins Part 2\",\n",
      "        \"tail_type\": \"BLOG_POST\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Semantic Kernel Hello World Plugins Part 2\",\n",
      "        \"head_type\": \"BLOG_POST\",\n",
      "        \"relation\": \"INTRODUCED\",\n",
      "        \"tail\": \"native function\",\n",
      "        \"tail_type\": \"TECHNOLOGY\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Semantic Kernel Hello World Plugins Part 2\",\n",
      "        \"head_type\": \"BLOG_POST\",\n",
      "        \"relation\": \"PART_OF\",\n",
      "        \"tail\": \"HelloWorld.Plugin2.Console project\",\n",
      "        \"tail_type\": \"PROJECT\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"HelloWorld.Plugin2.Console project\",\n",
      "        \"head_type\": \"PROJECT\",\n",
      "        \"relation\": \"HOSTED_IN\",\n",
      "        \"tail\": \"semantic-kernel-getting-started repo\",\n",
      "        \"tail_type\": \"REPOSITORY\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Microsoft Learn module\",\n",
      "        \"head_type\": \"PRODUCT\",\n",
      "        \"relation\": \"TITLED\",\n",
      "        \"tail\": \"Give your AI agent skills\",\n",
      "        \"tail_type\": \"COURSE\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Jason\",\n",
      "        \"head_type\": \"PERSON\",\n",
      "        \"relation\": \"POSTED\",\n",
      "        \"tail\": \"Semantic Kernel Hello World Plugins Part 3\",\n",
      "        \"tail_type\": \"BLOG_POST\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Semantic Kernel Hello World Plugins Part 3\",\n",
      "        \"head_type\": \"BLOG_POST\",\n",
      "        \"relation\": \"USED_FOR\",\n",
      "        \"tail\": \"OpenAI Function calling\",\n",
      "        \"tail_type\": \"TECHNOLOGY\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Semantic Kernel Hello World Plugins Part 3\",\n",
      "        \"head_type\": \"BLOG_POST\",\n",
      "        \"relation\": \"PART_OF\",\n",
      "        \"tail\": \"HelloWorld.Plugin3.Console project\",\n",
      "        \"tail_type\": \"PROJECT\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Jason\",\n",
      "        \"head_type\": \"PERSON\",\n",
      "        \"relation\": \"SPOKE_AT\",\n",
      "        \"tail\": \"Memphis Azure User Group\",\n",
      "        \"tail_type\": \"EVENT\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Memphis Azure User Group\",\n",
      "        \"head_type\": \"EVENT\",\n",
      "        \"relation\": \"LOCATED_IN\",\n",
      "        \"tail\": \"Memphis\",\n",
      "        \"tail_type\": \"PLACE\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"SPOKE_AT\", \"tail\": \"Memphis Azure User Group\", \"tail_type\": \"EVENT\"},\n",
      "    {\"head\": \"Memphis Azure User Group\", \"head_type\": \"EVENT\", \"relation\": \"LOCATED_IN\", \"tail\": \"Memphis\", \"tail_type\": \"PLACE\"},\n",
      "    \n",
      "    {\"head\": \"Talk: Getting Started with Retrieval Augmented Generation (RAG)\", \"head_type\": \"PRESENTATION\", \"relation\": \"GIVEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    {\"head\": \"Slide deck\", \"head_type\": \"CREATIVE_WORK\", \"relation\": \"USED_IN\", \"tail\": \"Getting Started with Retrieval Augmented Generation (RAG)\", \"tail_type\": \"PRESENTATION\"},\n",
      "    \n",
      "    {\"head\": \"Talk: Getting Started with Retrieval Augmented Generation (RAG)\", \"head_type\": \"PRESENTATION\", \"relation\": \"THEME\", \"tail\": \"Memphis\", \"tail_type\": \"PLACE\"},\n",
      "    \n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 1\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    \n",
      "    {\"head\": \"OpenAI Function Calling\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USED_IN\", \"tail\": \"Semantic Kernel Hello World Plugins Part 3\", \"tail_type\": \"BLOG_POST\"},\n",
      "    {\"head\": \"Handlebars Planner\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USED_FOR\", \"tail\": \"sample Hello World functionality\", \"tail_type\": \"ACTION\"},\n",
      "    \n",
      "    {\"head\": \"Semantic Kernel Hello World Planners Part 2\", \"head_type\": \"BLOG_POST\", \"relation\": \"WRITTEN_BY\", \"tail\": \"Jason\", \"tail_type\": \"PERSON\"},\n",
      "    \n",
      "    {\"head\": \"Function Calling Stepwise Planner\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USED_FOR\", \"tail\": \"sample Hello World functionality\", \"tail_type\": \"ACTION\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "    {\"head\": \"Semantic Kernel\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USED_IN\", \"tail\": \"WebSearchEnginePlugin\", \"tail_type\": \"PRODUCT\"},\n",
      "    {\"head\": \"Will Velida\", \"head_type\": \"PERSON\", \"relation\": \"CREATED\", \"tail\": \"Using Bing Search API in the Semantic Kernel SDK\", \"tail_type\": \"VIDEO\"},\n",
      "    {\"head\": \"Bing Search API\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USED_IN\", \"tail\": \"Semantic Kernel SDK\", \"tail_type\": \"TECHNOLOGY\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"POSTED_ON\", \"tail\": \"Monday, June 10, 2024\", \"tail_type\": \"DATE\"},\n",
      "    {\"head\": \"Demo Review: Chat Copilot\", \"head_type\": \"BLOG_POST\", \"relation\": \"PART_OF\", \"tail\": \"The RAG Demo Chronicles\", \"tail_type\": \"BLOG_SERIES\"},\n",
      "    {\"head\": \"Retrieval Augmented Generation\", \"head_type\": \"TECHNOLOGY\", \"relation\": \"USED_IN\", \"tail\": \"Chat Copilot\", \"tail_type\": \"PRODUCT\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"POSTED_ON\", \"tail\": \"Tuesday, June 18, 2024\", \"tail_type\": \"DATE\"},\n",
      "    {\"head\": \"Bill Wilder\", \"head_type\": \"PERSON\", \"relation\": \"PRESENTED\", \"tail\": \"fundamentals of Generative AI\", \"tail_type\": \"TOPIC\"},\n",
      "    {\"head\": \"Bill Wilder\", \"head_type\": \"PERSON\", \"relation\": \"PRESENTED\", \"tail\": \"Azure AI Studio\", \"tail_type\": \"PRODUCT\"},\n",
      "    {\"head\": \"Jason\", \"head_type\": \"PERSON\", \"relation\": \"POSTED_ON\", \"tail\": \"Tuesday, June 25, 2024\", \"tail_type\": \"DATE\"}\n",
      "]\n",
      "```\n",
      "Assistant: ```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"Jason\",\n",
      "    \"head_type\": \"PERSON\",\n",
      "    \"relation\": \"POSTED_ON\",\n",
      "    \"tail\": \"Tuesday, June 25, 2024\",\n",
      "    \"tail_type\": \"EVENT\"\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"Study Notes: Text-to-SQL\",\n",
      "    \"head_type\": \"CREATIVE_WORK\",\n",
      "    \"relation\": \"WRITTEN_BY\",\n",
      "    \"tail\": \"Jason\",\n",
      "    \"tail_type\": \"PERSON\"\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"Jason\",\n",
      "    \"head_type\": \"PERSON\",\n",
      "    \"relation\": \"RESEARCHING\",\n",
      "    \"tail\": \"Text-to-SQL\",\n",
      "    \"tail_type\": \"TECHNOLOGY\"\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"Text-to-SQL\",\n",
      "    \"head_type\": \"TECHNOLOGY\",\n",
      "    \"relation\": \"ALSO_KNOWN_AS\",\n",
      "    \"tail\": \"Natural Language to SQL\",\n",
      "    \"tail_type\": \"TECHNOLOGY\"\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"Text-to-SQL\",\n",
      "    \"head_type\": \"TECHNOLOGY\",\n",
      "    \"relation\": \"USED_FOR\",\n",
      "    \"tail\": \"extend usage scenarios in a RAG application\",\n",
      "    \"tail_type\": \"ACTION\"\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"LLM\",\n",
      "    \"head_type\": \"TECHNOLOGY\",\n",
      "    \"relation\": \"GENERATE\",\n",
      "    \"tail\": \"SQL statements\",\n",
      "    \"tail_type\": \"ACTION\"\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"Jason\",\n",
      "    \"head_type\": \"PERSON\",\n",
      "    \"relation\": \"POSTED_ON\",\n",
      "    \"tail\": \"Friday, July 5, 2024\",\n",
      "    \"tail_type\": \"EVENT\"\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"Code Sample for Text-to-SQL\",\n",
      "    \"head_type\": \"CREATIVE_WORK\",\n",
      "    \"relation\": \"WRITTEN_BY\",\n",
      "    \"tail\": \"Jason\",\n",
      "    \"tail_type\": \"PERSON\"\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"Jason\",\n",
      "    \"head_type\": \"PERSON\",\n",
      "    \"relation\": \"POSTED_ON\",\n",
      "    \"tail\": \"Saturday, July 6, 2024\",\n",
      "    \"tail_type\": \"EVENT\"\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"Text-to-SQL Code\",\n",
      "    \"head_type\": \"PRODUCT\",\n",
      "    \"relation\": \"LOCATED_IN\",\n",
      "    \"tail\": \"GitHub repo semantic-kernel-getting-started\",\n",
      "    \"tail_type\": \"PLACE\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "Number of chunks: 8\n"
     ]
    }
   ],
   "source": [
    "ChatClient chatClient = client.GetChatClient(llm);\n",
    "string fileName = \"input/essay.txt\";\n",
    "string fileText = File.ReadAllText(fileName);\n",
    "\n",
    "DocunentMetadata documentMetatdata = new (Guid.NewGuid().ToString(\"N\"), fileName);\n",
    "\n",
    "var tokenizer = TiktokenTokenizer.CreateForModel(\"gpt-4o\");\n",
    "#pragma warning disable SKEXP0050\n",
    "var lines = TextChunker.SplitPlainTextLines(fileText, 500, text => tokenizer.CountTokens(text));\n",
    "var paragraphs = TextChunker.SplitPlainTextParagraphs(lines, 500, 100, null, text => tokenizer.CountTokens(text));\n",
    "\n",
    "string entityTypes = \"BLOG_POST,BOOK,MOVIE,PRESENTATION,EVENT,ORGANIZATION,PERSON,PLACE,PRODUCT,REVIEW,ACTION\";\n",
    "string relationTypes = \"INTRODUCED,USED_FOR,WRITTEN_IN,PART_OF,LOCATED_IN,GIVEN,LIVES_IN,TRAVELED_TO\";\n",
    "\n",
    "Dictionary<ChunkMetadata, List<TripletRow>> chunks = new Dictionary<ChunkMetadata, List<TripletRow>>();\n",
    "int maxTripletsPerChunk = 10;\n",
    "for (int i = 0; i < paragraphs.Count; i++)\n",
    "{\n",
    "    string text = paragraphs[i];\n",
    "\n",
    "    ChunkMetadata chunkMetadata = new (Guid.NewGuid().ToString(\"N\"), $\"DocumentChunk{i}\", i, documentMetatdata.id, text);\n",
    "\n",
    "\tstring prompt =  $@\"Please extract up to {maxTripletsPerChunk} knowledge triplets from the provied text.\n",
    "    Each triplet should be in the form of (head, relation, tail) with their respective types.\n",
    "    ######################\n",
    "    ONTOLOGY:\n",
    "    Entity Types: {entityTypes}\n",
    "    Relation Types: {relationTypes}\n",
    "    \n",
    "    Use these entity types and relation types as a starting point, introduce new types if necessary based on the context.\n",
    "    \n",
    "    GUIDELINES:\n",
    "    - Output in JSON format: [{{\"\"head\"\": \"\"\"\", \"\"head_type\"\": \"\"\"\", \"\"relation\"\": \"\"\"\", \"\"tail\"\": \"\"\"\", \"\"tail_type\"\": \"\"\"\"}}]\n",
    "    - Use the full form for entities (ie., 'Artificial Intelligence' instead of 'AI')\n",
    "    - Keep entities and relation names concise (3-5 words max)\n",
    "    - Break down complex phrases into multiple triplets\n",
    "    - Ensure the knowledge graph is coherent and easily understandable\n",
    "    ######################\n",
    "    EXAMPLE:\n",
    "    Text: Jason Haley, chief engineer of Jason Haley Consulting, wrote a new blog post titled 'Study Notes: GraphRAG - Property Grids' about creating a property grid RAG system using Semantic Kernel. \n",
    "    Output:\n",
    "    [{{\"\"head\"\": \"\"Jason Haley\"\", \"\"head_type\"\": \"\"PERSON\"\", \"\"relation\"\": \"\"SOFTWARE_DEVELOPER\"\", \"\"tail\"\": \"\"Jason Haley Consulting\"\", \"\"tail_type\"\": \"\"COMPANY\"\"}},\n",
    "     {{\"\"head\"\": \"\"Jason Haley Consulting.\"\", \"\"head_type\"\": \"\"COMPANY\"\", \"\"relation\"\": \"\"EMPLOYES\"\", \"\"tail\"\": \"\"Jason Haley\"\", \"\"tail_type\"\": \"\"PERSON\"\"}},\n",
    "     {{\"\"head\"\": \"\"Study Notes: GraphRAG - Property Grids\"\", \"\"head_type\"\": \"\"BLOG_POST\"\", \"\"relation\"\": \"\"WRITTEN_BY\"\", \"\"tail\"\": \"\"Jason Haley\"\", \"\"tail_type\"\": \"\"PERSON\"\"}},\n",
    "     {{\"\"head\"\": \"\"property grid RAG system\"\", \"\"head_type\"\": \"\"SOFTWARE_SYSTEM\"\", \"\"relation\"\": \"\"USES\"\", \"\"tail\"\": \"\"Semantic Kernel\"\", \"\"tail_type\"\": \"\"TECHNOLOGY\"\"}}]\n",
    "    ######################\n",
    "    Text: {text}\n",
    "    ######################\n",
    "    Output:\";\n",
    "\n",
    "\tChatCompletion completion = chatClient.CompleteChat(\n",
    "    \t[\n",
    "        \tnew UserChatMessage(prompt),\n",
    "    \t]);\n",
    "\n",
    "\tConsole.WriteLine($\"{completion.Role}: {completion.Content[0].Text}\");\n",
    "    List<TripletRow> rows =  JsonSerializer.Deserialize<List<TripletRow>>(completion.Content[0].Text.Replace(\"```json\", \"\").Replace(\"```\",\"\").Replace(\"'\", \"\").Trim());\n",
    "    \n",
    "    chunks.Add(chunkMetadata, rows);\n",
    "}\n",
    "\n",
    "Console.WriteLine($\"Number of chunks: {chunks.Count}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "public class Utilities\n",
    "{    \n",
    "    public static EntityMetadata PopulateEntityMetadata(ChunkMetadata chunkMetadata, TripletRow triplet, EntityMetadata entityMetadata, bool isHead = true)\n",
    "    {\n",
    "        entityMetadata.id = Guid.NewGuid().ToString(\"N\");\n",
    "\n",
    "        if (isHead)\n",
    "        {\n",
    "            entityMetadata.name = CreateName(triplet.head);\n",
    "            entityMetadata.type = triplet.head_type;\n",
    "            entityMetadata.text = triplet.head;\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            entityMetadata.name = CreateName(triplet.tail);\n",
    "            entityMetadata.type = triplet.tail_type;\n",
    "            entityMetadata.text = triplet.tail;\n",
    "        }\n",
    "\n",
    "        entityMetadata.mentionedInChunks.Add(chunkMetadata.id, chunkMetadata);\n",
    "        \n",
    "        return entityMetadata;\n",
    "    }\n",
    "\n",
    "    public static string CreateName(string text)\n",
    "    {\n",
    "        if (string.IsNullOrEmpty(text))\n",
    "            return text;\n",
    "\n",
    "        // Split the text into words\n",
    "        string[] words = text.Split(new[] { ' ', '-', '_' }, StringSplitOptions.RemoveEmptyEntries);\n",
    "\n",
    "        StringBuilder nameText = new StringBuilder();\n",
    "        \n",
    "        foreach (string word in words)\n",
    "        {\n",
    "            // Capitalize the first letter and make the rest lowercase\n",
    "            var lword = word;\n",
    "            if (char.IsDigit(word[0]))\n",
    "            {\n",
    "                lword = \"_\" + word;\n",
    "            }\n",
    "\n",
    "            nameText.Append(lword.ToLower());\n",
    "        }\n",
    "        return System.Text.RegularExpressions.Regex.Replace(nameText.ToString(), \"[^a-zA-Z0-9_]\", \"\");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique entity count: 107\r\n"
     ]
    }
   ],
   "source": [
    "Dictionary<string,EntityMetadata> entities = new Dictionary<string,EntityMetadata>();\n",
    "\n",
    "foreach (ChunkMetadata key in chunks.Keys)\n",
    "{\n",
    "    List<TripletRow> triplets = chunks[key];\n",
    "    foreach (var triplet in triplets)\n",
    "    {\n",
    "        EntityMetadata entity;\n",
    "        string pcHead = Utilities.CreateName(triplet.head);\n",
    "        if (entities.ContainsKey(pcHead)) \n",
    "        {\n",
    "            entity = entities[pcHead];\n",
    "            if (!entity.mentionedInChunks.ContainsKey(key.id))\n",
    "            {\n",
    "                entity.mentionedInChunks.Add(key.id, key);\n",
    "            }\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            entity = new EntityMetadata();   \n",
    "            entities.Add(pcHead, Utilities.PopulateEntityMetadata(key, triplet, entity, true));\n",
    "        }      \n",
    "\n",
    "        string pcTail = Utilities.CreateName(triplet.tail);\n",
    "        if (entities.ContainsKey(pcTail)) \n",
    "        {\n",
    "            entity = entities[pcTail];\n",
    "            if (!entity.mentionedInChunks.ContainsKey(key.id))\n",
    "            {\n",
    "                entity.mentionedInChunks.Add(key.id, key);\n",
    "            }\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            entity = new EntityMetadata();   \n",
    "            entities.Add(pcTail, Utilities.PopulateEntityMetadata(key, triplet, entity, false));\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "Console.WriteLine($\"Unique entity count: {entities.Count}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jason Mentioned In 8 chunks\n",
      "ai Mentioned In 1 chunks\n",
      "michaelwashington Mentioned In 1 chunks\n",
      "simplerag Mentioned In 1 chunks\n",
      "azuresearchopenaidemoc Mentioned In 1 chunks\n",
      "azuresearchopenaidemo Mentioned In 1 chunks\n",
      "familyofragdemos Mentioned In 1 chunks\n",
      "azuresearchopenaidemocsharp Mentioned In 1 chunks\n",
      "azuresearchopenaijavascript Mentioned In 1 chunks\n",
      "azuresearchopenaidemojava Mentioned In 1 chunks\n",
      "azuresearchopenaidemojavascripttypescript Mentioned In 1 chunks\n",
      "azuresearchopenaidemopython Mentioned In 2 chunks\n",
      "hacktogethertheaichatapphack Mentioned In 1 chunks\n",
      "azurevectorsearchaiassistant Mentioned In 1 chunks\n",
      "bostoncodecamp_36 Mentioned In 1 chunks\n",
      "talk Mentioned In 1 chunks\n",
      "billwilder Mentioned In 2 chunks\n",
      "virtualbostonazuremeetup Mentioned In 1 chunks\n",
      "aiminiworkshop Mentioned In 1 chunks\n",
      "mslearningpathapl_2005 Mentioned In 1 chunks\n",
      "globalazurebootcamp Mentioned In 1 chunks\n",
      "post_12 Mentioned In 1 chunks\n",
      "semantickernelhelloworldpluginspart_2 Mentioned In 1 chunks\n",
      "nativefunction Mentioned In 1 chunks\n",
      "post_13 Mentioned In 1 chunks\n",
      "nativefunctionplugin Mentioned In 1 chunks\n",
      "post_14 Mentioned In 1 chunks\n",
      "memphisazureusergroup Mentioned In 2 chunks\n",
      "presentation Mentioned In 1 chunks\n",
      "slidedeck Mentioned In 1 chunks\n",
      "semantickernel Mentioned In 1 chunks\n",
      "handlebarsplanner Mentioned In 1 chunks\n",
      "willvelida Mentioned In 1 chunks\n",
      "bingsearchapi Mentioned In 1 chunks\n",
      "chatcopilot Mentioned In 1 chunks\n",
      "githubrepo Mentioned In 1 chunks\n",
      "texttosql Mentioned In 1 chunks\n",
      "llm Mentioned In 1 chunks\n",
      "codesample Mentioned In 1 chunks\n",
      "githubreposemantickernelgettingstarted Mentioned In 1 chunks\n"
     ]
    }
   ],
   "source": [
    "foreach(var key in entities.Keys)\n",
    "{\n",
    "    var e = entities[key];\n",
    "    Console.WriteLine($\"{key} Mentioned In {e.mentionedInChunks.Count} chunks\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "List<string> entityCypherText = new List<string>(); // Document, DocumentChunk and Entity\n",
    "\n",
    "entityCypherText.Add($\"MERGE (Document1:DOCUMENT {{ id: '{documentMetatdata.id}', name:'Document1', type:'DOCUMENT', source: '{documentMetatdata.source}'}})\"); \n",
    "\n",
    "foreach (var chunk in chunks.Keys)\n",
    "{\n",
    "    entityCypherText.Add($\"MERGE (DocumentChunk{chunk.sequence}:DOCUMENT_CHUNK {{ id: '{chunk.id}', name: '{chunk.name}', type: 'DOCUMENT_CHUNK', documentId: '{chunk.documentId}', sequence: '{chunk.sequence}', text: \\\"{chunk.text.Replace(\"\\\"\", \"'\")}\\\"}})\");\n",
    "    entityCypherText.Add($\"MERGE (Document1)-[:CONTAINS]->(DocumentChunk{chunk.sequence})\");\n",
    "}\n",
    "\n",
    "HashSet<string> types = new HashSet<string>();\n",
    "foreach(var entity in entities.Keys)\n",
    "{\n",
    "    var labels = entities[entity];\n",
    "    var pcEntity = entity;\n",
    "    entityCypherText.Add($\"MERGE ({pcEntity}:ENTITY {{ name: '{pcEntity}', type: '{labels.type}', id: '{labels.id}', text: '{labels.text}'}})\");\n",
    "\n",
    "    if (!types.Contains(labels.type))\n",
    "    {\n",
    "        types.Add(labels.type);\n",
    "    }\n",
    "\n",
    "    foreach(var key in labels.mentionedInChunks.Keys)\n",
    "    {\n",
    "        var documentChunk = labels.mentionedInChunks[key];\n",
    "        entityCypherText.Add($\"MERGE ({pcEntity})-[:MENTIONED_IN]->(DocumentChunk{documentChunk.sequence})\");\n",
    "    }\n",
    "}\n",
    "\n",
    "HashSet<string> relationships = new HashSet<string>();\n",
    "foreach (ChunkMetadata key in chunks.Keys)\n",
    "{\n",
    "    List<TripletRow> triplets = chunks[key];\n",
    "    foreach (var triplet in triplets)\n",
    "    {\n",
    "        var pcHead = Utilities.CreateName(triplet.head);\n",
    "        var pcTail = Utilities.CreateName(triplet.tail);\n",
    "        entityCypherText.Add($\"MERGE ({pcHead})-[:{triplet.relation.Replace(\" \", \"_\").Replace(\"-\",\"_\")}]->({pcTail})\");\n",
    "\n",
    "        string headRelationship = $\"MERGE (DocumentChunk{key.sequence})-[:MENTIONS]->({pcHead})\";\n",
    "        if (!relationships.Contains(headRelationship))\n",
    "        {\n",
    "            relationships.Add(headRelationship);\n",
    "            entityCypherText.Add(headRelationship);\n",
    "        }\n",
    "        \n",
    "        string tailRelationship = $\"MERGE (DocumentChunk{key.sequence})-[:MENTIONS]->({pcTail})\";\n",
    "        if (!relationships.Contains(tailRelationship))\n",
    "        {\n",
    "            relationships.Add(tailRelationship);\n",
    "            entityCypherText.Add(tailRelationship);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERGE (Document1:DOCUMENT { id: 'f6e5d401d98c43eb808bf2d819ae0df6', name:'Document1', type:'DOCUMENT', source: 'input/essay.txt'})\n",
      "MERGE (DocumentChunk0:DOCUMENT_CHUNK { id: 'dd5b6e0011c748b1a0fcee1a066f7514', name: 'DocumentChunk0', type: 'DOCUMENT_CHUNK', documentId: 'f6e5d401d98c43eb808bf2d819ae0df6', sequence: '0', text: \"Post 1 (Personal Update) Learning AI\n",
      "This is the first of many blog posts I plan to make this year, stay tuned (please subscribe) for more soon. Learning AI Currently I am working my way through the four stages of competence with the topic of AI. This quarter (Q1 of 2024), I’m currently working on moving from stage 2 to stage 3 in the four stages of competence. For reference, those stages are: Unconscious incompetence Conscious incompetence Conscious competence Unconscious competence Last year I moved from stage 1 to stage 2: In the beginning of last year (2023) I had my head buried in the sand while all the other leaders in my industry were actively learning how to use the latest and greatest AI tool (ChatGPT).\n",
      "Posted byJason Thursday, January 18, 2024\n",
      "\n",
      "Post 2 Demo Review: Simple RAG using SQL Server and OpenAI\n",
      "Demo Review: Simple RAG using Blazor, SQL Server and Azure OpenAI Are you a full stack C# developer attempting to get up to speed on all this GenAI stuff? Are you typically a relational database developer (ie. SQL Server) wondering what all the hoopla is around vector databases and more importantly how all this stuff relates to some type of functionaly that you have a chance at really using in your day-to-day work?\n",
      "Posted byJason Wednesday, February 7, 2024\n",
      "\n",
      "Post 3 Demo Review: Simple RAG using SQL Server, OpenAI and Function Calling Demo Review: Simple RAG using Blazor, SQL Server, Azure OpenAI and Function Calling If you are like me, a full stack C# developer who is attempting to get up to speed on how GenAI technologies are going to show up in our business applictions - then after you get the first demo up and running, this demo (also by Michael Washington) is a great next step. RAG (Retrieval Augmented Generation) applications typically have the following steps:\n",
      "\"})\n",
      "MERGE (Document1)-[:CONTAINS]->(DocumentChunk0)\n",
      "MERGE (DocumentChunk1:DOCUMENT_CHUNK { id: '41296538f20843a1837d6b97c856c037', name: 'DocumentChunk1', type: 'DOCUMENT_CHUNK', documentId: 'f6e5d401d98c43eb808bf2d819ae0df6', sequence: '1', text: \"Demo Review: Simple RAG using Blazor, SQL Server, Azure OpenAI and Function Calling If you are like me, a full stack C# developer who is attempting to get up to speed on how GenAI technologies are going to show up in our business applictions - then after you get the first demo up and running, this demo (also by Michael Washington) is a great next step. RAG (Retrieval Augmented Generation) applications typically have the following steps:\n",
      "Posted byJason Sunday, February 11, 2024\n",
      "\n",
      "Post 4 Demo Review: Azure Search OpenAI Demo C#\n",
      "Demo Review: Azure Search OpenAI Demo C# If you are looking for Retrieval Augmented Generation (RAG) demos that utilize Azure Search and Azure OpenAI (along with several other supporting Azure services), then there is a set of related demos that do just that in GitHub. This family of RAG demos consists of: azure-search-openai-demo-csharp - written in C#. azure-search-openai-demo - written in python. azure-search-openai-javascript - written in javascript/typescript. azure-search-openai-demo-java - written in java.\n",
      "Posted byJason Wednesday, February 14, 2024\n",
      "\n",
      "Post 5 Demo Review: Azure Search OpenAI Javascript/Typescript\n",
      "Demo Review: Azure Search OpenAI Javascript/Typescript This is the second in the family of Azure Search OpenAI demos that I’m reviewing. Last week I reviewed the C# version. As you’ll see below, the Javascript version is a bit different. The user interface (UI) functionality is provided by a set of web components that you can add to about any web application (ie. React, Angular, Vue, etc.) - in fact the web application in the demo is written in React.\n",
      "Posted byJason Monday, February 19, 2024\n",
      "\n",
      "Post 6 Demo Review: Azure Search OpenAI Demo (Python) Demo Review: Azure Search OpenAI Demo (Python) This is the last in the family of Azure Search OpenAI demos that I’m covering (I’m not looking at the Java version). I reviewed the C# version and the Javascript/Typescript version earlier this month.\"})\n",
      "MERGE (Document1)-[:CONTAINS]->(DocumentChunk1)\n",
      "MERGE (DocumentChunk2:DOCUMENT_CHUNK { id: '99e4ca795e804be881735c6339051d8b', name: 'DocumentChunk2', type: 'DOCUMENT_CHUNK', documentId: 'f6e5d401d98c43eb808bf2d819ae0df6', sequence: '2', text: \"Demo Review: Azure Search OpenAI Demo (Python) This is the last in the family of Azure Search OpenAI demos that I’m covering (I’m not looking at the Java version). I reviewed the C# version and the Javascript/Typescript version earlier this month. Of the three I’m covering, this one seems to be the most active, popular and have the most documentation. At the beginning of this month, the Hack Together: The AI Chat App Hack used this demo at the sample repository, marking it as a solid reference implementation for RAG.\n",
      "Posted byJason Friday, February 23, 2024\n",
      "\n",
      "Post 7 Demo Review: Azure Vector Search AI Assistant\n",
      "Demo Review: Azure Vector Search AI Assistant This is the fourth C# demo in The RAG Demo Chronicles (Blog Series) and is the first demo so far that saves its history to a database. This Retrieval Augmented Generation (RAG) demo is a little different than the last three because it primarily uses data from a database as the content to search instead of documents. It also uses Semantic Kernel more than other demos have, which is neat to see too.\n",
      "Posted byJason Monday, February 26, 2024\n",
      "\n",
      "Post 8 Boston Code Camp 36 Sessions\n",
      "Yesterday was Boston Code Camp 36 hard to believe it has been going on for 20+ years now. For me it is one of those regular events for the Boston tech community that is well worth spending a Saturday attending. It was nice to see a lot of regular faces and meet some new people. Talk: Getting Started with Retrieval Augmented Generation (RAG) I was surprise the room was full, it was good to see so many developers, students and architects - mostly with . Posted byJason Sunday, March 24, 2024\n",
      "\n",
      "Post 9 Semantic Kernel Hello World\n",
      "\"})\n",
      "MERGE (Document1)-[:CONTAINS]->(DocumentChunk2)\n",
      "MERGE (DocumentChunk3:DOCUMENT_CHUNK { id: '6a5833946992430e806b33db1ffc45d0', name: 'DocumentChunk3', type: 'DOCUMENT_CHUNK', documentId: 'f6e5d401d98c43eb808bf2d819ae0df6', sequence: '3', text: \"Posted byJason Sunday, March 24, 2024\n",
      "\n",
      "Post 9 Semantic Kernel Hello World\n",
      "This past Thursday night after the Virtual Boston Azure meetup, Bill Wilder (@codingoutloud) created an AI mini-workshop (hands on) for the attendees that were interested in getting hands on with code using the Azure OpenAI API. This post is me using the same idea but with Semantic Kernel. OpenAI Chat Hello World C# Bill provided the following code for us to get a simple OpenAI chat working: using Azure; using Azure.\n",
      "Posted byJason Saturday, March 30, 2024\n",
      "\n",
      "Post 10 Semantic Kernel Hello World Plugins Part 1\n",
      "A couple of weeks ago, in my last entry I created a simple Hello World application with Semantic Kernel. Since then, I’ve worked my way through the MS Learning path: APL-2005 Develop AI agents using Azure OpenAI and the Semantic Kernel SDK - which I highly recommend if you are also learning SK. In this entry I’m going to start with the code from the last entry and extract the prompt to a plugin.\n",
      "Posted byJason Thursday, April 11, 2024\n",
      "\n",
      "Post 11 My Session at Boston Global Azure Bootcamp\n",
      "This past weekend was Boston Azure’s Edition of the annual Global Azure Bootcamp. This year we focused on AI and hands-on-labs. The odd thing about when we scheduled the meetup was we had a lot of people sign up for the group just to rsvp - before most of the existing members had gotten around to rsvp’ing. We did not expect that. It is a mystery as how they heard about the event so quick. Posted byJason Tuesday, April 23, 2024\n",
      "\n",
      "Post 12 Semantic Kernel Hello World Plugins Part 2\n",
      "\"})\n",
      "MERGE (Document1)-[:CONTAINS]->(DocumentChunk3)\n",
      "MERGE (DocumentChunk4:DOCUMENT_CHUNK { id: '3245effc3bfa4d7380e954700245b4c5', name: 'DocumentChunk4', type: 'DOCUMENT_CHUNK', documentId: 'f6e5d401d98c43eb808bf2d819ae0df6', sequence: '4', text: \"Posted byJason Tuesday, April 23, 2024\n",
      "\n",
      "Post 12 Semantic Kernel Hello World Plugins Part 2\n",
      "Two weeks ago I blogged Part 1, in which I moved the prompt to a prompt template. In this part, I implement a native function that will take in the current date and make the call to the LLM. I’ve put the code for this blog in the HelloWorld.Plugin2.Console project in the same repo as the other SK entries: semantic-kernel-getting-started. Semantic Kernel Plugin: Native Function There is a good Microsoft Learn module: Give your AI agent skills that walks you through the details of what a native function is and how to implement them.\n",
      "Posted byJason Friday, April 26, 2024\n",
      "\n",
      "Post 13 Semantic Kernel Hello World Plugins Part 3\n",
      "Last week I blogged Part 2 showing the creation of a native function plugin, in this post I want to take that native function a step further and use the OpenAI Function calling. This will allow us to not provide the current date when making the call to get a historic daily fact and have OpenAI call a function to get the current date. I’ve added the HelloWorld.Plugin3.Console project to the GitHub repo for the code in this blog entry.\n",
      "Posted byJason Tuesday, April 30, 2024\n",
      "\n",
      "Post 14 Memphis Azure User Group Last Thursday night I spoke at the Memphis Azure User Group, it was nice to meet some people in person and see how excited others are about finding valuable ways to work GenAI into their applications.\"})\n",
      "MERGE (Document1)-[:CONTAINS]->(DocumentChunk4)\n",
      "MERGE (DocumentChunk5:DOCUMENT_CHUNK { id: '4f479cf64cf44c13844020afd7c3dd1d', name: 'DocumentChunk5', type: 'DOCUMENT_CHUNK', documentId: 'f6e5d401d98c43eb808bf2d819ae0df6', sequence: '5', text: \"Last Thursday night I spoke at the Memphis Azure User Group, it was nice to meet some people in person and see how excited others are about finding valuable ways to work GenAI into their applications. I also gave my slide deck a completely new look (Memphis themed via Bing/create): Talk: Getting Started with Retrieval Augmented Generation (RAG) The presentation pdf can be downloaded here. Since the presentation was hybrid, there were not as many questions as the other two times I’ve given the talk … or that is my guess at the reason why it was so quiet.\n",
      "Posted byJason Tuesday, May 7, 2024\n",
      "\n",
      "Post 15 Semantic Kernel Hello World Planners Part 1\n",
      "A few weeks ago in the Semantic Kernel Hello World Plugins Part 3 blog entry, I showed how to use OpenAI Function Calling. The last half of that entry was all about how to view the response and request JSON going back and forth to OpenAI, which detailed four API calls. In this entry I look at using the Handlebars Planner to accomplish the same functionality. Then I’ll show the request and response JSON for both using a saved plan as well as having the LLM create a plan and end with a token usage comparison.\n",
      "Posted byJason Sunday, May 19, 2024\n",
      "\n",
      "Post 16 Semantic Kernel Hello World Planners Part 2\n",
      "Last week in the Semantic Kernel Hello World Planners Part 1 entry, I used the Handlebars planner to implement the sample Hello World functionality and then looked at the token difference between using a saved plan vs. generating a plan. In this entry I use the Function Calling Stepwise Planner to create the sample Hello World functionality and compare it to the implementation in the Semantic Kernel Hello World Plugins Part 3 entry.\n",
      "Posted byJason Monday, May 27, 2024 Post 17 Semantic Kernel Hello World WebSearchEnginePlugin\n",
      "\"})\n",
      "MERGE (Document1)-[:CONTAINS]->(DocumentChunk5)\n",
      "MERGE (DocumentChunk6:DOCUMENT_CHUNK { id: '6961feeb0bf14914a7b8bbecfd6566e1', name: 'DocumentChunk6', type: 'DOCUMENT_CHUNK', documentId: 'f6e5d401d98c43eb808bf2d819ae0df6', sequence: '6', text: \"Post 17 Semantic Kernel Hello World WebSearchEnginePlugin\n",
      "A couple of weeks ago I thought I’d written my last of these blogs, mainly due to me getting more in depth with Semantic Kernel. However, after I watched Will Velida’s video Using Bing Search API in the Semantic Kernel SDK … I couldn’t help but wonder what the API calls were behind the scenes. Will does a great job at explaining how to use the plugin and the Bing resource needed to make calls to the search API, so I won’t get into that part of it - I want to focus on the usefulness and API calls made by the plugin.\n",
      "Posted byJason Monday, June 10, 2024\n",
      "\n",
      "Post 18 Demo Review: Chat Copilot\n",
      "Demo Review: Chat Copilot This is the fifth C# demo in The RAG Demo Chronicles (Blog Series) and has the most extensive use of Semantic Kernel out of all the demos I’ve reviewed. The use of Retrieval Augmented Generation (RAG) is different with this project than the other demos I’ve reviewed - mainly because RAG is just one of its features. With this demo, I also took the time to configure the optional authentication so I could play with the MS Graph plugin … and WOW!\n",
      "Posted byJason Tuesday, June 18, 2024\n",
      "\n",
      "Post 19 Boston Azure June 2024\n",
      "Last night was the Season of AI presentation. We started with Bill Wilder presenting the fundamentals of Generative AI and quick introduction to Azure AI Studio, then I finished up with a .NET code walkthrough implement Retrieval Augmented Generation (RAG) using Semantic Kernel. It was nice to see a lot of regular faces and meet several new people. Demo Code The demo code is on my GitHub repo BostonAzure-June2024 under a subdirectory. Posted byJason Tuesday, June 25, 2024\n",
      "\n",
      "Post 20 Study Notes: Text-to-SQL\n",
      "\"})\n",
      "MERGE (Document1)-[:CONTAINS]->(DocumentChunk6)\n",
      "MERGE (DocumentChunk7:DOCUMENT_CHUNK { id: '4d271029c1774124a5bf7588f26b81ca', name: 'DocumentChunk7', type: 'DOCUMENT_CHUNK', documentId: 'f6e5d401d98c43eb808bf2d819ae0df6', sequence: '7', text: \"Posted byJason Tuesday, June 25, 2024\n",
      "\n",
      "Post 20 Study Notes: Text-to-SQL\n",
      "This week I’ve been researching Text-to-SQL (also known as Natural Language to SQL), below are my study notes to compile all the resources I’ve found on the topic to date. There is also a corresponding blog entry that walks through a code example. NOTE: I am approaching this topic specifically looking at how it can be used to extend usage scenarios in a RAG application. Background Text-to-SQL (or Natural Language to SQL) is a pattern where the objective is to have an LLM generate SQL statements for a database using natural language.\n",
      "Posted byJason Friday, July 5, 2024\n",
      "\n",
      "Post 21 Study Notes: Text-to-SQL Code Sample\n",
      "Yesterday I posted my notes from this week’s study topic of Text-to-SQL, which if you haven’t read it - provides more information and resources about the topic. In this entry I want to walk through a code sample I put together after playing with a few samples this week. Where To Get The Code The code for this entry is in my GitHub repo semantic-kernel-getting-started under the samples/demos/Text-to-Sql directory. Originally I considered making this a review of the NL2SQL code sample, but I ended up needing to make some changes to it, so I just copied over some of their code for my sample - that is why the nl2sql.\n",
      "Posted byJason Saturday, July 6, 2024\"})\n",
      "MERGE (Document1)-[:CONTAINS]->(DocumentChunk7)\n",
      "MERGE (jason:ENTITY { name: 'jason', type: 'PERSON', id: 'f9ce3b2ce91f4ed886f4b314905c9f71', text: 'Jason'})\n",
      "MERGE (jason)-[:MENTIONED_IN]->(DocumentChunk0)\n",
      "MERGE (jason)-[:MENTIONED_IN]->(DocumentChunk1)\n",
      "MERGE (jason)-[:MENTIONED_IN]->(DocumentChunk2)\n",
      "MERGE (jason)-[:MENTIONED_IN]->(DocumentChunk3)\n",
      "MERGE (jason)-[:MENTIONED_IN]->(DocumentChunk4)\n",
      "MERGE (jason)-[:MENTIONED_IN]->(DocumentChunk5)\n",
      "MERGE (jason)-[:MENTIONED_IN]->(DocumentChunk6)\n",
      "MERGE (jason)-[:MENTIONED_IN]->(DocumentChunk7)\n",
      "MERGE (ai:ENTITY { name: 'ai', type: 'TECHNOLOGY', id: '452e25b8ce514d4b8b54f1f9561b04b2', text: 'AI'})\n",
      "MERGE (ai)-[:MENTIONED_IN]->(DocumentChunk0)\n",
      "MERGE (michaelwashington:ENTITY { name: 'michaelwashington', type: 'PERSON', id: 'ce3e3db944d7468198601b15f489315b', text: 'Michael Washington'})\n",
      "MERGE (michaelwashington)-[:MENTIONED_IN]->(DocumentChunk0)\n",
      "MERGE (simplerag:ENTITY { name: 'simplerag', type: 'CONCEPT', id: 'a9147e223ccd4b638d686bf3edf1785f', text: 'Simple RAG'})\n",
      "MERGE (simplerag)-[:MENTIONED_IN]->(DocumentChunk1)\n",
      "MERGE (azuresearchopenaidemoc:ENTITY { name: 'azuresearchopenaidemoc', type: 'PRODUCT', id: '1ba755d0ce9d43e7b1b08e03409df220', text: 'Azure Search OpenAI Demo C#'})\n",
      "MERGE (azuresearchopenaidemoc)-[:MENTIONED_IN]->(DocumentChunk1)\n",
      "MERGE (azuresearchopenaidemo:ENTITY { name: 'azuresearchopenaidemo', type: 'PRODUCT', id: '363a08c499b343adbb5ae9fa89c409d0', text: 'Azure Search OpenAI Demo'})\n",
      "MERGE (azuresearchopenaidemo)-[:MENTIONED_IN]->(DocumentChunk1)\n",
      "MERGE (familyofragdemos:ENTITY { name: 'familyofragdemos', type: 'CONCEPT', id: 'd8ee37acdd5b4106b09a3ec79ce435f6', text: 'Family of RAG demos'})\n",
      "MERGE (familyofragdemos)-[:MENTIONED_IN]->(DocumentChunk1)\n",
      "MERGE (azuresearchopenaidemocsharp:ENTITY { name: 'azuresearchopenaidemocsharp', type: 'PRODUCT', id: '56680792e41846e580faf93a63c93eaa', text: 'azure-search-openai-demo-csharp'})\n",
      "MERGE (azuresearchopenaidemocsharp)-[:MENTIONED_IN]->(DocumentChunk1)\n",
      "MERGE (azuresearchopenaijavascript:ENTITY { name: 'azuresearchopenaijavascript', type: 'PRODUCT', id: '2c20b5aacc4042e486b042ec97dd8cab', text: 'azure-search-openai-javascript'})\n",
      "MERGE (azuresearchopenaijavascript)-[:MENTIONED_IN]->(DocumentChunk1)\n",
      "MERGE (azuresearchopenaidemojava:ENTITY { name: 'azuresearchopenaidemojava', type: 'PRODUCT', id: '20da643fe67d4c438efd3dcfdbb3f8a2', text: 'azure-search-openai-demo-java'})\n",
      "MERGE (azuresearchopenaidemojava)-[:MENTIONED_IN]->(DocumentChunk1)\n",
      "MERGE (azuresearchopenaidemojavascripttypescript:ENTITY { name: 'azuresearchopenaidemojavascripttypescript', type: 'PRODUCT', id: '5559c87a5cc746e19f4dbc66581a1c2f', text: 'Azure Search OpenAI Demo Javascript/Typescript'})\n",
      "MERGE (azuresearchopenaidemojavascripttypescript)-[:MENTIONED_IN]->(DocumentChunk1)\n",
      "MERGE (azuresearchopenaidemopython:ENTITY { name: 'azuresearchopenaidemopython', type: 'PRODUCT', id: '24bf96886c9f4dd59e014b6946ba318e', text: 'Azure Search OpenAI Demo (Python)'})\n",
      "MERGE (azuresearchopenaidemopython)-[:MENTIONED_IN]->(DocumentChunk1)\n",
      "MERGE (azuresearchopenaidemopython)-[:MENTIONED_IN]->(DocumentChunk2)\n",
      "MERGE (hacktogethertheaichatapphack:ENTITY { name: 'hacktogethertheaichatapphack', type: 'EVENT', id: 'eb5b3776ebe7402782033f54a8252c1b', text: 'Hack Together: The AI Chat App Hack'})\n",
      "MERGE (hacktogethertheaichatapphack)-[:MENTIONED_IN]->(DocumentChunk2)\n",
      "MERGE (azurevectorsearchaiassistant:ENTITY { name: 'azurevectorsearchaiassistant', type: 'PRODUCT', id: '9989df0265a64b44b71de058adff2ea8', text: 'Azure Vector Search AI Assistant'})\n",
      "MERGE (azurevectorsearchaiassistant)-[:MENTIONED_IN]->(DocumentChunk2)\n",
      "MERGE (bostoncodecamp_36:ENTITY { name: 'bostoncodecamp_36', type: 'EVENT', id: '8da73e32d0ac46958f454310deeb5b9e', text: 'Boston Code Camp 36'})\n",
      "MERGE (bostoncodecamp_36)-[:MENTIONED_IN]->(DocumentChunk2)\n",
      "MERGE (talk:ENTITY { name: 'talk', type: 'EVENT', id: 'b12a5bf4cfbe4fb78082a7f64f3e7dd7', text: 'Talk'})\n",
      "MERGE (talk)-[:MENTIONED_IN]->(DocumentChunk2)\n",
      "MERGE (billwilder:ENTITY { name: 'billwilder', type: 'PERSON', id: 'bf8310459bde43918e827da4a3fef38f', text: 'Bill Wilder'})\n",
      "MERGE (billwilder)-[:MENTIONED_IN]->(DocumentChunk3)\n",
      "MERGE (billwilder)-[:MENTIONED_IN]->(DocumentChunk6)\n",
      "MERGE (virtualbostonazuremeetup:ENTITY { name: 'virtualbostonazuremeetup', type: 'EVENT', id: '5cbebdb70d0c4970836e5f73575151e2', text: 'Virtual Boston Azure meetup'})\n",
      "MERGE (virtualbostonazuremeetup)-[:MENTIONED_IN]->(DocumentChunk3)\n",
      "MERGE (aiminiworkshop:ENTITY { name: 'aiminiworkshop', type: 'EVENT', id: 'f038c8e8895f4b7bbe9ace5e356bbba4', text: 'AI mini-workshop'})\n",
      "MERGE (aiminiworkshop)-[:MENTIONED_IN]->(DocumentChunk3)\n",
      "MERGE (mslearningpathapl_2005:ENTITY { name: 'mslearningpathapl_2005', type: 'CONCEPT', id: '1db3d91ea4414c01a7c5ab53e15e0efe', text: 'MS Learning path: APL-2005'})\n",
      "MERGE (mslearningpathapl_2005)-[:MENTIONED_IN]->(DocumentChunk3)\n",
      "MERGE (globalazurebootcamp:ENTITY { name: 'globalazurebootcamp', type: 'EVENT', id: '1b38eb63bee34eef939fbcd36c39c06b', text: 'Global Azure Bootcamp'})\n",
      "MERGE (globalazurebootcamp)-[:MENTIONED_IN]->(DocumentChunk3)\n",
      "MERGE (post_12:ENTITY { name: 'post_12', type: 'EVENT', id: '77a393a6ba814094a03b73ad3fbcf11f', text: 'Post 12'})\n",
      "MERGE (post_12)-[:MENTIONED_IN]->(DocumentChunk4)\n",
      "MERGE (semantickernelhelloworldpluginspart_2:ENTITY { name: 'semantickernelhelloworldpluginspart_2', type: 'MISCELLANEOUS', id: '9cc7d904564e40169607d0f1db85aae3', text: 'Semantic Kernel Hello World Plugins Part 2'})\n",
      "MERGE (semantickernelhelloworldpluginspart_2)-[:MENTIONED_IN]->(DocumentChunk4)\n",
      "MERGE (nativefunction:ENTITY { name: 'nativefunction', type: 'TECHNOLOGY', id: '178b0c196b5744a7ae33a17b2741b408', text: 'native function'})\n",
      "MERGE (nativefunction)-[:MENTIONED_IN]->(DocumentChunk4)\n",
      "MERGE (post_13:ENTITY { name: 'post_13', type: 'EVENT', id: '83fddb65a62a4437a4e0d507e776ace6', text: 'Post 13'})\n",
      "MERGE (post_13)-[:MENTIONED_IN]->(DocumentChunk4)\n",
      "MERGE (nativefunctionplugin:ENTITY { name: 'nativefunctionplugin', type: 'TECHNOLOGY', id: '4614b4711744412383126898a18119f5', text: 'native function plugin'})\n",
      "MERGE (nativefunctionplugin)-[:MENTIONED_IN]->(DocumentChunk4)\n",
      "MERGE (post_14:ENTITY { name: 'post_14', type: 'EVENT', id: '4be2ae7741e144edb2343faa596472df', text: 'Post 14'})\n",
      "MERGE (post_14)-[:MENTIONED_IN]->(DocumentChunk4)\n",
      "MERGE (memphisazureusergroup:ENTITY { name: 'memphisazureusergroup', type: 'ORGANIZATION', id: 'e90df60a0d5044df820e97a657d6b64e', text: 'Memphis Azure User Group'})\n",
      "MERGE (memphisazureusergroup)-[:MENTIONED_IN]->(DocumentChunk4)\n",
      "MERGE (memphisazureusergroup)-[:MENTIONED_IN]->(DocumentChunk5)\n",
      "MERGE (presentation:ENTITY { name: 'presentation', type: 'EVENT', id: 'eb4ab11108d14e568d7d5343adbe739b', text: 'Presentation'})\n",
      "MERGE (presentation)-[:MENTIONED_IN]->(DocumentChunk5)\n",
      "MERGE (slidedeck:ENTITY { name: 'slidedeck', type: 'PRODUCT', id: '64340ba904c5478e987a0e80c044df50', text: 'slide deck'})\n",
      "MERGE (slidedeck)-[:MENTIONED_IN]->(DocumentChunk5)\n",
      "MERGE (semantickernel:ENTITY { name: 'semantickernel', type: 'TECHNOLOGY', id: '7ff0d2d362284b30a52574a41f0cd880', text: 'Semantic Kernel'})\n",
      "MERGE (semantickernel)-[:MENTIONED_IN]->(DocumentChunk5)\n",
      "MERGE (handlebarsplanner:ENTITY { name: 'handlebarsplanner', type: 'TECHNOLOGY', id: '9d5aec469de3404aa44dc91d24cca1a6', text: 'Handlebars Planner'})\n",
      "MERGE (handlebarsplanner)-[:MENTIONED_IN]->(DocumentChunk5)\n",
      "MERGE (willvelida:ENTITY { name: 'willvelida', type: 'PERSON', id: '3dd17d988372461e8b101b0375fbc3e7', text: 'Will Velida'})\n",
      "MERGE (willvelida)-[:MENTIONED_IN]->(DocumentChunk6)\n",
      "MERGE (bingsearchapi:ENTITY { name: 'bingsearchapi', type: 'TECHNOLOGY', id: 'd664a479359b47528a425575d057acff', text: 'Bing Search API'})\n",
      "MERGE (bingsearchapi)-[:MENTIONED_IN]->(DocumentChunk6)\n",
      "MERGE (chatcopilot:ENTITY { name: 'chatcopilot', type: 'TECHNOLOGY', id: 'd20d5bc9329b4ffc8b0cb64ea3528953', text: 'Chat Copilot'})\n",
      "MERGE (chatcopilot)-[:MENTIONED_IN]->(DocumentChunk6)\n",
      "MERGE (githubrepo:ENTITY { name: 'githubrepo', type: 'TECHNOLOGY', id: '6eedbaa734534c468bfbf403a586f392', text: 'GitHub repo'})\n",
      "MERGE (githubrepo)-[:MENTIONED_IN]->(DocumentChunk6)\n",
      "MERGE (texttosql:ENTITY { name: 'texttosql', type: 'TECHNOLOGY', id: '2d339251dbcc40a9a063194cd4431f9e', text: 'Text-to-SQL'})\n",
      "MERGE (texttosql)-[:MENTIONED_IN]->(DocumentChunk7)\n",
      "MERGE (llm:ENTITY { name: 'llm', type: 'CONCEPT', id: '79b8a0df5e23494aa76cdf93b64e347c', text: 'LLM'})\n",
      "MERGE (llm)-[:MENTIONED_IN]->(DocumentChunk7)\n",
      "MERGE (codesample:ENTITY { name: 'codesample', type: 'PRODUCT', id: '1827bfcde5e149e5940009ba679e38ac', text: 'code sample'})\n",
      "MERGE (codesample)-[:MENTIONED_IN]->(DocumentChunk7)\n",
      "MERGE (githubreposemantickernelgettingstarted:ENTITY { name: 'githubreposemantickernelgettingstarted', type: 'LOCATION', id: '34cfed5e13334df2a20ef3f81fdb29ea', text: 'GitHub repo semantic-kernel-getting-started'})\n",
      "MERGE (githubreposemantickernelgettingstarted)-[:MENTIONED_IN]->(DocumentChunk7)\n",
      "MERGE (jason)-[:POSTED]->(personalupdate)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(jason)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(personalupdate)\n",
      "MERGE (jason)-[:WORKING_ON]->(fourstagesofcompetence)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(fourstagesofcompetence)\n",
      "MERGE (jason)-[:WORKING_ON]->(competenceinai)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(competenceinai)\n",
      "MERGE (ai)-[:HAS_STAGE]->(unconsciousincompetence)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(ai)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(unconsciousincompetence)\n",
      "MERGE (ai)-[:HAS_STAGE]->(consciousincompetence)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(consciousincompetence)\n",
      "MERGE (ai)-[:HAS_STAGE]->(consciouscompetence)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(consciouscompetence)\n",
      "MERGE (ai)-[:HAS_STAGE]->(unconsciouscompetence)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(unconsciouscompetence)\n",
      "MERGE (jason)-[:USED]->(chatgpt)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(chatgpt)\n",
      "MERGE (jason)-[:POSTED]->(demoreviewsimpleragusingsqlserverandopenai)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(demoreviewsimpleragusingsqlserverandopenai)\n",
      "MERGE (michaelwashington)-[:CREATED]->(simpleragdemo)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(michaelwashington)\n",
      "MERGE (DocumentChunk0)-[:MENTIONS]->(simpleragdemo)\n",
      "MERGE (simplerag)-[:USES]->(blazor)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(simplerag)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(blazor)\n",
      "MERGE (simplerag)-[:USES]->(sqlserver)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(sqlserver)\n",
      "MERGE (simplerag)-[:USES]->(azureopenai)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(azureopenai)\n",
      "MERGE (simplerag)-[:USES]->(functioncalling)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(functioncalling)\n",
      "MERGE (jason)-[:POSTED_ON]->(february_11_2024)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(jason)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(february_11_2024)\n",
      "MERGE (azuresearchopenaidemoc)-[:WRITTEN_IN]->(c)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(azuresearchopenaidemoc)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(c)\n",
      "MERGE (azuresearchopenaidemo)-[:CONTAINS]->(azuresearch)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(azuresearchopenaidemo)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(azuresearch)\n",
      "MERGE (azuresearchopenaidemo)-[:CONTAINS]->(azureopenai)\n",
      "MERGE (familyofragdemos)-[:INCLUDES]->(azuresearchopenaidemocsharp)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(familyofragdemos)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(azuresearchopenaidemocsharp)\n",
      "MERGE (azuresearchopenaidemocsharp)-[:WRITTEN_IN]->(c)\n",
      "MERGE (azuresearchopenaidemo)-[:WRITTEN_IN]->(python)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(python)\n",
      "MERGE (azuresearchopenaijavascript)-[:WRITTEN_IN]->(javascripttypescript)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(azuresearchopenaijavascript)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(javascripttypescript)\n",
      "MERGE (azuresearchopenaidemojava)-[:WRITTEN_IN]->(java)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(azuresearchopenaidemojava)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(java)\n",
      "MERGE (jason)-[:POSTED_ON]->(february_14_2024)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(february_14_2024)\n",
      "MERGE (azuresearchopenaidemojavascripttypescript)-[:IN_FAMILY]->(familyofragdemos)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(azuresearchopenaidemojavascripttypescript)\n",
      "MERGE (azuresearchopenaidemo)-[:USES]->(react)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(react)\n",
      "MERGE (jason)-[:POSTED_ON]->(february_19_2024)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(february_19_2024)\n",
      "MERGE (azuresearchopenaidemopython)-[:PART_OF]->(familyofragdemos)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(azuresearchopenaidemopython)\n",
      "MERGE (jason)-[:REVIEWED]->(cversion)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(cversion)\n",
      "MERGE (jason)-[:REVIEWED]->(javascripttypescriptversion)\n",
      "MERGE (DocumentChunk1)-[:MENTIONS]->(javascripttypescriptversion)\n",
      "MERGE (azuresearchopenaidemopython)-[:PART_OF]->(azuresearchopenaidemos)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(azuresearchopenaidemopython)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(azuresearchopenaidemos)\n",
      "MERGE (hacktogethertheaichatapphack)-[:USED]->(azuresearchopenaidemopython)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(hacktogethertheaichatapphack)\n",
      "MERGE (azurevectorsearchaiassistant)-[:PART_OF]->(theragdemochronicles)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(azurevectorsearchaiassistant)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(theragdemochronicles)\n",
      "MERGE (azurevectorsearchaiassistant)-[:USES]->(semantickernel)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(semantickernel)\n",
      "MERGE (bostoncodecamp_36)-[:LOCATED_IN]->(boston)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(bostoncodecamp_36)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(boston)\n",
      "MERGE (bostoncodecamp_36)-[:HAS_DURATION]->(_20years)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(_20years)\n",
      "MERGE (talk)-[:TITLE]->(gettingstartedwithretrievalaugmentedgenerationrag)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(talk)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(gettingstartedwithretrievalaugmentedgenerationrag)\n",
      "MERGE (jason)-[:POSTED]->(demoreviewazuresearchopenaidemopython)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(jason)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(demoreviewazuresearchopenaidemopython)\n",
      "MERGE (jason)-[:POSTED]->(demoreviewazurevectorsearchaiassistant)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(demoreviewazurevectorsearchaiassistant)\n",
      "MERGE (jason)-[:POSTED]->(bostoncodecamp_36sessions)\n",
      "MERGE (DocumentChunk2)-[:MENTIONS]->(bostoncodecamp_36sessions)\n",
      "MERGE (jason)-[:POSTED_ON]->(sundaymarch_24_2024)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(jason)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(sundaymarch_24_2024)\n",
      "MERGE (billwilder)-[:CREATED]->(aiminiworkshop)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(billwilder)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(aiminiworkshop)\n",
      "MERGE (billwilder)-[:USERNAME]->(codingoutloud)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(codingoutloud)\n",
      "MERGE (virtualbostonazuremeetup)-[:LOCATED_IN]->(boston)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(virtualbostonazuremeetup)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(boston)\n",
      "MERGE (aiminiworkshop)-[:USED_FOR]->(handsonwithcodeusingtheazureopenaiapi)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(handsonwithcodeusingtheazureopenaiapi)\n",
      "MERGE (jason)-[:POSTED_ON]->(saturdaymarch_30_2024)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(saturdaymarch_30_2024)\n",
      "MERGE (mslearningpathapl_2005)-[:FOCUSES_ON]->(developaiagentsusingazureopenaiandthesemantickernelsdk)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(mslearningpathapl_2005)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(developaiagentsusingazureopenaiandthesemantickernelsdk)\n",
      "MERGE (jason)-[:POSTED_ON]->(thursdayapril_11_2024)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(thursdayapril_11_2024)\n",
      "MERGE (globalazurebootcamp)-[:FEATURED]->(aiandhandsonlabs)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(globalazurebootcamp)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(aiandhandsonlabs)\n",
      "MERGE (jason)-[:POSTED_ON]->(tuesdayapril_23_2024)\n",
      "MERGE (DocumentChunk3)-[:MENTIONS]->(tuesdayapril_23_2024)\n",
      "MERGE (jason)-[:POSTED]->(tuesdayapril_23_2024)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(jason)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(tuesdayapril_23_2024)\n",
      "MERGE (jason)-[:POSTED]->(post_12)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(post_12)\n",
      "MERGE (post_12)-[:PART_OF]->(semantickernelhelloworldpluginspart_2)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(semantickernelhelloworldpluginspart_2)\n",
      "MERGE (semantickernelhelloworldpluginspart_2)-[:INCLUDES]->(nativefunction)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(nativefunction)\n",
      "MERGE (nativefunction)-[:IMPLEMENTED_IN]->(helloworldplugin2consoleproject)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(helloworldplugin2consoleproject)\n",
      "MERGE (jason)-[:POSTED]->(fridayapril_26_2024)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(fridayapril_26_2024)\n",
      "MERGE (jason)-[:POSTED]->(post_13)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(post_13)\n",
      "MERGE (post_13)-[:PART_OF]->(semantickernelhelloworldpluginspart_3)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(semantickernelhelloworldpluginspart_3)\n",
      "MERGE (nativefunctionplugin)-[:USES]->(openaifunctioncalling)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(nativefunctionplugin)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(openaifunctioncalling)\n",
      "MERGE (jason)-[:POSTED]->(tuesdayapril_30_2024)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(tuesdayapril_30_2024)\n",
      "MERGE (jason)-[:POSTED]->(post_14)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(post_14)\n",
      "MERGE (post_14)-[:INVOLVED]->(jasonspokeatmemphisazureusergroup)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(jasonspokeatmemphisazureusergroup)\n",
      "MERGE (memphisazureusergroup)-[:LOCATED_IN]->(memphis)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(memphisazureusergroup)\n",
      "MERGE (DocumentChunk4)-[:MENTIONS]->(memphis)\n",
      "MERGE (memphisazureusergroup)-[:HELD_EVENT]->(lastthursdaynight)\n",
      "MERGE (DocumentChunk5)-[:MENTIONS]->(memphisazureusergroup)\n",
      "MERGE (DocumentChunk5)-[:MENTIONS]->(lastthursdaynight)\n",
      "MERGE (memphisazureusergroup)-[:LOCATED_IN]->(memphis)\n",
      "MERGE (DocumentChunk5)-[:MENTIONS]->(memphis)\n",
      "MERGE (jason)-[:SPEAKER_AT]->(memphisazureusergroup)\n",
      "MERGE (DocumentChunk5)-[:MENTIONS]->(jason)\n",
      "MERGE (jason)-[:GAVE_PRESENTATION]->(gettingstartedwithretrievalaugmentedgenerationrag)\n",
      "MERGE (DocumentChunk5)-[:MENTIONS]->(gettingstartedwithretrievalaugmentedgenerationrag)\n",
      "MERGE (presentation)-[:HAS]->(slidedeck)\n",
      "MERGE (DocumentChunk5)-[:MENTIONS]->(presentation)\n",
      "MERGE (DocumentChunk5)-[:MENTIONS]->(slidedeck)\n",
      "MERGE (slidedeck)-[:THEME]->(memphis)\n",
      "MERGE (jason)-[:POSTED_ON]->(tuesdaymay_7_2024)\n",
      "MERGE (DocumentChunk5)-[:MENTIONS]->(tuesdaymay_7_2024)\n",
      "MERGE (semantickernel)-[:USED_IN]->(helloworldpluginspart_3)\n",
      "MERGE (DocumentChunk5)-[:MENTIONS]->(semantickernel)\n",
      "MERGE (DocumentChunk5)-[:MENTIONS]->(helloworldpluginspart_3)\n",
      "MERGE (jason)-[:EXPLAINED]->(openaifunctioncalling)\n",
      "MERGE (DocumentChunk5)-[:MENTIONS]->(openaifunctioncalling)\n",
      "MERGE (handlebarsplanner)-[:ACCOMPLISHES_SAME]->(openaifunctioncalling)\n",
      "MERGE (DocumentChunk5)-[:MENTIONS]->(handlebarsplanner)\n",
      "MERGE (jason)-[:POSTED_ON]->(mondayjune_10_2024)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(jason)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(mondayjune_10_2024)\n",
      "MERGE (willvelida)-[:CREATED]->(videousingbingsearchapiinthesemantickernelsdk)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(willvelida)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(videousingbingsearchapiinthesemantickernelsdk)\n",
      "MERGE (bingsearchapi)-[:USED_IN]->(semantickernelsdk)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(bingsearchapi)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(semantickernelsdk)\n",
      "MERGE (jason)-[:POSTED_ON]->(tuesdayjune_18_2024)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(tuesdayjune_18_2024)\n",
      "MERGE (chatcopilot)-[:FEATURES]->(retrievalaugmentedgenerationrag)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(chatcopilot)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(retrievalaugmentedgenerationrag)\n",
      "MERGE (jason)-[:POSTED_ON]->(tuesdayjune_25_2024)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(tuesdayjune_25_2024)\n",
      "MERGE (billwilder)-[:PRESENTED]->(fundamentalsofgenerativeai)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(billwilder)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(fundamentalsofgenerativeai)\n",
      "MERGE (billwilder)-[:INTRODUCED]->(azureaistudio)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(azureaistudio)\n",
      "MERGE (jason)-[:PRESENTED]->(retrievalaugmentedgenerationragusingsemantickernel)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(retrievalaugmentedgenerationragusingsemantickernel)\n",
      "MERGE (githubrepo)-[:CONTAINS]->(bostonazurejune2024)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(githubrepo)\n",
      "MERGE (DocumentChunk6)-[:MENTIONS]->(bostonazurejune2024)\n",
      "MERGE (jason)-[:POSTED_ON]->(tuesdayjune_25_2024)\n",
      "MERGE (DocumentChunk7)-[:MENTIONS]->(jason)\n",
      "MERGE (DocumentChunk7)-[:MENTIONS]->(tuesdayjune_25_2024)\n",
      "MERGE (jason)-[:IS_RESEARCHING]->(texttosql)\n",
      "MERGE (DocumentChunk7)-[:MENTIONS]->(texttosql)\n",
      "MERGE (texttosql)-[:HAS_ALIAS]->(naturallanguagetosql)\n",
      "MERGE (DocumentChunk7)-[:MENTIONS]->(naturallanguagetosql)\n",
      "MERGE (llm)-[:USED_FOR]->(generatesqlstatements)\n",
      "MERGE (DocumentChunk7)-[:MENTIONS]->(llm)\n",
      "MERGE (DocumentChunk7)-[:MENTIONS]->(generatesqlstatements)\n",
      "MERGE (jason)-[:POSTED_ON]->(fridayjuly_5_2024)\n",
      "MERGE (DocumentChunk7)-[:MENTIONS]->(fridayjuly_5_2024)\n",
      "MERGE (jason)-[:POSTED_ON]->(saturdayjuly_6_2024)\n",
      "MERGE (DocumentChunk7)-[:MENTIONS]->(saturdayjuly_6_2024)\n",
      "MERGE (jason)-[:CREATED]->(codesample)\n",
      "MERGE (DocumentChunk7)-[:MENTIONS]->(codesample)\n",
      "MERGE (codesample)-[:LOCATED_IN]->(githubreposemantickernelgettingstarted)\n",
      "MERGE (DocumentChunk7)-[:MENTIONS]->(githubreposemantickernelgettingstarted)\n",
      "MERGE (githubreposemantickernelgettingstarted)-[:INCLUDES]->(samplesdemostexttosqldirectory)\n",
      "MERGE (DocumentChunk7)-[:MENTIONS]->(samplesdemostexttosqldirectory)\n",
      "MERGE (jason)-[:MODIFIED]->(nl2sqlcodesample)\n",
      "MERGE (DocumentChunk7)-[:MENTIONS]->(nl2sqlcodesample)\n"
     ]
    }
   ],
   "source": [
    "foreach(var t in entityCypherText)\n",
    "{\n",
    "    Console.WriteLine(t);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON\n",
      "TECHNOLOGY\n",
      "CONCEPT\n",
      "PRODUCT\n",
      "EVENT\n",
      "MISCELLANEOUS\n",
      "ORGANIZATION\n",
      "LOCATION\n"
     ]
    }
   ],
   "source": [
    "foreach(var t in types.Keys)\n",
    "{\n",
    "    Console.WriteLine(t);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "IAuthToken token = AuthTokens.Basic(\n",
    "                envVars[\"NEO4J_USER\"],\n",
    "                envVars[\"NEO4J_PASSWORD\"]\n",
    "            );\n",
    "IDriver driver = GraphDatabase.Driver(envVars[\"NEO4J_URI\"], token);\n",
    "\n",
    "QueryConfig config = new QueryConfig();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467\r\n"
     ]
    }
   ],
   "source": [
    "Console.WriteLine(entityCypherText.ToArray().Length);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "using (var session = driver.AsyncSession())\n",
    "{\n",
    "    StringBuilder all = new StringBuilder();\n",
    "    all.AppendJoin(Environment.NewLine, entityCypherText.ToArray());\n",
    "    await driver.ExecutableQuery(all.ToString()).WithConfig(config).ExecuteAsync();\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string createVectorIndex = @\"CREATE VECTOR INDEX CHUNK_EMBEDDING IF NOT EXISTS\n",
    "                            FOR (c:DOCUMENT_CHUNK) ON c.embedding\n",
    "                            OPTIONS {indexConfig: {\n",
    "                           `vector.dimensions`: 1536,\n",
    "                            `vector.similarity_function`: 'cosine'\n",
    "                            }}\";\n",
    "\n",
    "await driver.ExecutableQuery(createVectorIndex).WithConfig(config).ExecuteAsync();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "string createFulltextIndex = @\"CREATE FULLTEXT INDEX ENTITY_TEXT IF NOT EXISTS \n",
    "                                FOR (n:ENTITY) ON EACH [n.text]\";\n",
    "await driver.ExecutableQuery(createFulltextIndex).WithConfig(config).ExecuteAsync();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "string populateEmbeddings = $@\"\n",
    "                            MATCH (n:DOCUMENT_CHUNK) WHERE n.text IS NOT NULL\n",
    "                            WITH n, genai.vector.encode(\n",
    "                                n.text,\n",
    "                                'AzureOpenAI',\n",
    "                                {{\n",
    "                                    token: $token,\n",
    "                                    resource: $resource,\n",
    "                                    deployment: $deployment\n",
    "                                }}) AS vector\n",
    "                            CALL db.create.setNodeVectorProperty(n, 'embedding', vector)\n",
    "                            \";\n",
    "await driver.ExecutableQuery(populateEmbeddings)\n",
    "    .WithParameters(new() { \n",
    "        {\"token\", envVars[\"AZURE_OPENAI_API_KEY\"]}, \n",
    "        {\"resource\", envVars[\"AZURE_OPENAI_RESOURCE\"]}, \n",
    "        {\"deployment\", envVars[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"]}})\n",
    "    .WithConfig(config)\n",
    "    .ExecuteAsync();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "//string questionText = \"what are the blog post titles that are about Semantic Kernel?\";\n",
    "string questionText = \"How many blog post did Jason write about Semantic Kernel and what is their titles?\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: How many blog posts did Jason write about Semantic Kernel^Jason's blog entries about Semantic Kernel^Semantic Kernel blog posts by Jason^Jason's Semantic Kernel articles^number of Jason's Semantic Kernel posts^titles of Jason's Semantic Kernel posts^Jason's blog entries on Semantic Kernel titles^Jason's posts about Semantic Kernel^Semantic Kernel articles by Jason^blog titles by Jason on Semantic Kernel\r\n"
     ]
    }
   ],
   "source": [
    "ChatClient chatClient = client.GetChatClient(\"chat\");\n",
    "\n",
    "int maxSynonyms = 10;\n",
    "\n",
    "string prompt = $@\"\n",
    "Given a user question, generate synonyms or related keywords up to {maxSynonyms} in total, considering possible cases of capitalization, pluralization, and common expressions. Provide all synonyms/keywords separated by '~' symbols in a single line format: 'synonym1~synonyms2~...'.\n",
    "\n",
    "QUERY: {questionText}\n",
    "######################\n",
    "KEYWORDS:\n",
    "\";\n",
    "ChatCompletion completion = chatClient.CompleteChat(\n",
    "    [\n",
    "        new UserChatMessage(prompt),\n",
    "    ]);\n",
    "\n",
    "Console.WriteLine($\"{completion.Role}: {completion.Content[0].Text}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many blog posts did Jason write about Semantic Kernel^Jason's blog entries about Semantic Kernel^Semantic Kernel blog posts by Jason^Jason's Semantic Kernel articles^number of Jason's Semantic Kernel posts^titles of Jason's Semantic Kernel posts^Jason's blog entries on Semantic Kernel titles^Jason's posts about Semantic Kernel^Semantic Kernel articles by Jason^blog titles by Jason on Semantic Kernel\r\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Neo4j.Driver.ClientException: Failed to invoke procedure `db.index.fulltext.queryNodes`: Caused by: org.apache.lucene.queryparser.classic.TokenMgrError: Lexical error at line 1, column 59.  Encountered: '74' (74),\r\n   at Neo4j.Driver.Internal.MessageHandling.ResponsePipelineError.EnsureThrown()\r\n   at Neo4j.Driver.Internal.Result.ResultCursorBuilder.NextRecordAsync()\r\n   at Neo4j.Driver.Internal.Result.ResultCursor.MoveNextAsync()\r\n   at Neo4j.Driver.Internal.Driver.<>c__DisplayClass29_0.<<GetRowsAsync>g__Process|0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Neo4j.Driver.Internal.Driver.<>c__DisplayClass29_0.<<GetRowsAsync>g__Process|0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Neo4j.Driver.Internal.Driver.<>c__DisplayClass37_0`1.<<TransformCursor>g__TransformCursorImpl|0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Neo4j.Driver.Internal.Driver.Work[T](Query q, IAsyncQueryRunner x, Func`3 process, CancellationToken cancellationToken)\r\n   at Neo4j.Driver.Internal.AsyncSession.<>c__DisplayClass52_0`1.<<RunTransactionAsync>b__1>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Neo4j.Driver.Internal.AsyncSession.<>c__DisplayClass52_0`1.<<RunTransactionAsync>b__1>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Neo4j.Driver.Internal.AsyncRetryLogic.RetryAsync[T](Func`1 runTxAsyncFunc)\r\n   at Neo4j.Driver.Internal.Logging.DriverLoggerUtil.TryExecuteAsync[T](ILogger logger, Func`1 func, String message)\r\n   at Neo4j.Driver.Internal.Driver.ExecuteQueryAsyncInternal[T](Query query, QueryConfig config, CancellationToken cancellationToken, Func`3 cursorProcessor)\r\n   at Neo4j.Driver.Internal.Driver.ExecuteQueryAsyncInternal[T](Query query, QueryConfig config, CancellationToken cancellationToken, Func`3 cursorProcessor)\r\n   at Neo4j.Driver.Internal.Driver.GetRowsAsync(Query query, QueryConfig config, Action`1 streamProcessor, CancellationToken cancellationToken)\r\n   at Neo4j.Driver.Internal.ReducedExecutableQuery`3.ExecuteAsync(CancellationToken token)\r\n   at Submission#12.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "Neo4j.Driver.ClientException: Failed to invoke procedure `db.index.fulltext.queryNodes`: Caused by: org.apache.lucene.queryparser.classic.TokenMgrError: Lexical error at line 1, column 59.  Encountered: '74' (74),\r\n",
      "   at Neo4j.Driver.Internal.MessageHandling.ResponsePipelineError.EnsureThrown()\r\n",
      "   at Neo4j.Driver.Internal.Result.ResultCursorBuilder.NextRecordAsync()\r\n",
      "   at Neo4j.Driver.Internal.Result.ResultCursor.MoveNextAsync()\r\n",
      "   at Neo4j.Driver.Internal.Driver.<>c__DisplayClass29_0.<<GetRowsAsync>g__Process|0>d.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Neo4j.Driver.Internal.Driver.<>c__DisplayClass29_0.<<GetRowsAsync>g__Process|0>d.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Neo4j.Driver.Internal.Driver.<>c__DisplayClass37_0`1.<<TransformCursor>g__TransformCursorImpl|0>d.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Neo4j.Driver.Internal.Driver.Work[T](Query q, IAsyncQueryRunner x, Func`3 process, CancellationToken cancellationToken)\r\n",
      "   at Neo4j.Driver.Internal.AsyncSession.<>c__DisplayClass52_0`1.<<RunTransactionAsync>b__1>d.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Neo4j.Driver.Internal.AsyncSession.<>c__DisplayClass52_0`1.<<RunTransactionAsync>b__1>d.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Neo4j.Driver.Internal.AsyncRetryLogic.RetryAsync[T](Func`1 runTxAsyncFunc)\r\n",
      "   at Neo4j.Driver.Internal.Logging.DriverLoggerUtil.TryExecuteAsync[T](ILogger logger, Func`1 func, String message)\r\n",
      "   at Neo4j.Driver.Internal.Driver.ExecuteQueryAsyncInternal[T](Query query, QueryConfig config, CancellationToken cancellationToken, Func`3 cursorProcessor)\r\n",
      "   at Neo4j.Driver.Internal.Driver.ExecuteQueryAsyncInternal[T](Query query, QueryConfig config, CancellationToken cancellationToken, Func`3 cursorProcessor)\r\n",
      "   at Neo4j.Driver.Internal.Driver.GetRowsAsync(Query query, QueryConfig config, Action`1 streamProcessor, CancellationToken cancellationToken)\r\n",
      "   at Neo4j.Driver.Internal.ReducedExecutableQuery`3.ExecuteAsync(CancellationToken token)\r\n",
      "   at Submission#12.<<Initialize>>d__0.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "var synonyms = completion.Content[0].Text.Split(\"~\");\n",
    "\n",
    "\n",
    "var uniqueNodes = new Dictionary<string, string>();\n",
    "foreach(var synonym in synonyms)\n",
    "{\n",
    "    Console.WriteLine(synonym);\n",
    "    string cypher = $@\"\n",
    "                        CALL db.index.fulltext.queryNodes(\"\"ENTITY_TEXT\"\", \"\"{synonym}\"\")\n",
    "                        YIELD node AS e1\n",
    "                        MATCH (e1)-[r]-(e2:ENTITY)\n",
    "                        RETURN e1.id, e1.type, e1.text, e2.name, e2.type, e2.text, type(r)\n",
    "                    \";\n",
    "\n",
    "    var textSearchResult = await driver.ExecutableQuery(cypher)\n",
    "                    .WithConfig(config)\n",
    "                    .ExecuteAsync();\n",
    "    if (textSearchResult.Result.Count() > 0)\n",
    "    {\n",
    "        foreach(var r in textSearchResult.Result)\n",
    "        {\n",
    "            var tripletText = $\"{r[\"e1.text\"]} -> {r[\"type(r)\"]} -> {r[\"e2.text\"]}\";\n",
    "            if (!uniqueNodes.ContainsKey(tripletText))\n",
    "            {\n",
    "                uniqueNodes.Add(tripletText,tripletText);\n",
    "            }   \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"\");\n",
    "Console.WriteLine($\"{uniqueNodes.Count} Unique nodes with matches:\");\n",
    "foreach(var key in uniqueNodes.Keys)\n",
    "{\n",
    "    Console.WriteLine($\"{key}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string question = $@\"\n",
    "                    WITH genai.vector.encode(\n",
    "                        $question,\n",
    "                        'AzureOpenAI',\n",
    "                        {{\n",
    "                            token: $token,\n",
    "                            resource: $resource,\n",
    "                            deployment: $deployment\n",
    "                        }}) AS question_embedding\n",
    "                    CALL db.index.vector.queryNodes(\n",
    "                        'CHUNK_EMBEDDING',\n",
    "                        $top_k, \n",
    "                        question_embedding\n",
    "                        ) YIELD node AS chunk, score \n",
    "                    RETURN chunk.id, chunk.text, score\n",
    "                    \";\n",
    "\n",
    "var chunkResult = await driver.ExecutableQuery(question)\n",
    "                .WithParameters(new() { \n",
    "                    {\"question\", questionText},\n",
    "                    {\"token\", envVars[\"AZURE_OPENAI_API_KEY\"]}, \n",
    "                    {\"resource\", envVars[\"AZURE_OPENAI_RESOURCE\"]}, \n",
    "                    {\"deployment\", envVars[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"]},\n",
    "                    {\"top_k\", 5}})\n",
    "                .WithConfig(config)\n",
    "                .ExecuteAsync();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Keys\": [\n",
      "    \"chunk.id\",\n",
      "    \"chunk.text\",\n",
      "    \"score\"\n",
      "  ],\n",
      "  \"Result\": [\n",
      "    {\n",
      "      \"chunk.id\": \"6961feeb0bf14914a7b8bbecfd6566e1\",\n",
      "      \"chunk.text\": \"Post 17 Semantic Kernel Hello World WebSearchEnginePlugin\\nA couple of weeks ago I thought I\\u2019d written my last of these blogs, mainly due to me getting more in depth with Semantic Kernel. However, after I watched Will Velida\\u2019s video Using Bing Search API in the Semantic Kernel SDK \\u2026 I couldn\\u2019t help but wonder what the API calls were behind the scenes. Will does a great job at explaining how to use the plugin and the Bing resource needed to make calls to the search API, so I won\\u2019t get into that part of it - I want to focus on the usefulness and API calls made by the plugin.\\nPosted byJason Monday, June 10, 2024\\n\\nPost 18 Demo Review: Chat Copilot\\nDemo Review: Chat Copilot This is the fifth C# demo in The RAG Demo Chronicles (Blog Series) and has the most extensive use of Semantic Kernel out of all the demos I\\u2019ve reviewed. The use of Retrieval Augmented Generation (RAG) is different with this project than the other demos I\\u2019ve reviewed - mainly because RAG is just one of its features. With this demo, I also took the time to configure the optional authentication so I could play with the MS Graph plugin \\u2026 and WOW!\\nPosted byJason Tuesday, June 18, 2024\\n\\nPost 19 Boston Azure June 2024\\nLast night was the Season of AI presentation. We started with Bill Wilder presenting the fundamentals of Generative AI and quick introduction to Azure AI Studio, then I finished up with a .NET code walkthrough implement Retrieval Augmented Generation (RAG) using Semantic Kernel. It was nice to see a lot of regular faces and meet several new people. Demo Code The demo code is on my GitHub repo BostonAzure-June2024 under a subdirectory. Posted byJason Tuesday, June 25, 2024\\n\\nPost 20 Study Notes: Text-to-SQL\\n\",\n",
      "      \"score\": 0.9324615001678467\n",
      "    },\n",
      "    {\n",
      "      \"chunk.id\": \"6a5833946992430e806b33db1ffc45d0\",\n",
      "      \"chunk.text\": \"Posted byJason Sunday, March 24, 2024\\n\\nPost 9 Semantic Kernel Hello World\\nThis past Thursday night after the Virtual Boston Azure meetup, Bill Wilder (@codingoutloud) created an AI mini-workshop (hands on) for the attendees that were interested in getting hands on with code using the Azure OpenAI API. This post is me using the same idea but with Semantic Kernel. OpenAI Chat Hello World C# Bill provided the following code for us to get a simple OpenAI chat working: using Azure; using Azure.\\nPosted byJason Saturday, March 30, 2024\\n\\nPost 10 Semantic Kernel Hello World Plugins Part 1\\nA couple of weeks ago, in my last entry I created a simple Hello World application with Semantic Kernel. Since then, I\\u2019ve worked my way through the MS Learning path: APL-2005 Develop AI agents using Azure OpenAI and the Semantic Kernel SDK - which I highly recommend if you are also learning SK. In this entry I\\u2019m going to start with the code from the last entry and extract the prompt to a plugin.\\nPosted byJason Thursday, April 11, 2024\\n\\nPost 11 My Session at Boston Global Azure Bootcamp\\nThis past weekend was Boston Azure\\u2019s Edition of the annual Global Azure Bootcamp. This year we focused on AI and hands-on-labs. The odd thing about when we scheduled the meetup was we had a lot of people sign up for the group just to rsvp - before most of the existing members had gotten around to rsvp\\u2019ing. We did not expect that. It is a mystery as how they heard about the event so quick. Posted byJason Tuesday, April 23, 2024\\n\\nPost 12 Semantic Kernel Hello World Plugins Part 2\\n\",\n",
      "      \"score\": 0.9271335601806641\n",
      "    },\n",
      "    {\n",
      "      \"chunk.id\": \"3245effc3bfa4d7380e954700245b4c5\",\n",
      "      \"chunk.text\": \"Posted byJason Tuesday, April 23, 2024\\n\\nPost 12 Semantic Kernel Hello World Plugins Part 2\\nTwo weeks ago I blogged Part 1, in which I moved the prompt to a prompt template. In this part, I implement a native function that will take in the current date and make the call to the LLM. I\\u2019ve put the code for this blog in the HelloWorld.Plugin2.Console project in the same repo as the other SK entries: semantic-kernel-getting-started. Semantic Kernel Plugin: Native Function There is a good Microsoft Learn module: Give your AI agent skills that walks you through the details of what a native function is and how to implement them.\\nPosted byJason Friday, April 26, 2024\\n\\nPost 13 Semantic Kernel Hello World Plugins Part 3\\nLast week I blogged Part 2 showing the creation of a native function plugin, in this post I want to take that native function a step further and use the OpenAI Function calling. This will allow us to not provide the current date when making the call to get a historic daily fact and have OpenAI call a function to get the current date. I\\u2019ve added the HelloWorld.Plugin3.Console project to the GitHub repo for the code in this blog entry.\\nPosted byJason Tuesday, April 30, 2024\\n\\nPost 14 Memphis Azure User Group Last Thursday night I spoke at the Memphis Azure User Group, it was nice to meet some people in person and see how excited others are about finding valuable ways to work GenAI into their applications.\",\n",
      "      \"score\": 0.9131969213485718\n",
      "    },\n",
      "    {\n",
      "      \"chunk.id\": \"4f479cf64cf44c13844020afd7c3dd1d\",\n",
      "      \"chunk.text\": \"Last Thursday night I spoke at the Memphis Azure User Group, it was nice to meet some people in person and see how excited others are about finding valuable ways to work GenAI into their applications. I also gave my slide deck a completely new look (Memphis themed via Bing/create): Talk: Getting Started with Retrieval Augmented Generation (RAG) The presentation pdf can be downloaded here. Since the presentation was hybrid, there were not as many questions as the other two times I\\u2019ve given the talk \\u2026 or that is my guess at the reason why it was so quiet.\\nPosted byJason Tuesday, May 7, 2024\\n\\nPost 15 Semantic Kernel Hello World Planners Part 1\\nA few weeks ago in the Semantic Kernel Hello World Plugins Part 3 blog entry, I showed how to use OpenAI Function Calling. The last half of that entry was all about how to view the response and request JSON going back and forth to OpenAI, which detailed four API calls. In this entry I look at using the Handlebars Planner to accomplish the same functionality. Then I\\u2019ll show the request and response JSON for both using a saved plan as well as having the LLM create a plan and end with a token usage comparison.\\nPosted byJason Sunday, May 19, 2024\\n\\nPost 16 Semantic Kernel Hello World Planners Part 2\\nLast week in the Semantic Kernel Hello World Planners Part 1 entry, I used the Handlebars planner to implement the sample Hello World functionality and then looked at the token difference between using a saved plan vs. generating a plan. In this entry I use the Function Calling Stepwise Planner to create the sample Hello World functionality and compare it to the implementation in the Semantic Kernel Hello World Plugins Part 3 entry.\\nPosted byJason Monday, May 27, 2024 Post 17 Semantic Kernel Hello World WebSearchEnginePlugin\\n\",\n",
      "      \"score\": 0.9068493843078613\n",
      "    },\n",
      "    {\n",
      "      \"chunk.id\": \"99e4ca795e804be881735c6339051d8b\",\n",
      "      \"chunk.text\": \"Demo Review: Azure Search OpenAI Demo (Python) This is the last in the family of Azure Search OpenAI demos that I\\u2019m covering (I\\u2019m not looking at the Java version). I reviewed the C# version and the Javascript/Typescript version earlier this month. Of the three I\\u2019m covering, this one seems to be the most active, popular and have the most documentation. At the beginning of this month, the Hack Together: The AI Chat App Hack used this demo at the sample repository, marking it as a solid reference implementation for RAG.\\nPosted byJason Friday, February 23, 2024\\n\\nPost 7 Demo Review: Azure Vector Search AI Assistant\\nDemo Review: Azure Vector Search AI Assistant This is the fourth C# demo in The RAG Demo Chronicles (Blog Series) and is the first demo so far that saves its history to a database. This Retrieval Augmented Generation (RAG) demo is a little different than the last three because it primarily uses data from a database as the content to search instead of documents. It also uses Semantic Kernel more than other demos have, which is neat to see too.\\nPosted byJason Monday, February 26, 2024\\n\\nPost 8 Boston Code Camp 36 Sessions\\nYesterday was Boston Code Camp 36 hard to believe it has been going on for 20\\u002B years now. For me it is one of those regular events for the Boston tech community that is well worth spending a Saturday attending. It was nice to see a lot of regular faces and meet some new people. Talk: Getting Started with Retrieval Augmented Generation (RAG) I was surprise the room was full, it was good to see so many developers, students and architects - mostly with . Posted byJason Sunday, March 24, 2024\\n\\nPost 9 Semantic Kernel Hello World\\n\",\n",
      "      \"score\": 0.9020144939422607\n",
      "    }\n",
      "  ],\n",
      "  \"Summary\": {\n",
      "    \"Query\": {\n",
      "      \"Text\": \"\\n                    WITH genai.vector.encode(\\n                        $question,\\n                        \\u0027AzureOpenAI\\u0027,\\n                        {\\n                            token: $token,\\n                            resource: $resource,\\n                            deployment: $deployment\\n                        }) AS question_embedding\\n                    CALL db.index.vector.queryNodes(\\n                        \\u0027CHUNK_EMBEDDING\\u0027,\\n                        $top_k, \\n                        question_embedding\\n                        ) YIELD node AS chunk, score \\n                    RETURN chunk.id, chunk.text, score\\n                    \",\n",
      "      \"Parameters\": {\n",
      "        \"question\": \"How many blog post did Jason write about Semantic Kernel and what is their titles?\",\n",
      "        \"token\": \"c36e2182dbbc401d9a6867bad09712ac\",\n",
      "        \"resource\": \"aoai-jhaley\",\n",
      "        \"deployment\": \"embedding\",\n",
      "        \"top_k\": 5\n",
      "      }\n",
      "    },\n",
      "    \"Counters\": {\n",
      "      \"ContainsUpdates\": false,\n",
      "      \"NodesCreated\": 0,\n",
      "      \"NodesDeleted\": 0,\n",
      "      \"RelationshipsCreated\": 0,\n",
      "      \"RelationshipsDeleted\": 0,\n",
      "      \"PropertiesSet\": 0,\n",
      "      \"LabelsAdded\": 0,\n",
      "      \"LabelsRemoved\": 0,\n",
      "      \"IndexesAdded\": 0,\n",
      "      \"IndexesRemoved\": 0,\n",
      "      \"ConstraintsAdded\": 0,\n",
      "      \"ConstraintsRemoved\": 0,\n",
      "      \"SystemUpdates\": 0,\n",
      "      \"ContainsSystemUpdates\": false\n",
      "    },\n",
      "    \"QueryType\": 1,\n",
      "    \"HasPlan\": false,\n",
      "    \"HasProfile\": false,\n",
      "    \"Plan\": null,\n",
      "    \"Profile\": null,\n",
      "    \"Notifications\": null,\n",
      "    \"ResultAvailableAfter\": \"00:00:00.1120000\",\n",
      "    \"ResultConsumedAfter\": \"00:00:00.1980000\",\n",
      "    \"Server\": {\n",
      "      \"Address\": \"localhost:7687\",\n",
      "      \"ProtocolVersion\": \"5.4\",\n",
      "      \"Agent\": \"Neo4j/5.21.2\"\n",
      "    },\n",
      "    \"Database\": {\n",
      "      \"Name\": \"neo4j\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "Document: { text: Post 17 Semantic Kernel Hello World WebSearchEnginePlugin\n",
      "A couple of weeks ago I thought I’d written my last of these blogs, mainly due to me getting more in depth with Semantic Kernel. However, after I watched Will Velida’s video Using Bing Search API in the Semantic Kernel SDK … I couldn’t help but wonder what the API calls were behind the scenes. Will does a great job at explaining how to use the plugin and the Bing resource needed to make calls to the search API, so I won’t get into that part of it - I want to focus on the usefulness and API calls made by the plugin.\n",
      "Posted byJason Monday, June 10, 2024\n",
      "\n",
      "Post 18 Demo Review: Chat Copilot\n",
      "Demo Review: Chat Copilot This is the fifth C# demo in The RAG Demo Chronicles (Blog Series) and has the most extensive use of Semantic Kernel out of all the demos I’ve reviewed. The use of Retrieval Augmented Generation (RAG) is different with this project than the other demos I’ve reviewed - mainly because RAG is just one of its features. With this demo, I also took the time to configure the optional authentication so I could play with the MS Graph plugin … and WOW!\n",
      "Posted byJason Tuesday, June 18, 2024\n",
      "\n",
      "Post 19 Boston Azure June 2024\n",
      "Last night was the Season of AI presentation. We started with Bill Wilder presenting the fundamentals of Generative AI and quick introduction to Azure AI Studio, then I finished up with a .NET code walkthrough implement Retrieval Augmented Generation (RAG) using Semantic Kernel. It was nice to see a lot of regular faces and meet several new people. Demo Code The demo code is on my GitHub repo BostonAzure-June2024 under a subdirectory. Posted byJason Tuesday, June 25, 2024\n",
      "\n",
      "Post 20 Study Notes: Text-to-SQL\n",
      " }\n",
      "Document: { text: Posted byJason Sunday, March 24, 2024\n",
      "\n",
      "Post 9 Semantic Kernel Hello World\n",
      "This past Thursday night after the Virtual Boston Azure meetup, Bill Wilder (@codingoutloud) created an AI mini-workshop (hands on) for the attendees that were interested in getting hands on with code using the Azure OpenAI API. This post is me using the same idea but with Semantic Kernel. OpenAI Chat Hello World C# Bill provided the following code for us to get a simple OpenAI chat working: using Azure; using Azure.\n",
      "Posted byJason Saturday, March 30, 2024\n",
      "\n",
      "Post 10 Semantic Kernel Hello World Plugins Part 1\n",
      "A couple of weeks ago, in my last entry I created a simple Hello World application with Semantic Kernel. Since then, I’ve worked my way through the MS Learning path: APL-2005 Develop AI agents using Azure OpenAI and the Semantic Kernel SDK - which I highly recommend if you are also learning SK. In this entry I’m going to start with the code from the last entry and extract the prompt to a plugin.\n",
      "Posted byJason Thursday, April 11, 2024\n",
      "\n",
      "Post 11 My Session at Boston Global Azure Bootcamp\n",
      "This past weekend was Boston Azure’s Edition of the annual Global Azure Bootcamp. This year we focused on AI and hands-on-labs. The odd thing about when we scheduled the meetup was we had a lot of people sign up for the group just to rsvp - before most of the existing members had gotten around to rsvp’ing. We did not expect that. It is a mystery as how they heard about the event so quick. Posted byJason Tuesday, April 23, 2024\n",
      "\n",
      "Post 12 Semantic Kernel Hello World Plugins Part 2\n",
      " }\n",
      "Document: { text: Posted byJason Tuesday, April 23, 2024\n",
      "\n",
      "Post 12 Semantic Kernel Hello World Plugins Part 2\n",
      "Two weeks ago I blogged Part 1, in which I moved the prompt to a prompt template. In this part, I implement a native function that will take in the current date and make the call to the LLM. I’ve put the code for this blog in the HelloWorld.Plugin2.Console project in the same repo as the other SK entries: semantic-kernel-getting-started. Semantic Kernel Plugin: Native Function There is a good Microsoft Learn module: Give your AI agent skills that walks you through the details of what a native function is and how to implement them.\n",
      "Posted byJason Friday, April 26, 2024\n",
      "\n",
      "Post 13 Semantic Kernel Hello World Plugins Part 3\n",
      "Last week I blogged Part 2 showing the creation of a native function plugin, in this post I want to take that native function a step further and use the OpenAI Function calling. This will allow us to not provide the current date when making the call to get a historic daily fact and have OpenAI call a function to get the current date. I’ve added the HelloWorld.Plugin3.Console project to the GitHub repo for the code in this blog entry.\n",
      "Posted byJason Tuesday, April 30, 2024\n",
      "\n",
      "Post 14 Memphis Azure User Group Last Thursday night I spoke at the Memphis Azure User Group, it was nice to meet some people in person and see how excited others are about finding valuable ways to work GenAI into their applications. }\n",
      "Document: { text: Last Thursday night I spoke at the Memphis Azure User Group, it was nice to meet some people in person and see how excited others are about finding valuable ways to work GenAI into their applications. I also gave my slide deck a completely new look (Memphis themed via Bing/create): Talk: Getting Started with Retrieval Augmented Generation (RAG) The presentation pdf can be downloaded here. Since the presentation was hybrid, there were not as many questions as the other two times I’ve given the talk … or that is my guess at the reason why it was so quiet.\n",
      "Posted byJason Tuesday, May 7, 2024\n",
      "\n",
      "Post 15 Semantic Kernel Hello World Planners Part 1\n",
      "A few weeks ago in the Semantic Kernel Hello World Plugins Part 3 blog entry, I showed how to use OpenAI Function Calling. The last half of that entry was all about how to view the response and request JSON going back and forth to OpenAI, which detailed four API calls. In this entry I look at using the Handlebars Planner to accomplish the same functionality. Then I’ll show the request and response JSON for both using a saved plan as well as having the LLM create a plan and end with a token usage comparison.\n",
      "Posted byJason Sunday, May 19, 2024\n",
      "\n",
      "Post 16 Semantic Kernel Hello World Planners Part 2\n",
      "Last week in the Semantic Kernel Hello World Planners Part 1 entry, I used the Handlebars planner to implement the sample Hello World functionality and then looked at the token difference between using a saved plan vs. generating a plan. In this entry I use the Function Calling Stepwise Planner to create the sample Hello World functionality and compare it to the implementation in the Semantic Kernel Hello World Plugins Part 3 entry.\n",
      "Posted byJason Monday, May 27, 2024 Post 17 Semantic Kernel Hello World WebSearchEnginePlugin\n",
      " }\n",
      "Document: { text: Demo Review: Azure Search OpenAI Demo (Python) This is the last in the family of Azure Search OpenAI demos that I’m covering (I’m not looking at the Java version). I reviewed the C# version and the Javascript/Typescript version earlier this month. Of the three I’m covering, this one seems to be the most active, popular and have the most documentation. At the beginning of this month, the Hack Together: The AI Chat App Hack used this demo at the sample repository, marking it as a solid reference implementation for RAG.\n",
      "Posted byJason Friday, February 23, 2024\n",
      "\n",
      "Post 7 Demo Review: Azure Vector Search AI Assistant\n",
      "Demo Review: Azure Vector Search AI Assistant This is the fourth C# demo in The RAG Demo Chronicles (Blog Series) and is the first demo so far that saves its history to a database. This Retrieval Augmented Generation (RAG) demo is a little different than the last three because it primarily uses data from a database as the content to search instead of documents. It also uses Semantic Kernel more than other demos have, which is neat to see too.\n",
      "Posted byJason Monday, February 26, 2024\n",
      "\n",
      "Post 8 Boston Code Camp 36 Sessions\n",
      "Yesterday was Boston Code Camp 36 hard to believe it has been going on for 20+ years now. For me it is one of those regular events for the Boston tech community that is well worth spending a Saturday attending. It was nice to see a lot of regular faces and meet some new people. Talk: Getting Started with Retrieval Augmented Generation (RAG) I was surprise the room was full, it was good to see so many developers, students and architects - mostly with . Posted byJason Sunday, March 24, 2024\n",
      "\n",
      "Post 9 Semantic Kernel Hello World\n",
      " }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Console.WriteLine(JsonSerializer.Serialize(chunkResult, new JsonSerializerOptions {\n",
    "             WriteIndented = true\n",
    "         }));\n",
    "\n",
    "StringBuilder chunkTexts = new StringBuilder();\n",
    "foreach(var r in chunkResult.Result)\n",
    "{\n",
    "    chunkTexts.AppendLine($\"Document: {{ text: {r[\"chunk.text\"].ToString()} }}\");\n",
    "}\n",
    "\n",
    "Console.WriteLine(chunkTexts.ToString());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I don't know.\r\n"
     ]
    }
   ],
   "source": [
    "ChatClient chatClient = client.GetChatClient(\"chat\");\n",
    "\n",
    "string prompt = $@\"Question: {questionText}\n",
    "                ######################\n",
    "                Answer:\";\n",
    "\n",
    "\n",
    "\n",
    "string sysprompt = @\"Be brief in your answers.\n",
    "                    Answer ONLY with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below. If asking a clarifying question to the user would help, ask the question.\n",
    "                    For tabular information return it as an html table. Do not return markdown format. If the question is not in English, answer in the language used in the question.\";\n",
    "\n",
    "ChatCompletion completion = chatClient.CompleteChat(\n",
    "    [\n",
    "        new SystemChatMessage(sysprompt),\n",
    "        new UserChatMessage(prompt),\n",
    "    ]);\n",
    "\n",
    "Console.WriteLine($\"{completion.Role}: {completion.Content[0].Text}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "ChatClient chatClient = client.GetChatClient(\"chat\");\n",
    "\n",
    "string context = $@\"Structured data:\n",
    "    {string.Join(Environment.NewLine, uniqueNodes.Keys.ToArray())}\n",
    "Unstructured data:\n",
    "{chunkTexts.ToString()}\n",
    "\";\n",
    "\n",
    "//Console.WriteLine(context);\n",
    "\n",
    "string prompt = $@\"Answer the question based only on the following context:\n",
    "\t\t\t    {context}\n",
    "                ######################\n",
    "                Question: {questionText}\n",
    "                ######################\n",
    "                Answer:\";\n",
    "\n",
    "\n",
    "string sysprompt = @\"Be brief in your answers.\n",
    "                    Answer ONLY with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below. If asking a clarifying question to the user would help, ask the question.\n",
    "                    For tabular information return it as an html table. Do not return markdown format. If the question is not in English, answer in the language used in the question.\";\n",
    "\n",
    "ChatCompletion completion = chatClient.CompleteChat(\n",
    "    [\n",
    "        new SystemChatMessage(sysprompt),\n",
    "        new UserChatMessage(prompt),\n",
    "    ]);\n",
    "\n",
    "Console.WriteLine($\"{completion.Role}: {completion.Content[0].Text}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: (\"entity\"^\"Jason\"^\"person\"^\"Jason is the author of the blog posts and is actively learning AI, moving through the four stages of competence.\")<EOR>\n",
      "(\"entity\"^\"Michael Washington\"^\"person\"^\"Michael Washington is mentioned as a demo creator for RAG (Retrieval Augmented Generation) applications using various technologies.\")<EOR>\n",
      "(\"entity\"^\"AI\"^\"technology\"^\"Artificial Intelligence, abbreviated as AI, is the primary focus of learning and development in these blog posts.\")<EOR>\n",
      "(\"entity\"^\"GenAI\"^\"technology\"^\"Generative AI, abbreviated as GenAI, is a key technology being integrated into business applications.\")<EOR>\n",
      "(\"entity\"^\"ChatGPT\"^\"technology\"^\"ChatGPT is highlighted as a significant AI tool that leaders in the industry are using.\")<EOR>\n",
      "(\"entity\"^\"Blazor\"^\"technology\"^\"Blazor is a framework mentioned in the context of building RAG applications.\")<EOR>\n",
      "(\"entity\"^\"SQL Server\"^\"technology\"^\"SQL Server is frequently mentioned as a relational database tool utilized in RAG application demos.\")<EOR>\n",
      "(\"entity\"^\"Azure OpenAI\"^\"technology\"^\"Azure OpenAI represents the AI services provided by Azure, used in the demos discussed in the blog posts.\")<EOR>\n",
      "(\"entity\"^\"Function Calling\"^\"technology\"^\"Function Calling is a technology integrated into RAG applications to enhance functionality.\")<EOR>\n",
      "(\"relationship\"^\"Jason\"^\"AI\"^\"Jason is learning about AI and progressing through different stages of competence.\"^10)<EOR>\n",
      "(\"relationship\"^\"Jason\"^\"ChatGPT\"^\"Jason has learned about ChatGPT as a significant AI tool used by industry leaders.\"^8)<EOR>\n",
      "(\"relationship\"^\"Jason\"^\"GenAI\"^\"Jason, a full-stack C# developer, is getting up to speed on GenAI technologies for business applications.\"^9)<EOR>\n",
      "(\"relationship\"^\"Michael Washington\"^\"Blazor\"^\"Michael Washington created a demo using Blazor for RAG applications.\"^7)<EOR>\n",
      "(\"relationship\"^\"Michael Washington\"^\"SQL Server\"^\"Michael Washington created a demo incorporating SQL Server for RAG applications.\"^7)<EOR>\n",
      "(\"relationship\"^\"Michael Washington\"^\"Azure OpenAI\"^\"Michael Washington's demo includes the usage of Azure OpenAI services.\"^7)<EOR>\n",
      "(\"relationship\"^\"Michael Washington\"^\"Function Calling\"^\"Michael Washington's demo makes use of Function Calling to enhance RAG applications.\"^7)<EOR>\n",
      "(\"relationship\"^\"Blazor\"^\"SQL Server\"^\"Blazor and SQL Server are used together in RAG application demos.\"^6)<EOR>\n",
      "(\"relationship\"^\"SQL Server\"^\"Azure OpenAI\"^\"SQL Server and Azure OpenAI services are utilized in the same demos for RAG applications.\"^6)<COMPLETE>\n",
      "Assistant: (\"entity\"^\"Michael Washington\"^\"person\"^\"Michael Washington is identified as the individual who created the demo described in the text, specifically a demo for Simple RAG using Blazor, SQL Server, Azure OpenAI, and Function Calling.\")<EOR>\n",
      "(\"entity\"^\"Jason\"^\"person\"^\"Jason is the author of multiple demo review posts, sharing information and reviews about various Azure Search OpenAI demos written in different programming languages.\")<EOR>\n",
      "(\"entity\"^\"Azure Search OpenAI\"^\"technology\"^\"Azure Search OpenAI refers to a suite of demos and projects that utilize Azure's search capabilities combined with OpenAI's technology.\")<EOR>\n",
      "(\"entity\"^\"C#\"^\"technology\"^\"C# is a programming language used in one of the Azure Search OpenAI demos reviewed by Jason.\")<EOR>\n",
      "(\"entity\"^\"Javascript/Typescript\"^\"technology\"^\"Javascript/Typescript is a programming language used in the second Azure Search OpenAI demo reviewed by Jason.\")<EOR>\n",
      "(\"entity\"^\"Python\"^\"technology\"^\"Python is a programming language used in another Azure Search OpenAI demo reviewed by Jason.\")<EOR>\n",
      "(\"entity\"^\"Blazor\"^\"technology\"^\"Blazor is a framework used in Michael Washington's demo for Simple RAG.\")<EOR>\n",
      "(\"entity\"^\"SQL Server\"^\"technology\"^\"SQL Server is a database technology used in Michael Washington's demo for Simple RAG.\")<EOR>\n",
      "(\"entity\"^\"Azure OpenAI\"^\"technology\"^\"Azure OpenAI is a service used in Michael Washington's demo for Simple RAG and is a central technology in the suite of Azure Search OpenAI demos.\")<EOR>\n",
      "(\"entity\"^\"Function Calling\"^\"technology\"^\"Function Calling is a feature used in Michael Washington's demo for Simple RAG.\")<EOR>\n",
      "(\"relationship\"^\"Jason\"^\"Michael Washington\"^\"Jason reviews a demo created by Michael Washington, acknowledging it as a great next step for developers looking to integrate GenAI technologies.\"^7)<EOR>\n",
      "(\"relationship\"^\"Jason\"^\"Azure Search OpenAI\"^\"Jason reviews multiple demos utilizing Azure Search OpenAI services, showcasing their application in different programming languages.\"^9)<EOR>\n",
      "(\"relationship\"^\"Michael Washington\"^\"Blazor\"^\"Michael Washington's demo for Simple RAG utilizes the Blazor framework.\"^8)<EOR>\n",
      "(\"relationship\"^\"Michael Washington\"^\"SQL Server\"^\"Michael Washington's demo for Simple RAG involves using SQL Server as a database technology.\"^8)<EOR>\n",
      "(\"relationship\"^\"Michael Washington\"^\"Azure OpenAI\"^\"Michael Washington's demo for Simple RAG includes the use of Azure OpenAI services.\"^9)<EOR>\n",
      "(\"relationship\"^\"Michael Washington\"^\"Function Calling\"^\"Michael Washington's demo for Simple RAG incorporates Function Calling as a feature.\"^8)<EOR>\n",
      "(\"relationship\"^\"Azure Search OpenAI\"^\"C#\"^\"One of the Azure Search OpenAI demos reviewed by Jason is written in C#.\"^7)<EOR>\n",
      "(\"relationship\"^\"Azure Search OpenAI\"^\"Javascript/Typescript\"^\"One of the Azure Search OpenAI demos reviewed by Jason is written in Javascript/Typescript.\"^7)<EOR>\n",
      "(\"relationship\"^\"Azure Search OpenAI\"^\"Python\"^\"One of the Azure Search OpenAI demos reviewed by Jason is written in Python.\"^7)<COMPLETE>\n"
     ]
    }
   ],
   "source": [
    "string tuple_delimiter = \"^\";\n",
    "string completion_delimiter = \"<COMPLETE>\";\n",
    "string record_delimiter = \"<EOR>\";\n",
    "string entity_types = \"\"\"organization\"\", \"\"person\"\", \"\"geo\"\", \"\"event\"\"\";\n",
    "\n",
    "ChatClient chatClient = client.GetChatClient(llm);\n",
    "\n",
    "string fileText = File.ReadAllText(\"input/essay.txt\");\n",
    "\n",
    "var tokenizer = Tiktoken.CreateTiktokenForModel(\"gpt-4o\");\n",
    "#pragma warning disable SKEXP0050\n",
    "var lines = TextChunker.SplitPlainTextLines(fileText, 500, text => tokenizer.CountTokens(text));\n",
    "var paragraphs = TextChunker.SplitPlainTextParagraphs(lines, 500, 100, null, text => tokenizer.CountTokens(text));\n",
    "\n",
    "int max_knowledge_triplets = 10;\n",
    "for (int i = 0; i < 2; i++)\n",
    "{\n",
    "    string input_text = paragraphs[i];\n",
    "    \n",
    "string prompt = $@\"\n",
    "-Goal-\n",
    "Given a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n",
    "\n",
    "-Steps-\n",
    "1. Identify all entities. For each identified entity, extract the following information:\n",
    "- entity_name: Name of the entity, capitalized\n",
    "- entity_type: One of the following types: [{entity_types}]\n",
    "- entity_description: Comprehensive description of the entity's attributes and activities\n",
    "Format each entity as (\"\"entity\"\"{tuple_delimiter}<entity_name>{tuple_delimiter}<entity_type>{tuple_delimiter}<entity_description>\n",
    "\n",
    "2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\n",
    "For each pair of related entities, extract the following information:\n",
    "- source_entity: name of the source entity, as identified in step 1\n",
    "- target_entity: name of the target entity, as identified in step 1\n",
    "- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n",
    "- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n",
    " Format each relationship as (\"\"relationship\"\"{tuple_delimiter}<source_entity>{tuple_delimiter}<target_entity>{tuple_delimiter}<relationship_description>{tuple_delimiter}<relationship_strength>)\n",
    "\n",
    "3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **{record_delimiter}** as the list delimiter.\n",
    "\n",
    "4. When finished, output {completion_delimiter}\n",
    "\n",
    "######################\n",
    "-Examples-\n",
    "######################\n",
    "Example 1:\n",
    "\n",
    "Entity_types: [person, technology, mission, organization, location]\n",
    "Text:\n",
    "while Alex clenched his jaw, the buzz of frustration dull against the backdrop of Taylor's authoritarian certainty. It was this competitive undercurrent that kept him alert, the sense that his and Jordan's shared commitment to discovery was an unspoken rebellion against Cruz's narrowing vision of control and order.\n",
    "\n",
    "Then Taylor did something unexpected. They paused beside Jordan and, for a moment, observed the device with something akin to reverence. �If this tech can be understood...\"\" Taylor said, their voice quieter, \"\"It could change the game for us. For all of us.�\n",
    "\n",
    "The underlying dismissal earlier seemed to falter, replaced by a glimpse of reluctant respect for the gravity of what lay in their hands. Jordan looked up, and for a fleeting heartbeat, their eyes locked with Taylor's, a wordless clash of wills softening into an uneasy truce.\n",
    "\n",
    "It was a small transformation, barely perceptible, but one that Alex noted with an inward nod. They had all been brought here by different paths\n",
    "################\n",
    "Output:\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"Alex\"\"{tuple_delimiter}\"\"person\"\"{tuple_delimiter}\"\"Alex is a character who experiences frustration and is observant of the dynamics among other characters.\"\"){record_delimiter}\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"Taylor\"\"{tuple_delimiter}\"\"person\"\"{tuple_delimiter}\"\"Taylor is portrayed with authoritarian certainty and shows a moment of reverence towards a device, indicating a change in perspective.\"\"){record_delimiter}\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"Jordan\"\"{tuple_delimiter}\"\"person\"\"{tuple_delimiter}\"\"Jordan shares a commitment to discovery and has a significant interaction with Taylor regarding a device.\"\"){record_delimiter}\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"Cruz\"\"{tuple_delimiter}\"\"person\"\"{tuple_delimiter}\"\"Cruz is associated with a vision of control and order, influencing the dynamics among other characters.\"\"){record_delimiter}\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"The Device\"\"{tuple_delimiter}\"\"technology\"\"{tuple_delimiter}\"\"The Device is central to the story, with potential game-changing implications, and is revered by Taylor.\"\"){record_delimiter}\n",
    "(\"\"relationship\"\"{tuple_delimiter}\"\"Alex\"\"{tuple_delimiter}\"\"Taylor\"\"{tuple_delimiter}\"\"Alex is affected by Taylor's authoritarian certainty and observes changes in Taylor's attitude towards the device.\"\"{tuple_delimiter}7){record_delimiter}\n",
    "(\"\"relationship\"\"{tuple_delimiter}\"\"Alex\"\"{tuple_delimiter}\"\"Jordan\"\"{tuple_delimiter}\"\"Alex and Jordan share a commitment to discovery, which contrasts with Cruz's vision.\"\"{tuple_delimiter}6){record_delimiter}\n",
    "(\"\"relationship\"\"{tuple_delimiter}\"\"Taylor\"\"{tuple_delimiter}\"\"Jordan\"\"{tuple_delimiter}\"\"Taylor and Jordan interact directly regarding the device, leading to a moment of mutual respect and an uneasy truce.\"\"{tuple_delimiter}8){record_delimiter}\n",
    "(\"\"relationship\"\"{tuple_delimiter}\"\"Jordan\"\"{tuple_delimiter}\"\"Cruz\"\"{tuple_delimiter}\"\"Jordan's commitment to discovery is in rebellion against Cruz's vision of control and order.\"\"{tuple_delimiter}5){record_delimiter}\n",
    "(\"\"relationship\"\"{tuple_delimiter}\"\"Taylor\"\"{tuple_delimiter}\"\"The Device\"\"{tuple_delimiter}\"\"Taylor shows reverence towards the device, indicating its importance and potential impact.\"\"{tuple_delimiter}9){completion_delimiter}\n",
    "#############################\n",
    "Example 2:\n",
    "\n",
    "Entity_types: [person, technology, mission, organization, location]\n",
    "Text:\n",
    "They were no longer mere operatives; they had become guardians of a threshold, keepers of a message from a realm beyond stars and stripes. This elevation in their mission could not be shackled by regulations and established protocols�it demanded a new perspective, a new resolve.\n",
    "\n",
    "Tension threaded through the dialogue of beeps and static as communications with Washington buzzed in the background. The team stood, a portentous air enveloping them. It was clear that the decisions they made in the ensuing hours could redefine humanity's place in the cosmos or condemn them to ignorance and potential peril.\n",
    "\n",
    "Their connection to the stars solidified, the group moved to address the crystallizing warning, shifting from passive recipients to active participants. Mercer's latter instincts gained precedence� the team's mandate had evolved, no longer solely to observe and report but to interact and prepare. A metamorphosis had begun, and Operation: Dulce hummed with the newfound frequency of their daring, a tone set not by the earthly\n",
    "#############\n",
    "Output:\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"Washington\"\"{tuple_delimiter}\"\"location\"\"{tuple_delimiter}\"\"Washington is a location where communications are being received, indicating its importance in the decision-making process.\"\"){record_delimiter}\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"Operation: Dulce\"\"{tuple_delimiter}\"\"mission\"\"{tuple_delimiter}\"\"Operation: Dulce is described as a mission that has evolved to interact and prepare, indicating a significant shift in objectives and activities.\"\"){record_delimiter}\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"The team\"\"{tuple_delimiter}\"\"organization\"\"{tuple_delimiter}\"\"The team is portrayed as a group of individuals who have transitioned from passive observers to active participants in a mission, showing a dynamic change in their role.\"\"){record_delimiter}\n",
    "(\"\"relationship\"\"{tuple_delimiter}\"\"The team\"\"{tuple_delimiter}\"\"Washington\"\"{tuple_delimiter}\"\"The team receives communications from Washington, which influences their decision-making process.\"\"{tuple_delimiter}7){record_delimiter}\n",
    "(\"\"relationship\"\"{tuple_delimiter}\"\"The team\"\"{tuple_delimiter}\"\"Operation: Dulce\"\"{tuple_delimiter}\"\"The team is directly involved in Operation: Dulce, executing its evolved objectives and activities.\"\"{tuple_delimiter}9){completion_delimiter}\n",
    "#############################\n",
    "Example 3:\n",
    "\n",
    "Entity_types: [person, role, technology, organization, event, location, concept]\n",
    "Text:\n",
    "their voice slicing through the buzz of activity. \"\"Control may be an illusion when facing an intelligence that literally writes its own rules,\"\" they stated stoically, casting a watchful eye over the flurry of data.\n",
    "\n",
    "\"\"It's like it's learning to communicate,\"\" offered Sam Rivera from a nearby interface, their youthful energy boding a mix of awe and anxiety. \"\"This gives talking to strangers' a whole new meaning.\"\"\n",
    "\n",
    "Alex surveyed his team�each face a study in concentration, determination, and not a small measure of trepidation. \"\"This might well be our first contact,\"\" he acknowledged, \"\"And we need to be ready for whatever answers back.\"\"\n",
    "\n",
    "Together, they stood on the edge of the unknown, forging humanity's response to a message from the heavens. The ensuing silence was palpable�a collective introspection about their role in this grand cosmic play, one that could rewrite human history.\n",
    "\n",
    "The encrypted dialogue continued to unfold, its intricate patterns showing an almost uncanny anticipation\n",
    "#############\n",
    "Output:\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"Sam Rivera\"\"{tuple_delimiter}\"\"person\"\"{tuple_delimiter}\"\"Sam Rivera is a member of a team working on communicating with an unknown intelligence, showing a mix of awe and anxiety.\"\"){record_delimiter}\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"Alex\"\"{tuple_delimiter}\"\"person\"\"{tuple_delimiter}\"\"Alex is the leader of a team attempting first contact with an unknown intelligence, acknowledging the significance of their task.\"\"){record_delimiter}\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"Control\"\"{tuple_delimiter}\"\"concept\"\"{tuple_delimiter}\"\"Control refers to the ability to manage or govern, which is challenged by an intelligence that writes its own rules.\"\"){record_delimiter}\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"Intelligence\"\"{tuple_delimiter}\"\"concept\"\"{tuple_delimiter}\"\"Intelligence here refers to an unknown entity capable of writing its own rules and learning to communicate.\"\"){record_delimiter}\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"First Contact\"\"{tuple_delimiter}\"\"event\"\"{tuple_delimiter}\"\"First Contact is the potential initial communication between humanity and an unknown intelligence.\"\"){record_delimiter}\n",
    "(\"\"entity\"\"{tuple_delimiter}\"\"Humanity's Response\"\"{tuple_delimiter}\"\"event\"\"{tuple_delimiter}\"\"Humanity's Response is the collective action taken by Alex's team in response to a message from an unknown intelligence.\"\"){record_delimiter}\n",
    "(\"\"relationship\"\"{tuple_delimiter}\"\"Sam Rivera\"\"{tuple_delimiter}\"\"Intelligence\"\"{tuple_delimiter}\"\"Sam Rivera is directly involved in the process of learning to communicate with the unknown intelligence.\"\"{tuple_delimiter}9){record_delimiter}\n",
    "(\"\"relationship\"\"{tuple_delimiter}\"\"Alex\"\"{tuple_delimiter}\"\"First Contact\"\"{tuple_delimiter}\"\"Alex leads the team that might be making the First Contact with the unknown intelligence.\"\"{tuple_delimiter}10){record_delimiter}\n",
    "(\"\"relationship\"\"{tuple_delimiter}\"\"Alex\"\"{tuple_delimiter}\"\"Humanity's Response\"\"{tuple_delimiter}\"\"Alex and his team are the key figures in Humanity's Response to the unknown intelligence.\"\"{tuple_delimiter}8){record_delimiter}\n",
    "(\"\"relationship\"\"{tuple_delimiter}\"\"Control\"\"{tuple_delimiter}\"\"Intelligence\"\"{tuple_delimiter}\"\"The concept of Control is challenged by the Intelligence that writes its own rules.\"\"{tuple_delimiter}7){completion_delimiter}\n",
    "#############################\n",
    "-Real Data-\n",
    "######################\n",
    "Entity_types: {entity_types}\n",
    "Text: {input_text}\n",
    "######################\n",
    "Output:\";\n",
    "\n",
    "    ChatCompletion completion = chatClient.CompleteChat(\n",
    "    \t[\n",
    "        \tnew UserChatMessage(prompt),\n",
    "    \t]);\n",
    "\n",
    "\tConsole.WriteLine($\"{completion.Role}: {completion.Content[0].Text}\");\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
